{"question": "What is not the primary reason my duck feather filled jacket works well against the snow", "choices": ["feathers slows heat transfer", "small flexible solar panels"], "answer": 1, "metadata": {"id": "1095", "split": "test", "negation_rule": "not/be"}}
{"question": "Turning a piece of paper into a ball is not an example of", "choices": ["flattening", "squashing"], "answer": 0, "metadata": {"id": "12-999", "split": "train", "negation_rule": "not/be"}}
{"question": "Pushing on a pedal isn't an example of", "choices": ["force", "speed"], "answer": 1, "metadata": {"id": "297", "split": "train", "negation_rule": "not/be"}}
{"question": "Camel humps are not a good example of", "choices": ["Iraqi roadside prime cuisine", "changing to meet the environment"], "answer": 0, "metadata": {"id": "10-516", "split": "train", "negation_rule": "not/be"}}
{"question": "A person puts a potato in some embers on the edge of a campfire. The embers are not", "choices": ["doing a thermal release", "taking in the warmth"], "answer": 1, "metadata": {"id": "10-1096", "split": "train", "negation_rule": "not/be"}}
{"question": "If a bucket of water from the sea is left out in the sun for long enough, all that will eventually remain in the bucket isn't", "choices": ["grapes", "sodium"], "answer": 0, "metadata": {"id": "13-151", "split": "train", "negation_rule": "not/be"}}
{"question": "If you're looking for the rock between the 2nd and the 4th from our star you are not looking for", "choices": ["earth", "pluto"], "answer": 1, "metadata": {"id": "12-820", "split": "train", "negation_rule": "not/be"}}
{"question": "an example of an excellent earth mover isn't", "choices": ["cat", "annelids"], "answer": 0, "metadata": {"id": "9-439", "split": "train", "negation_rule": "not/be"}}
{"question": "Quartz crystals aren't made up of", "choices": ["hexagons", "majic"], "answer": 1, "metadata": {"id": "9-966", "split": "test", "negation_rule": "not/be"}}
{"question": "Two wheeled conveyances are not held together by", "choices": ["glue", "helically ridged pins"], "answer": 0, "metadata": {"id": "12-233", "split": "train", "negation_rule": "not/be"}}
{"question": "a producer is not a source of energy for", "choices": ["external food eaters", "rubber"], "answer": 1, "metadata": {"id": "13-773", "split": "train", "negation_rule": "not/be"}}
{"question": "Redwoods are not supported by", "choices": ["donations from the environmental protection agency", "very large and thick trunks"], "answer": 0, "metadata": {"id": "12-624", "split": "train", "negation_rule": "not/be"}}
{"question": "If a person enjoys star gazing the best place to live is not", "choices": ["the countryside", "the big city"], "answer": 1, "metadata": {"id": "13-109", "split": "train", "negation_rule": "not/be"}}
{"question": "A thermal conductor isn't made of", "choices": ["electrodes", "often metallic"], "answer": 0, "metadata": {"id": "13-335", "split": "train", "negation_rule": "not/be"}}
{"question": "Viewing stars is not made easier by", "choices": ["technology that collects electromagnetic radiation", "technology that picks up sound in space"], "answer": 1, "metadata": {"id": "7-535", "split": "dev", "negation_rule": "not/be"}}
{"question": "The substance that the respiratory system takes in from the air isn't released by", "choices": ["insects", "plants"], "answer": 0, "metadata": {"id": "13-944", "split": "train", "negation_rule": "not/be"}}
{"question": "If a see through thing is multifaceted, it isn't most likely", "choices": ["a quartz square", "a silver globe"], "answer": 1, "metadata": {"id": "13-886", "split": "train", "negation_rule": "not/be"}}
{"question": "What anchors plants into the soil are not called", "choices": ["large anchors made of metal", "the same as an american television miniseries about slavery"], "answer": 0, "metadata": {"id": "12-951", "split": "train", "negation_rule": "not/be"}}
{"question": "An example of thermal energy isn't", "choices": ["Drying our clothes in the sun", "crying in a school bathroom"], "answer": 1, "metadata": {"id": "13-982", "split": "train", "negation_rule": "not/be"}}
{"question": "A person drops a bean in the dirt, and kicks some dirt over it. If the person goes to dig up that bean a month later, it isn't likely to have", "choices": ["shrunk", "sprouted"], "answer": 0, "metadata": {"id": "11-388", "split": "train", "negation_rule": "not/be"}}
{"question": "Much iron is not in", "choices": ["Earth's second layer", "empty"], "answer": 1, "metadata": {"id": "14-512", "split": "train", "negation_rule": "not/be"}}
{"question": "The type of climate change known as anthropogenic isn't caused by this:", "choices": ["volcanic activity", "humanity"], "answer": 0, "metadata": {"id": "9-677", "split": "dev", "negation_rule": "not/be"}}
{"question": "The crust is not made of different kinds of", "choices": ["stone", "stars"], "answer": 1, "metadata": {"id": "14-1126", "split": "train", "negation_rule": "not/be"}}
{"question": "The black bear in Alaska isn't known for hunting this type of feast", "choices": ["moose", "fish"], "answer": 0, "metadata": {"id": "9-398", "split": "dev", "negation_rule": "not/be"}}
{"question": "A cypress tree's stout roots splitting asphalt is not an example of", "choices": ["weathering", "beer"], "answer": 1, "metadata": {"id": "13-955", "split": "train", "negation_rule": "not/be"}}
{"question": "When the moon, sun, and earth line up, tides aren't at their", "choices": ["Happy", "Max"], "answer": 0, "metadata": {"id": "12-123", "split": "train", "negation_rule": "not/be"}}
{"question": "A cloud gets fat and heavy and dark. The sky gets darker. The next step to expect is not", "choices": ["precipitation", "flowers"], "answer": 1, "metadata": {"id": "10-1151", "split": "train", "negation_rule": "not/be"}}
{"question": "Which isn't recyclable", "choices": ["Styrofoam food container", "soda can"], "answer": 0, "metadata": {"id": "1348", "split": "dev", "negation_rule": "not/be"}}
{"question": "A renewable resource is not used to produce", "choices": ["notebook paper", "plastic rulers"], "answer": 1, "metadata": {"id": "7-1036", "split": "dev", "negation_rule": "not/be"}}
{"question": "A light isn't refracted when", "choices": ["it shines at a mirror", "it shines at a gem"], "answer": 0, "metadata": {"id": "7-819", "split": "train", "negation_rule": "not/be"}}
{"question": "Which isn't a visible example of water vapor", "choices": ["aerial clouds", "snow"], "answer": 1, "metadata": {"id": "11-290", "split": "train", "negation_rule": "not/be"}}
{"question": "In the natural world, camouflage is not used by animals to", "choices": ["stay warm in the winter", "avoid being a meal"], "answer": 0, "metadata": {"id": "14-571", "split": "train", "negation_rule": "not/be"}}
{"question": "Our only star provides us with energy that isn't", "choices": ["reusable", "temporary"], "answer": 1, "metadata": {"id": "14-825", "split": "train", "negation_rule": "not/be"}}
{"question": "a seismograph is not a kind of tool for measuring the size of", "choices": ["planets", "terra plate displacements"], "answer": 0, "metadata": {"id": "13-474", "split": "train", "negation_rule": "not/be"}}
{"question": "365 solar cycles isn't equivalent to", "choices": ["one trip around the sun", "2 years in deep space"], "answer": 1, "metadata": {"id": "10-530", "split": "train", "negation_rule": "not/be"}}
{"question": "A full moon is not caused by", "choices": ["moonlight", "orbiting"], "answer": 0, "metadata": {"id": "1949", "split": "dev", "negation_rule": "not/be"}}
{"question": "Soil quality is not improved when", "choices": ["organisms pass and rot away", "microscopic insects infest the landscape"], "answer": 1, "metadata": {"id": "7-466", "split": "train", "negation_rule": "not/be"}}
{"question": "As the barometer reading goes lower there is not a greater chance of", "choices": ["sunshine", "getting wet"], "answer": 0, "metadata": {"id": "12-255", "split": "train", "negation_rule": "not/be"}}
{"question": "If a cat has a body temp that is below average, it isn't in", "choices": ["danger", "safe ranges"], "answer": 1, "metadata": {"id": "12-1140", "split": "train", "negation_rule": "not/be"}}
{"question": "Snow isn't more likely to fall two months before", "choices": ["June", "March"], "answer": 0, "metadata": {"id": "1271", "split": "test", "negation_rule": "not/be"}}
{"question": "Dead plants are not easier to find in", "choices": ["January", "September"], "answer": 1, "metadata": {"id": "35", "split": "test", "negation_rule": "not/be"}}
{"question": "This object in your pocket isn't the most likely to shock you", "choices": ["your library card", "your phone"], "answer": 0, "metadata": {"id": "14-659", "split": "train", "negation_rule": "not/be"}}
{"question": "panting isn't the equivalent to humans", "choices": ["expelling water from their dermis", "drowning in a small puddle"], "answer": 1, "metadata": {"id": "9-1161", "split": "dev", "negation_rule": "not/be"}}
{"question": "A thing which ferns have in endless supply when expanding isn't", "choices": ["darkness", "dirt"], "answer": 0, "metadata": {"id": "12-640", "split": "train", "negation_rule": "not/be"}}
{"question": "A boy hates summer with a burning passion, so luckily the longest he should ever have to endure the season isn't", "choices": ["twelve weeks", "nine months"], "answer": 1, "metadata": {"id": "12-355", "split": "train", "negation_rule": "not/be"}}
{"question": "One way to remember the method of Scientific Classification is not", "choices": ["run", "make a sentence"], "answer": 0, "metadata": {"id": "13-580", "split": "train", "negation_rule": "not/be"}}
{"question": "Rabbits with white fur aren't hardest to detect in", "choices": ["the arctic in Winter", "The middle of a well-lit street"], "answer": 1, "metadata": {"id": "13-660", "split": "train", "negation_rule": "not/be"}}
{"question": "All the food in the fridge is warm on a remote farm with a windmill. The most likely cause is not", "choices": ["it's a very windy day", "it's a windless day"], "answer": 0, "metadata": {"id": "13-391", "split": "train", "negation_rule": "not/be"}}
{"question": "It isn't easiest to get a clear photo of the moon by", "choices": ["using a telescopic lens", "looking through a microscope"], "answer": 1, "metadata": {"id": "7-13", "split": "train", "negation_rule": "not/be"}}
{"question": "A way to conserve something isn't to", "choices": ["use it quickly", "use it sparsely"], "answer": 0, "metadata": {"id": "12-288", "split": "train", "negation_rule": "not/be"}}
{"question": "If your dog is not overweight", "choices": ["cut back their caloric intake", "let them sleep more"], "answer": 1, "metadata": {"id": "7-284", "split": "test", "negation_rule": "not/be"}}
{"question": "A mouse is not made up of", "choices": ["dairy", "organic material"], "answer": 0, "metadata": {"id": "10-1163", "split": "train", "negation_rule": "not/be"}}
{"question": "A place where penguins exist with pods of black and white mammals is not", "choices": ["uninhabitable by iguanas", "painted with cream"], "answer": 1, "metadata": {"id": "14-372", "split": "train", "negation_rule": "not/be"}}
{"question": "A woman is digging under a tree on a tall mountain. She is looking for interesting rocks, and a foot down into the soil, discovers a fossilized fish skeleton. From this discovery, the woman is not able to determine that", "choices": ["sometimes rain can move fish to high spaces", "the mountain used to be underwater"], "answer": 0, "metadata": {"id": "8-264", "split": "train", "negation_rule": "not/be"}}
{"question": "one inherited characteristic of fur isn't it's", "choices": ["hue", "weight"], "answer": 1, "metadata": {"id": "9-617", "split": "train", "negation_rule": "not/be"}}
{"question": "The creation of sediment is not produced by", "choices": ["chemicals compounds combining together", "the break down of other materials"], "answer": 0, "metadata": {"id": "1564", "split": "train", "negation_rule": "not/be"}}
{"question": "Bluebirds are not found in", "choices": ["vast green fields", "glaciers"], "answer": 1, "metadata": {"id": "14-894", "split": "train", "negation_rule": "not/be"}}
{"question": "Leaving remain oil supplies alone isn't a form of", "choices": ["transportation", "conservation"], "answer": 0, "metadata": {"id": "10-258", "split": "train", "negation_rule": "not/be"}}
{"question": "the hourly totals of sunshine aren't directly connect to", "choices": ["seasons", "altitude"], "answer": 1, "metadata": {"id": "9-1105", "split": "dev", "negation_rule": "not/be"}}
{"question": "something that can negatively impact an organisms health is not", "choices": ["chemistry", "chickenpox"], "answer": 0, "metadata": {"id": "10-1003", "split": "train", "negation_rule": "not/be"}}
{"question": "A container with a printed scale on it's side is not used to", "choices": ["measure volume", "hold flowers"], "answer": 1, "metadata": {"id": "12-176", "split": "train", "negation_rule": "not/be"}}
{"question": "Your clothes likely will be soaked if the skies aren't", "choices": ["sunny without clouds", "black"], "answer": 0, "metadata": {"id": "14-574", "split": "train", "negation_rule": "not/be"}}
{"question": "If a thing is going between liquid and solid, it is not likely to", "choices": ["measure consistently", "be a door"], "answer": 1, "metadata": {"id": "14-987", "split": "train", "negation_rule": "not/be"}}
{"question": "There isn't a heightened threat of landslide in", "choices": ["the ocean", "The Andes"], "answer": 0, "metadata": {"id": "9-692", "split": "test", "negation_rule": "not/be"}}
{"question": "A moth leaving it's cocoon isn't the final step in a", "choices": ["transformation", "life cycle"], "answer": 1, "metadata": {"id": "9-638", "split": "test", "negation_rule": "not/be"}}
{"question": "If a puppy steps on a lit cigarette, it is not likely", "choices": ["happy", "pained"], "answer": 0, "metadata": {"id": "12-111", "split": "train", "negation_rule": "not/be"}}
{"question": "A landslide is not likely to occur on a slope as", "choices": ["downward movement is facilitated", "there is more debris"], "answer": 1, "metadata": {"id": "10-688", "split": "train", "negation_rule": "not/be"}}
{"question": "The organisms likely to have the waxiest leaves aren't", "choices": ["gorilla", "jades"], "answer": 0, "metadata": {"id": "11-483", "split": "train", "negation_rule": "not/be"}}
{"question": "Corn and wheat aren't among the favorite foods of", "choices": ["humans", "fish"], "answer": 1, "metadata": {"id": "14-730", "split": "train", "negation_rule": "not/be"}}
{"question": "A thing's position is not altered when", "choices": ["thing feels moved emotionally", "the thing adjusts its location"], "answer": 0, "metadata": {"id": "7-392", "split": "train", "negation_rule": "not/be"}}
{"question": "A way to tell if a rock could possibly hold Fe inside is not to", "choices": ["hover a magnet over it", "take the rock home"], "answer": 1, "metadata": {"id": "7-283", "split": "dev", "negation_rule": "not/be"}}
{"question": "The leading cause of soil and rock erosion is not", "choices": ["NaCl", "H2O"], "answer": 0, "metadata": {"id": "1500", "split": "test", "negation_rule": "not/be"}}
{"question": "A horse is outside alone in the middle of summer on a sunny day in a desert. The horse is getting wet. The wetness is not coming from", "choices": ["sweat glands", "orange juice"], "answer": 1, "metadata": {"id": "12-864", "split": "train", "negation_rule": "not/be"}}
{"question": "A family moves into an old home that mice have moved into. Soon after the human family moves in, the family of mice aren't likely to", "choices": ["be frozen", "be ejected"], "answer": 0, "metadata": {"id": "11-415", "split": "train", "negation_rule": "not/be"}}
{"question": "steam isn't a kind of water above", "choices": ["373 kelvin", "jupiter"], "answer": 1, "metadata": {"id": "13-600", "split": "train", "negation_rule": "not/be"}}
{"question": "Nearly all prehistoric bones are not found in", "choices": ["granite", "shale"], "answer": 0, "metadata": {"id": "12-1157", "split": "train", "negation_rule": "not/be"}}
{"question": "A mighty river flows through an area for millennia. Afterwards, it can be noted that where there once were shallow rivers, there aren't now", "choices": ["massive canyons", "old socks"], "answer": 1, "metadata": {"id": "10-56", "split": "train", "negation_rule": "not/be"}}
{"question": "A thermal conductor is not made of", "choices": ["types of wire", "that which conducts"], "answer": 0, "metadata": {"id": "7-994", "split": "train", "negation_rule": "not/be"}}
{"question": "The Earth's closest heat source isn't", "choices": ["our celestial fireball", "gamma rays"], "answer": 1, "metadata": {"id": "9-181", "split": "test", "negation_rule": "not/be"}}
{"question": "Personal protection equipment isn't essential when", "choices": ["wearing a sports cup", "experimenting with volatile and vaporous liquids"], "answer": 0, "metadata": {"id": "10-544", "split": "train", "negation_rule": "not/be"}}
{"question": "A person is wondering how much the steam from the pot of water that is boiling will measure. They are not able to measure it in a definite way by", "choices": ["collecting the condensed liquid", "making the liquid condense outdoors"], "answer": 1, "metadata": {"id": "11-731", "split": "train", "negation_rule": "not/be"}}
{"question": "nutrients from food and water are not necessary to an organism's", "choices": ["friendships", "survival"], "answer": 0, "metadata": {"id": "8-462", "split": "train", "negation_rule": "not/be"}}
{"question": "If the ground is fully shaded, and plants there barely grow, likely the reason isn't", "choices": ["oaks there are mighty", "birds there are fat"], "answer": 1, "metadata": {"id": "12-16", "split": "train", "negation_rule": "not/be"}}
{"question": "If a thing is electrically insulated, then it is not", "choices": ["metal inside, metal outside", "metal inside, other material outside"], "answer": 0, "metadata": {"id": "12-884", "split": "train", "negation_rule": "not/be"}}
{"question": "One way to retain your own thermal energy is not to", "choices": ["wear fluffy socks", "sit in snow"], "answer": 1, "metadata": {"id": "13-804", "split": "train", "negation_rule": "not/be"}}
{"question": "Which of these isn't less likely to cause pollution", "choices": ["chopper", "mountain bike"], "answer": 0, "metadata": {"id": "14-451", "split": "train", "negation_rule": "not/be"}}
{"question": "If a person wants to save the environment, a thing they can try isn't", "choices": ["reusing plastic dishware", "burning more plastic"], "answer": 1, "metadata": {"id": "12-31", "split": "train", "negation_rule": "not/be"}}
{"question": "The crust under everyone's feet isn't", "choices": ["the ice that forms in cold regions", "the outer covering of the third planet from the sun"], "answer": 0, "metadata": {"id": "11-566", "split": "train", "negation_rule": "not/be"}}
{"question": "Sleet is not", "choices": ["potentially dangerous", "poison"], "answer": 1, "metadata": {"id": "10-201", "split": "train", "negation_rule": "not/be"}}
{"question": "We are trying to use air as sources of energy because there is an infinite amount of it, same with water. These are not two examples of", "choices": ["Limited resources", "Renewable resources"], "answer": 0, "metadata": {"id": "9-143", "split": "dev", "negation_rule": "not/be"}}
{"question": "What separates animals that thrive and those that go extinct are not", "choices": ["the ability to adapt", "the type of animal"], "answer": 1, "metadata": {"id": "405", "split": "train", "negation_rule": "not/be"}}
{"question": "Nectar isn't taken to", "choices": ["flowers", "a hive"], "answer": 0, "metadata": {"id": "78", "split": "test", "negation_rule": "not/be"}}
{"question": "The appropriate place to put this item isn't the recycling bin", "choices": ["used soda can", "used Styrofoam plates"], "answer": 1, "metadata": {"id": "8-471", "split": "test", "negation_rule": "not/be"}}
{"question": "Avoiding the use of fossil fuel is not an example of", "choices": ["Ecosystem Vulnerability", "Conservationism"], "answer": 0, "metadata": {"id": "8-391", "split": "train", "negation_rule": "not/be"}}
{"question": "As a lake increases in size, there aren't more", "choices": ["catfish", "volcanoes"], "answer": 1, "metadata": {"id": "12-1125", "split": "train", "negation_rule": "not/be"}}
{"question": "A sunburn isn't most likely to happen after hiking in a", "choices": ["wetland", "desert"], "answer": 0, "metadata": {"id": "9-850", "split": "train", "negation_rule": "not/be"}}
{"question": "the oceans aren't full of", "choices": ["sea life", "fresh water"], "answer": 1, "metadata": {"id": "9-883", "split": "test", "negation_rule": "not/be"}}
{"question": "Winter in the northern hemisphere is not occurring on", "choices": ["the day after July 4th", "the day after November 30th"], "answer": 0, "metadata": {"id": "1232", "split": "train", "negation_rule": "not/be"}}
{"question": "The transportation with the most mass isn't likely a", "choices": ["commercial plane", "private car"], "answer": 1, "metadata": {"id": "163", "split": "test", "negation_rule": "not/be"}}
{"question": "when a tadpole changes into a frog, the tadpole isn't like", "choices": ["a grape", "a maggot"], "answer": 0, "metadata": {"id": "267", "split": "train", "negation_rule": "not/be"}}
{"question": "There are less hummingbirds by this house than before not because of", "choices": ["a feeder at another house", "the size of the feeder"], "answer": 1, "metadata": {"id": "664", "split": "test", "negation_rule": "not/because"}}
{"question": "A goose needs to move to warmer states for the winter. Leaving its summer home, it heads out without a map, not because it can always find the right way by using", "choices": ["a compass that points north", "the Earth's magnetic patterns"], "answer": 0, "metadata": {"id": "10-343", "split": "train", "negation_rule": "not/because"}}
{"question": "Driving during a snow storm or strong thunderstorm is a bad idea not because bad weather makes it", "choices": ["harder to see", "able to fly"], "answer": 1, "metadata": {"id": "14-701", "split": "train", "negation_rule": "not/because"}}
{"question": "The Appalachians reach amazing heights not because of how stone", "choices": ["created anchors", "piles together"], "answer": 0, "metadata": {"id": "9-639", "split": "train", "negation_rule": "not/because"}}
{"question": "A small rodent will fear a creature such as a fox not because", "choices": ["foxes enjoy rodent dinners", "mice are able to fly"], "answer": 1, "metadata": {"id": "11-641", "split": "train", "negation_rule": "not/because"}}
{"question": "A cow can see that the farmer is coming not because there is light that makes its way", "choices": ["into a bucket", "into his eyes"], "answer": 0, "metadata": {"id": "11-97", "split": "train", "negation_rule": "not/because"}}
{"question": "Humans have the ability to change how much they weigh, but we cannot change how tall we are not because that is", "choices": ["hereditary", "Too hard"], "answer": 1, "metadata": {"id": "10-645", "split": "train", "negation_rule": "not/because"}}
{"question": "A young boy is reprimanded by his mother for sleeping with his heavy blankets over his head. His mother is worried that if the boy continues to sleep like that, he will suffocate. This is not because", "choices": ["beds can cause issues with breathing", "CO2 in large amounts is fatal"], "answer": 0, "metadata": {"id": "8-187", "split": "train", "negation_rule": "not/because"}}
{"question": "Insomniacs are less healthy than other people not because they", "choices": ["rarely slumber", "are in space"], "answer": 1, "metadata": {"id": "14-4", "split": "train", "negation_rule": "not/because"}}
{"question": "There are many protests and outraged people about humans changing the environment of the rain forest not because changing even something small in an environment can", "choices": ["make it laugh", "wreck it"], "answer": 0, "metadata": {"id": "10-455", "split": "train", "negation_rule": "not/because"}}
{"question": "A person can be punched in the chest without the heart stopping not because", "choices": ["ribs guard it", "hearts are hollow"], "answer": 1, "metadata": {"id": "10-1190", "split": "train", "negation_rule": "not/because"}}
{"question": "An electric car uses less gasoline than a regular car not because", "choices": ["gas is unable to be used", "power is prioritized over gas"], "answer": 0, "metadata": {"id": "7-114", "split": "dev", "negation_rule": "not/because"}}
{"question": "A camel can survive in the desert not because of", "choices": ["hoarded energy", "horses"], "answer": 1, "metadata": {"id": "12-678", "split": "train", "negation_rule": "not/because"}}
{"question": "Venus fly traps are poor at creating their own food though photosynthesis not because", "choices": ["they need water", "they require insects"], "answer": 0, "metadata": {"id": "7-1183", "split": "train", "negation_rule": "not/because"}}
{"question": "A creature can hide in plain sight from predators not because", "choices": ["it misdirects", "it burns"], "answer": 1, "metadata": {"id": "10-1095", "split": "train", "negation_rule": "not/because"}}
{"question": "A bear hibernates through cold weather not because", "choices": ["winter is too cold", "resources are scarce in winter"], "answer": 0, "metadata": {"id": "7-73", "split": "dev", "negation_rule": "not/because"}}
{"question": "When an animal goes into a den during cold weather they probably did this not because", "choices": ["their ancestors did the same thing", "they are escaping predators"], "answer": 1, "metadata": {"id": "11-520", "split": "train", "negation_rule": "not/because"}}
{"question": "If Paul is playing basketball and finds that his skin is becoming wet and smelly, it might be not because", "choices": ["His body is too cold", "His body is trying to lower its temperature"], "answer": 0, "metadata": {"id": "9-972", "split": "train", "negation_rule": "not/because"}}
{"question": "A flashlight works not because the batteries inside of it produce chemical energy that", "choices": ["is transferred to another type", "burn into the plastic"], "answer": 1, "metadata": {"id": "7-1124", "split": "dev", "negation_rule": "not/because"}}
{"question": "The inside of the Thanksgiving turkey is white instead of pink not because of", "choices": ["light energy", "heat energy"], "answer": 0, "metadata": {"id": "490", "split": "test", "negation_rule": "not/because"}}
{"question": "Greenhouses work not because", "choices": ["air retains humidity and warmth", "gasses are trapped in buildings"], "answer": 1, "metadata": {"id": "7-371", "split": "train", "negation_rule": "not/because"}}
{"question": "More carbon dioxide is in the air in the past decade than ever before, probably not because", "choices": ["more plant life", "human population increased"], "answer": 0, "metadata": {"id": "7-617", "split": "train", "negation_rule": "not/because"}}
{"question": "Water, while a finite resource, is renewable not because", "choices": ["water is quite cyclical", "water is found in trees"], "answer": 1, "metadata": {"id": "8-172", "split": "train", "negation_rule": "not/because"}}
{"question": "Worms are excellent decomposers not because", "choices": ["worms enjoy eating dirt and decay", "they enjoy eating carcasses and expel waste back to earth"], "answer": 0, "metadata": {"id": "7-982", "split": "train", "negation_rule": "not/because"}}
{"question": "The reason you tend to think of the color white when you think of environments where its constantly freezing, is not because those place get tons of", "choices": ["snowfall", "droughts"], "answer": 1, "metadata": {"id": "12-816", "split": "train", "negation_rule": "not/because"}}
{"question": "One of the reasons some species go extinct is not because predators", "choices": ["go dancing with them", "murder too many of them"], "answer": 0, "metadata": {"id": "13-578", "split": "train", "negation_rule": "not/because"}}
{"question": "Runoff happens not because of", "choices": ["people", "cattails"], "answer": 1, "metadata": {"id": "1635", "split": "test", "negation_rule": "not/because"}}
{"question": "Doing this in national parks and many other wooded areas is illegal not because it harms the environment", "choices": ["talking", "ditching your junk"], "answer": 0, "metadata": {"id": "14-1419", "split": "train", "negation_rule": "not/because"}}
{"question": "The rhino population is smaller than before not because", "choices": ["people use parts for health remedies", "cars crashed into rhinos"], "answer": 1, "metadata": {"id": "1766", "split": "train", "negation_rule": "not/because"}}
{"question": "When a person gets hurt physically, the person feels pain not because there are", "choices": ["magic receptors", "electric reactions"], "answer": 0, "metadata": {"id": "9-344", "split": "train", "negation_rule": "not/because"}}
{"question": "A person discovers a dinosaur skeleton in their backyard under a lot of dirt. The skeleton is lacking the bright whiteness of bones, not because it is", "choices": ["trapped in stone", "filled with beer"], "answer": 1, "metadata": {"id": "10-65", "split": "train", "negation_rule": "not/because"}}
{"question": "Fish are quickly caught in water not because of the webbed feet possessed by a", "choices": ["cheetah", "penguin"], "answer": 0, "metadata": {"id": "9-715", "split": "train", "negation_rule": "not/because"}}
{"question": "A ship navigates with a magnetic compass not because it is", "choices": ["predictable", "tradition"], "answer": 1, "metadata": {"id": "12-339", "split": "train", "negation_rule": "not/because"}}
{"question": "Steve was driving on the highway when he rear-ended another car because he didn't see it until he was just a foot away. This could have happened not because of", "choices": ["ice forming on the road", "a sudden fog moving into the area"], "answer": 0, "metadata": {"id": "9-461", "split": "test", "negation_rule": "not/because"}}
{"question": "A star produces light energy and heat not because it has a variety of", "choices": ["reactions of nuclear form", "moon rotation causing friction"], "answer": 1, "metadata": {"id": "10-577", "split": "train", "negation_rule": "not/because"}}
{"question": "Another term for wind energy is clean energy not because the wind and air contains", "choices": ["moon", "zero pollutants"], "answer": 0, "metadata": {"id": "13-718", "split": "train", "negation_rule": "not/because"}}
{"question": "Water needs to be clean in order for someone to safely drink it. Drinking polluted water is bad not because it is the same as drinking", "choices": ["poison", "rocks"], "answer": 1, "metadata": {"id": "12-137", "split": "train", "negation_rule": "not/because"}}
{"question": "Cows know there is salt in a mineral lick not because", "choices": ["they evolved where there were great redwood trees", "they have receptors on their tongue that allow them to experience spice and seasonings"], "answer": 0, "metadata": {"id": "10-648", "split": "train", "negation_rule": "not/because"}}
{"question": "Roads need repaved in spring not because", "choices": ["ice ruins them", "they are cold"], "answer": 1, "metadata": {"id": "7-499", "split": "train", "negation_rule": "not/because"}}
{"question": "A person in the woods who accidentally runs into a wild wolf will have little to fear not because", "choices": ["wolves smoke people", "wolves evade people"], "answer": 0, "metadata": {"id": "10-15", "split": "train", "negation_rule": "not/because"}}
{"question": "The reason that ducks are such excellent swimmers is not because", "choices": ["ducks have extra foot skin", "ducks are buoyant and resilient"], "answer": 1, "metadata": {"id": "7-449", "split": "train", "negation_rule": "not/because"}}
{"question": "The main reason people want to use wind as an energy source is not because there is", "choices": ["make cookies", "an everlasting supply"], "answer": 0, "metadata": {"id": "14-1259", "split": "train", "negation_rule": "not/because"}}
{"question": "A cop can tell that a car is speeding not because it is", "choices": ["cruising quickly", "moving forward"], "answer": 1, "metadata": {"id": "7-783", "split": "train", "negation_rule": "not/because"}}
{"question": "A person knows that a place always has blue skies, warm weather and a light breeze not because", "choices": ["that is the beach", "climate is fairly reliable"], "answer": 0, "metadata": {"id": "10-874", "split": "train", "negation_rule": "not/because"}}
{"question": "Squirrels are seed dispersers not because", "choices": ["they bury their food", "they eat lots of nuts"], "answer": 1, "metadata": {"id": "7-717", "split": "dev", "negation_rule": "not/because"}}
{"question": "A pod of dolphins is swimming while searching for food. The youngest dolphin swims away from the pod and is lost. The rest of the pod searches for the young dolphin by clicking into the water. The young dolphin is found not because of", "choices": ["sound of water", "echoes from noise"], "answer": 0, "metadata": {"id": "8-99", "split": "train", "negation_rule": "not/because"}}
{"question": "Rocket engines can lift rockets not because", "choices": ["of the power the hit the ground with", "of how fast they are"], "answer": 1, "metadata": {"id": "7-363", "split": "train", "negation_rule": "not/because"}}
{"question": "Some animals get caught easily by other animals not because they are slow while the predators are", "choices": ["manipulative", "speedy"], "answer": 0, "metadata": {"id": "9-691", "split": "train", "negation_rule": "not/because"}}
{"question": "Bats hunt through echolocation not because", "choices": ["their chirps are sent back after bouncing", "bats can only hear echoes"], "answer": 1, "metadata": {"id": "7-836", "split": "train", "negation_rule": "not/because"}}
{"question": "Saturn hangs around not because of", "choices": ["Saturnalia", "a central star"], "answer": 0, "metadata": {"id": "13-432", "split": "train", "negation_rule": "not/because"}}
{"question": "Using wind in order to power factories is a good idea not because", "choices": ["it can be gotten continuously", "it is free from dirt"], "answer": 1, "metadata": {"id": "7-274", "split": "train", "negation_rule": "not/because"}}
{"question": "A polar bear is white not because", "choices": ["it wants to make a Grizzly bear jealous", "its parents had white fur"], "answer": 0, "metadata": {"id": "10-720", "split": "train", "negation_rule": "not/because"}}
{"question": "Jackrabbits live in very hot environments, but are able to stay cool not because their long ears help", "choices": ["releasing warmth", "change tires"], "answer": 1, "metadata": {"id": "13-723", "split": "train", "negation_rule": "not/because"}}
{"question": "Feeling sweaty is normal on the ocean not because", "choices": ["the desert is drier", "there is more moisture in the air"], "answer": 0, "metadata": {"id": "7-476", "split": "train", "negation_rule": "not/because"}}
{"question": "When we think of bees, we also think of pollen. This is not because bees", "choices": ["consume it", "sell it"], "answer": 1, "metadata": {"id": "9-660", "split": "train", "negation_rule": "not/because"}}
{"question": "Make sure to protect your eyes when working with chemicals not because they can easily do what if handled wrong", "choices": ["nothing", "spatter upward"], "answer": 0, "metadata": {"id": "12-1060", "split": "train", "negation_rule": "not/because"}}
{"question": "A light was off not because the cord was", "choices": ["sitting on the table", "attached to a battery pack"], "answer": 1, "metadata": {"id": "9-550", "split": "test", "negation_rule": "not/because"}}
{"question": "People are switching to electric cars not because cars that use gas", "choices": ["cry", "dirty the air"], "answer": 0, "metadata": {"id": "14-1142", "split": "train", "negation_rule": "not/because"}}
{"question": "a reptile that was brown an hour later is now green not because", "choices": ["it's sitting in a leafy shrub and using camouflage", "red paint was poured over it"], "answer": 1, "metadata": {"id": "13-12", "split": "train", "negation_rule": "not/because"}}
{"question": "A metal sticker remains on a fridge not because of", "choices": ["magic that Juggaloes are unable to explain", "a force that pulls two objects together"], "answer": 0, "metadata": {"id": "10-597", "split": "train", "negation_rule": "not/because"}}
{"question": "A television may turn on at the push of a button not because", "choices": ["the path of electricity is completed", "the television is pretty short"], "answer": 1, "metadata": {"id": "7-209", "split": "train", "negation_rule": "not/because"}}
{"question": "Alice flipped a switch and the ceiling fan started running not because", "choices": ["a circuit was opened", "a circuit was closed"], "answer": 0, "metadata": {"id": "11-431", "split": "train", "negation_rule": "not/because"}}
{"question": "Plants brought to the western United States from the eastern United States often die not because of", "choices": ["the wrong climate", "bad planting methods"], "answer": 1, "metadata": {"id": "658", "split": "train", "negation_rule": "not/because"}}
{"question": "Recently, a lot of people, en masse, were told that they should take an opportunity to cast an image of an object through a pinhole onto a screen, in order to best enjoy an activity. This was not because", "choices": ["science tells us eclipses are scary", "avoiding looking directly at an eclipse is important"], "answer": 0, "metadata": {"id": "8-303", "split": "dev", "negation_rule": "not/because"}}
{"question": "A compass uses natural magnetism so it works only not because", "choices": ["the Earth yanks it", "the Earth is fat"], "answer": 1, "metadata": {"id": "12-643", "split": "train", "negation_rule": "not/because"}}
{"question": "In addition to a slippery road, blizzards can be dangerous to drive in not because", "choices": ["a tornado is likely to pick up your car", "you may only see a car in front of you when it's too late"], "answer": 0, "metadata": {"id": "12-479", "split": "train", "negation_rule": "not/because"}}
{"question": "It's too foggy to see more than two feet on a highway. This is not because of", "choices": ["vapor of H2O condensed in the air", "helium vapor in the air"], "answer": 1, "metadata": {"id": "14-1153", "split": "train", "negation_rule": "not/because"}}
{"question": "Riding a two wheeled human powered vehicle is good for the environment not because", "choices": ["it helps people stay in shape", "it runs without fuel"], "answer": 0, "metadata": {"id": "9-353", "split": "train", "negation_rule": "not/because"}}
{"question": "Asking a blind person to look at something is rude not because they are", "choices": ["unable to see", "unable to speak"], "answer": 1, "metadata": {"id": "14-819", "split": "train", "negation_rule": "not/because"}}
{"question": "A person is reading a map and gets frustrated. The map ends up in a hundred scraps on the floor not because the person", "choices": ["burned it", "ripped it"], "answer": 0, "metadata": {"id": "11-222", "split": "train", "negation_rule": "not/because"}}
{"question": "Being able to enjoy eating Mideastern dates in a small town in the USA is possible not because", "choices": ["transporting food became easier, cheaper, and quicker", "transported food tastes great"], "answer": 1, "metadata": {"id": "7-313", "split": "train", "negation_rule": "not/because"}}
{"question": "A shark will be unable to survive on eating algae and moss, not because", "choices": ["it is a vegetarian", "it is a predator"], "answer": 0, "metadata": {"id": "9-645", "split": "test", "negation_rule": "not/because"}}
{"question": "powered on lightbulbs burst with cold water not because they", "choices": ["the inside is hot", "the inside is also cool"], "answer": 1, "metadata": {"id": "285", "split": "train", "negation_rule": "not/because"}}
{"question": "The moon is bright in the night sky, especially when full not because", "choices": ["batteries power it", "sunlight brightens it"], "answer": 0, "metadata": {"id": "10-505", "split": "train", "negation_rule": "not/because"}}
{"question": "Billy's new puppy had floppy ears. That might be not because", "choices": ["The puppy's mother had ears that looked the same way", "The puppy was tired"], "answer": 1, "metadata": {"id": "9-642", "split": "train", "negation_rule": "not/because"}}
{"question": "A person wanting to find a live bear in a forest will have difficulty not because bears", "choices": ["are friendly", "avoid humanity"], "answer": 0, "metadata": {"id": "11-485", "split": "train", "negation_rule": "not/because"}}
{"question": "All the water vanishes from a small depression basked in sunlight on a paved road not because of", "choices": ["evaporation", "condensation"], "answer": 1, "metadata": {"id": "10-399", "split": "train", "negation_rule": "not/because"}}
{"question": "Sandbars are a part of most seas not because there are", "choices": ["places where fish eat", "waves which adjust silt"], "answer": 0, "metadata": {"id": "7-293", "split": "train", "negation_rule": "not/because"}}
{"question": "A barracuda will be able to raise its own offspring not because", "choices": ["it is alive", "it is troubled"], "answer": 1, "metadata": {"id": "11-251", "split": "train", "negation_rule": "not/because"}}
{"question": "Frogs withstand noisy areas easily when they eat insects not because they have", "choices": ["problems jumping", "zero eardrums"], "answer": 0, "metadata": {"id": "11-511", "split": "train", "negation_rule": "not/because"}}
{"question": "If you're stuck outside on a sunny day, the coolest place would be under a tree not because they do what to the sunlight", "choices": ["block it out", "sell it"], "answer": 1, "metadata": {"id": "13-9", "split": "train", "negation_rule": "not/because"}}
{"question": "Milk sold in supermarkets is pasteurized not because", "choices": ["all raw milk is safe", "to keep bacteria from getting into the milk after the customer buys it"], "answer": 0, "metadata": {"id": "14-756", "split": "train", "negation_rule": "not/because"}}
{"question": "There are very few species of plants and animals in places like the North Pole not because the temperatures are always very", "choices": ["low", "muggy"], "answer": 1, "metadata": {"id": "8-485", "split": "train", "negation_rule": "not/because"}}
{"question": "As a soccer ball goes flying through the air, the person watching it knows that the reason is not because", "choices": ["everything is aerial", "exerting occurred"], "answer": 0, "metadata": {"id": "14-443", "split": "train", "negation_rule": "not/because"}}
{"question": "Jane's hat flew off her head while standing still on a hilltop. This could be not because", "choices": ["there was uneven heating of the ground", "her head blew the hat off"], "answer": 1, "metadata": {"id": "11-741", "split": "train", "negation_rule": "not/because"}}
{"question": "All the deer in one area moved away. This could be not because", "choices": ["The deer went for a walk and got lost", "all the trees had died from disease and fell down"], "answer": 0, "metadata": {"id": "9-753", "split": "dev", "negation_rule": "not/because"}}
{"question": "The hamster was malnourished not because", "choices": ["There was a depletion in the corn supply", "It was waiting for the key to get the food"], "answer": 1, "metadata": {"id": "9-863", "split": "train", "negation_rule": "not/because"}}
{"question": "A boy is standing in the bathroom brushing his teeth, but the lights are off in the bathroom. However, his room is next to the bathroom and his bedroom light is on. The bathroom is still bright, not because the mirror reflects", "choices": ["light from the bathroom", "light from the bedroom"], "answer": 0, "metadata": {"id": "8-313", "split": "train", "negation_rule": "not/because"}}
{"question": "A herd of cattle is slowly making its way through a large field. The shepherd realizes that he forgot to bring grain for the cattle, yet the cattle will survive just fine in the field, not because", "choices": ["they eat roughage", "they eat insects"], "answer": 1, "metadata": {"id": "8-427", "split": "train", "negation_rule": "not/because"}}
{"question": "I have to plug in a processor of food not because it", "choices": ["is a battery operated machine", "is an electric Motor"], "answer": 0, "metadata": {"id": "8-8", "split": "train", "negation_rule": "not/because"}}
{"question": "The dust bowl happened not because of", "choices": ["unsustainable farming practice", "sweeping reform"], "answer": 1, "metadata": {"id": "14-677", "split": "train", "negation_rule": "not/because"}}
{"question": "A car drives right past the gas station not because it's motor is", "choices": ["coal", "electric"], "answer": 0, "metadata": {"id": "7-220", "split": "train", "negation_rule": "not/because"}}
{"question": "A tortoise died many years ago, but it is easy to tell that what was left behind was from a tortoise not because in the rock there are", "choices": ["skeletal system", "muscles"], "answer": 1, "metadata": {"id": "10-226", "split": "train", "negation_rule": "not/because"}}
{"question": "A river can push tin cans down the path of the water not because", "choices": ["it is loud", "it has motion"], "answer": 0, "metadata": {"id": "7-1156", "split": "train", "negation_rule": "not/because"}}
{"question": "A strawberry is in zero way a true berry not because it", "choices": ["has seeds outside the flesh, unlike the blueberry", "is too wet inside"], "answer": 1, "metadata": {"id": "7-289", "split": "dev", "negation_rule": "not/because"}}
{"question": "An island can sprout up from seemingly suddenly not because", "choices": ["underwater volcanoes are invisible", "underwater volcanoes are hidden"], "answer": 0, "metadata": {"id": "7-524", "split": "dev", "negation_rule": "not/because"}}
{"question": "Tungsten is a metal which is found in large amounts in filaments, which are used in incandescent light bulbs. These light bulbs work not because", "choices": ["the filament glows warmly", "light bulbs get very warm"], "answer": 1, "metadata": {"id": "8-416", "split": "train", "negation_rule": "not/because"}}
{"question": "Cars are big polluters not because they release toxins from the gas into the air making it", "choices": ["space", "unhealthy to breathe"], "answer": 0, "metadata": {"id": "14-239", "split": "train", "negation_rule": "not/because"}}
{"question": "Geese fly south for the winter not because", "choices": ["of instinct", "their following orders"], "answer": 1, "metadata": {"id": "12-99", "split": "train", "negation_rule": "not/because"}}
{"question": "A man grows flowers in the winter using his greenhouse. The flowers blossom there, despite the cold, freezing weather and lack of sunshine, not because", "choices": ["they are regularly chilled", "they are carefully protected"], "answer": 0, "metadata": {"id": "8-372", "split": "dev", "negation_rule": "not/because"}}
{"question": "A person wants to discover how much time they've spent on something, so when they think about data, they don't need to", "choices": ["accumulate it", "lose it"], "answer": 1, "metadata": {"id": "11-360", "split": "train", "negation_rule": "not/do"}}
{"question": "After a week of storms, the nearby lake now doesn't have more", "choices": ["birds", "liquid"], "answer": 0, "metadata": {"id": "10-593", "split": "train", "negation_rule": "not/do"}}
{"question": "In order to play with a beach ball, you do not need to fill it with", "choices": ["a gaseous substance", "with oil"], "answer": 1, "metadata": {"id": "14-752", "split": "train", "negation_rule": "not/do"}}
{"question": "Predators do not eat", "choices": ["humans", "bunnies"], "answer": 0, "metadata": {"id": "880", "split": "test", "negation_rule": "not/do"}}
{"question": "A lack of water doesn't have a direct connection on the amount of available", "choices": ["sustenance", "shelters"], "answer": 1, "metadata": {"id": "10-297", "split": "train", "negation_rule": "not/do"}}
{"question": "plants do not gather their nutrients from the", "choices": ["store", "area under grass"], "answer": 0, "metadata": {"id": "9-55", "split": "train", "negation_rule": "not/do"}}
{"question": "Thermal conduction does not occur when", "choices": ["I leave a log poker in the fire", "I sit down on a bed"], "answer": 1, "metadata": {"id": "8-4", "split": "train", "negation_rule": "not/do"}}
{"question": "Hummingbirds do not contribute to seed dispersal by", "choices": ["eating pizza", "consuming flower sustenance"], "answer": 0, "metadata": {"id": "12-453", "split": "train", "negation_rule": "not/do"}}
{"question": "Bird dogs don't use their nose to find", "choices": ["water foul", "your keys"], "answer": 1, "metadata": {"id": "12-793", "split": "train", "negation_rule": "not/do"}}
{"question": "transplanting seedling oaks doesn't have a positive impact on", "choices": ["the economy", "the environment"], "answer": 0, "metadata": {"id": "9-416", "split": "test", "negation_rule": "not/do"}}
{"question": "Sea horses do not require", "choices": ["the sun", "jockeys"], "answer": 1, "metadata": {"id": "10-869", "split": "train", "negation_rule": "not/do"}}
{"question": "Skittles left in snow do not become", "choices": ["mushy", "hard"], "answer": 0, "metadata": {"id": "13-985", "split": "train", "negation_rule": "not/do"}}
{"question": "If plants are going to grow, their seeds do not need to", "choices": ["travel elsewhere", "be washed"], "answer": 1, "metadata": {"id": "7-856", "split": "train", "negation_rule": "not/do"}}
{"question": "Eyes do not allow humans", "choices": ["detect acrid odors in the air", "to detect when a traffic light changes"], "answer": 0, "metadata": {"id": "8-135", "split": "test", "negation_rule": "not/do"}}
{"question": "During a sandstorm, a bird does not look for a", "choices": ["bush", "worm"], "answer": 1, "metadata": {"id": "325", "split": "train", "negation_rule": "not/do"}}
{"question": "a carpenter ant does not require energy for", "choices": ["patience", "growth"], "answer": 0, "metadata": {"id": "10-379", "split": "train", "negation_rule": "not/do"}}
{"question": "Grow lamps don't provide artificial sun to", "choices": ["succulents", "dogs"], "answer": 1, "metadata": {"id": "12-698", "split": "train", "negation_rule": "not/do"}}
{"question": "adding a direct flame to container of acid doesn't cause a", "choices": ["lot of nothing", "vapor expulsion"], "answer": 0, "metadata": {"id": "8-286", "split": "train", "negation_rule": "not/do"}}
{"question": "Slate probably didn't form", "choices": ["deep within the earth", "on top of a glacier"], "answer": 1, "metadata": {"id": "10-702", "split": "train", "negation_rule": "not/do"}}
{"question": "The skeletal system doesn't protect the", "choices": ["ears", "stomach"], "answer": 0, "metadata": {"id": "12-1188", "split": "train", "negation_rule": "not/do"}}
{"question": "Diverting overflow from a reservoir through pipes does not generate", "choices": ["hydropower", "solar power"], "answer": 1, "metadata": {"id": "10-1084", "split": "train", "negation_rule": "not/do"}}
{"question": "Humans don't grow thinner when they", "choices": ["eat food", "lack food"], "answer": 0, "metadata": {"id": "828", "split": "train", "negation_rule": "not/do"}}
{"question": "The floating arrow on a compass always doesn't point away from the", "choices": ["south", "west"], "answer": 1, "metadata": {"id": "13-613", "split": "train", "negation_rule": "not/do"}}
{"question": "Some fields don't house incredible creatures such as", "choices": ["lions", "large rabbits"], "answer": 0, "metadata": {"id": "7-1083", "split": "train", "negation_rule": "not/do"}}
{"question": "Where various seasons currently take place doesn't depend upon", "choices": ["the globe's turning", "the globe's size"], "answer": 1, "metadata": {"id": "11-705", "split": "train", "negation_rule": "not/do"}}
{"question": "Some people do not have an", "choices": ["snakes for hair", "extra rib"], "answer": 0, "metadata": {"id": "14-1213", "split": "train", "negation_rule": "not/do"}}
{"question": "Birds carrying away fruit doesn't have what kind of impact on the plant", "choices": ["positive", "negative"], "answer": 1, "metadata": {"id": "12-583", "split": "train", "negation_rule": "not/do"}}
{"question": "the moon's surface doesn't contain many", "choices": ["smoothies", "ground bumps"], "answer": 0, "metadata": {"id": "13-575", "split": "train", "negation_rule": "not/do"}}
{"question": "A skin bacterium does not lose its habitat when", "choices": ["you cut off your finger nails", "you eat pepperoni pizza"], "answer": 1, "metadata": {"id": "10-396", "split": "train", "negation_rule": "not/do"}}
{"question": "Japan didn't make Pearl Harbor", "choices": ["boring and empty", "it's victim"], "answer": 0, "metadata": {"id": "13-700", "split": "train", "negation_rule": "not/do"}}
{"question": "After evaporation water does not become", "choices": ["snow", "ice caps"], "answer": 1, "metadata": {"id": "1764", "split": "dev", "negation_rule": "not/do"}}
{"question": "Muscles don't move bones to produce movement like when", "choices": ["arms are resting", "toes are wiggled"], "answer": 0, "metadata": {"id": "7-444", "split": "test", "negation_rule": "not/do"}}
{"question": "In December, someone in England probably does not want to", "choices": ["Wear heavy clothing when outdoors", "Start planting seeds in their garden"], "answer": 1, "metadata": {"id": "13-173", "split": "train", "negation_rule": "not/do"}}
{"question": "If a deer eats a berry plant, the plant does not eat", "choices": ["small bugs that glow", "its self created nutriment"], "answer": 0, "metadata": {"id": "12-851", "split": "train", "negation_rule": "not/do"}}
{"question": "little balls of H2O on the inside of a closed window didn't come from", "choices": ["condensed water", "rain"], "answer": 1, "metadata": {"id": "13-405", "split": "train", "negation_rule": "not/do"}}
{"question": "A woman notices that she is depressed every autumn, and wonders why. A friend suggests to her that perhaps certain changes that take place as seasons move from warm to cold may be having an effect on her. When pressed for an example of these changes, the friend doesn't cite", "choices": ["flowers blooming", "grass turning brown"], "answer": 0, "metadata": {"id": "8-445", "split": "test", "negation_rule": "not/do"}}
{"question": "Water doesn't evaporate less", "choices": ["in a basement", "on a hot street"], "answer": 1, "metadata": {"id": "89", "split": "train", "negation_rule": "not/do"}}
{"question": "the earth's tilt doesn't control the", "choices": ["clocks", "seasons"], "answer": 0, "metadata": {"id": "8-283", "split": "train", "negation_rule": "not/do"}}
{"question": "Relocating a stalled vehicle does not require a lot of", "choices": ["force", "slopes"], "answer": 1, "metadata": {"id": "14-28", "split": "train", "negation_rule": "not/do"}}
{"question": "H2O does not allow for the conduction of", "choices": ["people", "electrical potential"], "answer": 0, "metadata": {"id": "10-100", "split": "train", "negation_rule": "not/do"}}
{"question": "In December in the northern hemisphere you don't need", "choices": ["mittens", "cooling fans"], "answer": 1, "metadata": {"id": "14-159", "split": "train", "negation_rule": "not/do"}}
{"question": "Adding milk to a hot pan does not create", "choices": ["water", "curds"], "answer": 0, "metadata": {"id": "13-49", "split": "train", "negation_rule": "not/do"}}
{"question": "Glaciers do not have", "choices": ["slow, hidden rivers", "emotions"], "answer": 1, "metadata": {"id": "13-1048", "split": "train", "negation_rule": "not/do"}}
{"question": "If a day has passed, so does not have", "choices": ["most of a year", "most of thirty hours"], "answer": 0, "metadata": {"id": "12-421", "split": "train", "negation_rule": "not/do"}}
{"question": "Cameras don't reflect", "choices": ["UV rays", "the stars"], "answer": 1, "metadata": {"id": "10-1166", "split": "train", "negation_rule": "not/do"}}
{"question": "Storms do not lead to", "choices": ["an increase in water temperature", "an uptick in local ponds water level"], "answer": 0, "metadata": {"id": "1578", "split": "dev", "negation_rule": "not/do"}}
{"question": "plant does not require what for photosynthesis", "choices": ["light from our closest star", "the reflection of something shiny"], "answer": 1, "metadata": {"id": "9-472", "split": "dev", "negation_rule": "not/do"}}
{"question": "If a person doesn't want to decrease their risk of experiencing flooding", "choices": ["they would live in a flood plain", "they would live on a mountaintop"], "answer": 0, "metadata": {"id": "7-607", "split": "train", "negation_rule": "not/do"}}
{"question": "a switch does not turn something with a power source on because:", "choices": ["a piece of copper closes the circuit", "the circuit is opened"], "answer": 1, "metadata": {"id": "10-70", "split": "train", "negation_rule": "not/do"}}
{"question": "animals don't learn some behaviors from watching their", "choices": ["trees", "caretakers"], "answer": 0, "metadata": {"id": "13-414", "split": "train", "negation_rule": "not/do"}}
{"question": "Ground does not have", "choices": ["elements", "common understanding"], "answer": 1, "metadata": {"id": "13-938", "split": "train", "negation_rule": "not/do"}}
{"question": "Trees don't take in CO2 from the atmosphere for", "choices": ["fun", "synthesizing food"], "answer": 0, "metadata": {"id": "12-1095", "split": "train", "negation_rule": "not/do"}}
{"question": "a decline in the number of predators often does not lead to", "choices": ["a rise in the number of prey", "a decrease in breeding between prey"], "answer": 1, "metadata": {"id": "14-134", "split": "train", "negation_rule": "not/do"}}
{"question": "The respiratory system doesn't allow the body to", "choices": ["remove oxygen from the blood", "oxygenate blood from the air"], "answer": 0, "metadata": {"id": "7-1039", "split": "dev", "negation_rule": "not/do"}}
{"question": "Pasteurization does not reduce the amount of bacteria in", "choices": ["cheddar cheese", "orange juice"], "answer": 1, "metadata": {"id": "9-634", "split": "dev", "negation_rule": "not/do"}}
{"question": "Thick feathers do not come in handy for birds", "choices": ["that live in warm climates", "that live in frigid climates"], "answer": 0, "metadata": {"id": "7-253", "split": "train", "negation_rule": "not/do"}}
{"question": "A leaf falling from a tree does not mean", "choices": ["I should wear a coat", "I should wear sandals"], "answer": 1, "metadata": {"id": "9-22", "split": "dev", "negation_rule": "not/do"}}
{"question": "Miles above the equator, people from several faiths do not celebrate holidays in", "choices": ["warm months", "cool months"], "answer": 0, "metadata": {"id": "10-120", "split": "train", "negation_rule": "not/do"}}
{"question": "A person wants to dry their clothes for work. They seek out some energy that can be continuously gotten without running out, so they don't dry clothes using", "choices": ["the sun", "the water"], "answer": 1, "metadata": {"id": "11-623", "split": "train", "negation_rule": "not/do"}}
{"question": "Green parts of a life form don't absorb", "choices": ["oxygen", "light"], "answer": 0, "metadata": {"id": "898", "split": "test", "negation_rule": "not/do"}}
{"question": "A farmer wants to plant seeds, but first needs a field with soil. There is a field with pebbles, which don't have potential to become soil after experiencing", "choices": ["time's passage", "gentle singing"], "answer": 1, "metadata": {"id": "11-107", "split": "train", "negation_rule": "not/do"}}
{"question": "all cells do not use cellular respiration to", "choices": ["perform meiosis", "release waste"], "answer": 0, "metadata": {"id": "9-1134", "split": "test", "negation_rule": "not/do"}}
{"question": "Compost, small rocks, and organic material do not make up", "choices": ["land", "air"], "answer": 1, "metadata": {"id": "10-1154", "split": "train", "negation_rule": "not/do"}}
{"question": "Recycling old cars doesn't have a positive impact on", "choices": ["human life span.", "conservation of metal"], "answer": 0, "metadata": {"id": "864", "split": "train", "negation_rule": "not/do"}}
{"question": "Rain doesn't help", "choices": ["communities thrive", "candy"], "answer": 1, "metadata": {"id": "10-473", "split": "train", "negation_rule": "not/do"}}
{"question": "A microscope does not create clarity by", "choices": ["acceleration", "augmentation"], "answer": 0, "metadata": {"id": "12-193", "split": "train", "negation_rule": "not/do"}}
{"question": "Flashlights don't require batteries", "choices": ["to properly illuminate objects", "to meet weight requirements"], "answer": 1, "metadata": {"id": "7-1137", "split": "train", "negation_rule": "not/do"}}
{"question": "Animals don't have more fat", "choices": ["in human homes", "in polar areas"], "answer": 0, "metadata": {"id": "676", "split": "test", "negation_rule": "not/do"}}
{"question": "what doesn't characterize a cycle", "choices": ["a steady recurrence", "none of these"], "answer": 1, "metadata": {"id": "7-178", "split": "train", "negation_rule": "not/do"}}
{"question": "A person wants to collect green slime, so they do not seek out", "choices": ["dry bones", "damp gutters"], "answer": 0, "metadata": {"id": "11-277", "split": "train", "negation_rule": "not/do"}}
{"question": "A rainy environment doesn't result in", "choices": ["more overcast days", "a dry environment"], "answer": 1, "metadata": {"id": "1404", "split": "train", "negation_rule": "not/do"}}
{"question": "Magnifying does not make it easier to see a", "choices": ["whale", "shrimp"], "answer": 0, "metadata": {"id": "8-145", "split": "train", "negation_rule": "not/do"}}
{"question": "Communities don't contain", "choices": ["a diverse selection of living beings", "sparse flora and fauna"], "answer": 1, "metadata": {"id": "8-317", "split": "train", "negation_rule": "not/do"}}
{"question": "Breaking a vase doesn't change its", "choices": ["speed", "shape and mass"], "answer": 0, "metadata": {"id": "9-1189", "split": "train", "negation_rule": "not/do"}}
{"question": "which of these don't need to be present for a tectonic plate movement", "choices": ["a crack in the core", "an ocean with fish"], "answer": 1, "metadata": {"id": "12-911", "split": "train", "negation_rule": "not/do"}}
{"question": "A producer doesn't produce it's own", "choices": ["heartbeat", "nourishment"], "answer": 0, "metadata": {"id": "14-290", "split": "train", "negation_rule": "not/do"}}
{"question": "Rainbows don't need", "choices": ["sun and some drizzle", "leprechauns and pots of gold"], "answer": 1, "metadata": {"id": "1570", "split": "train", "negation_rule": "not/do"}}
{"question": "A tiny sand particle didn't come from", "choices": ["boiling water", "larger mineral chunks"], "answer": 0, "metadata": {"id": "10-466", "split": "train", "negation_rule": "not/do"}}
{"question": "Sycamores don't have the worlds largest", "choices": ["trunk", "friends"], "answer": 1, "metadata": {"id": "14-828", "split": "train", "negation_rule": "not/do"}}
{"question": "Humans do not contribute to environmental pollution", "choices": ["by purchasing products made from recycled products", "by leaving behind refuse on public beaches"], "answer": 0, "metadata": {"id": "1299", "split": "train", "negation_rule": "not/do"}}
{"question": "recycling doesn't have a positive impact on the", "choices": ["surrounding creature homes", "rocks"], "answer": 1, "metadata": {"id": "13-782", "split": "train", "negation_rule": "not/do"}}
{"question": "Squirrels do not stay busy in the autumn", "choices": ["planting flowers", "amassing pecans"], "answer": 0, "metadata": {"id": "9-581", "split": "train", "negation_rule": "not/do"}}
{"question": "Hummingbirds do not take what with them", "choices": ["Pollen", "energy"], "answer": 1, "metadata": {"id": "1302", "split": "train", "negation_rule": "not/do"}}
{"question": "The cell membrane doesn't keep a cell from", "choices": ["running away", "falling apart"], "answer": 0, "metadata": {"id": "9-904", "split": "dev", "negation_rule": "not/do"}}
{"question": "feeders don't attract animals to a", "choices": ["nearby spot", "volcano"], "answer": 1, "metadata": {"id": "13-950", "split": "train", "negation_rule": "not/do"}}
{"question": "Rabbits do not consume", "choices": ["verdant monkeys that swing from the trees", "verdant organisms that grow from the ground"], "answer": 0, "metadata": {"id": "1686", "split": "dev", "negation_rule": "not/do"}}
{"question": "Birds do not reproduce using", "choices": ["eggs", "live birth"], "answer": 1, "metadata": {"id": "851", "split": "dev", "negation_rule": "not/do"}}
{"question": "amphibians don't hatch from", "choices": ["trees", "calcium life pods"], "answer": 0, "metadata": {"id": "13-963", "split": "train", "negation_rule": "not/do"}}
{"question": "When eagles are hunting in a field, some of their nutrients do not come from", "choices": ["rodents", "deer"], "answer": 1, "metadata": {"id": "7-834", "split": "train", "negation_rule": "not/do"}}
{"question": "Marbles in the right light do not make", "choices": ["thee channel change", "rainbows"], "answer": 0, "metadata": {"id": "13-607", "split": "train", "negation_rule": "not/do"}}
{"question": "A satellite does not orbit a", "choices": ["terrestrial body", "ocean"], "answer": 1, "metadata": {"id": "9-436", "split": "test", "negation_rule": "not/do"}}
{"question": "positively do not impact your bodies strength by", "choices": ["singing", "dead-lifting"], "answer": 0, "metadata": {"id": "10-449", "split": "train", "negation_rule": "not/do"}}
{"question": "After extensive logging activity, a forest did not have less", "choices": ["biodiversity", "carbon dioxide"], "answer": 1, "metadata": {"id": "1187", "split": "train", "negation_rule": "not/do"}}
{"question": "Someone doesn't stop living when", "choices": ["They eat disgusting food", "They are without air"], "answer": 0, "metadata": {"id": "13-382", "split": "train", "negation_rule": "not/do"}}
{"question": "A fan does not push air with", "choices": ["rotating flat surface", "straw"], "answer": 1, "metadata": {"id": "10-138", "split": "train", "negation_rule": "not/do"}}
{"question": "Kelp does not have to have provisions to", "choices": ["hibernate", "maintain life"], "answer": 0, "metadata": {"id": "12-1027", "split": "train", "negation_rule": "not/do"}}
{"question": "seasons do not change due to the earth's", "choices": ["degree of angle", "weather"], "answer": 1, "metadata": {"id": "9-21", "split": "train", "negation_rule": "not/do"}}
{"question": "A man wants to use a material in a project that will be nonrenewable. The man doesn't decide to use", "choices": ["grass", "solo cups"], "answer": 0, "metadata": {"id": "9-740", "split": "dev", "negation_rule": "not/do"}}
{"question": "Someone wants their electromagnets to work, but is having difficulty powering them. In order to make them work, they don't need to", "choices": ["run a continuous current", "run around the wire"], "answer": 1, "metadata": {"id": "8-97", "split": "test", "negation_rule": "not/do"}}
{"question": "Compared to an area with farmland, an area with housing developments does not have more", "choices": ["crops", "light pollution"], "answer": 0, "metadata": {"id": "10-581", "split": "train", "negation_rule": "not/do"}}
{"question": "A crowd-source worker wants to track when a certain task drops. They would not", "choices": ["use a notebook", "randomly play tracks"], "answer": 1, "metadata": {"id": "13-1025", "split": "train", "negation_rule": "not/modal"}}
{"question": "A good mixture would not be", "choices": ["water and olive oil", "coffee and almond creamer"], "answer": 0, "metadata": {"id": "13-615", "split": "train", "negation_rule": "not/modal"}}
{"question": "A bass may not make its home", "choices": ["in a liquid", "in a field"], "answer": 1, "metadata": {"id": "10-1107", "split": "train", "negation_rule": "not/modal"}}
{"question": "The cracks in a sidewalk couldn't be caused by", "choices": ["emotions", "Pine"], "answer": 0, "metadata": {"id": "12-321", "split": "train", "negation_rule": "not/modal"}}
{"question": "Trembling muscles spasms in animals can not be caused in party by", "choices": ["temperature in single digits", "being unaware of the temperature"], "answer": 1, "metadata": {"id": "7-940", "split": "train", "negation_rule": "not/modal"}}
{"question": "A person can not inflate a beach ball using", "choices": ["a salt shaker", "organ processed gas"], "answer": 0, "metadata": {"id": "11-362", "split": "train", "negation_rule": "not/modal"}}
{"question": "A person wants to turn on their fan to cool down their room. In order to do this, they won't have to", "choices": ["plug it in", "spin a wire"], "answer": 1, "metadata": {"id": "9-101", "split": "dev", "negation_rule": "not/modal"}}
{"question": "Replacing a natural resource can not be", "choices": ["planting a berry patch", "refilling a lake that evaporated"], "answer": 0, "metadata": {"id": "7-936", "split": "train", "negation_rule": "not/modal"}}
{"question": "A cow will not gain energy from eating", "choices": ["dandelions", "birds"], "answer": 1, "metadata": {"id": "11-587", "split": "train", "negation_rule": "not/modal"}}
{"question": "If a deer is unable to eat regularly, or only eats that which lacks essential minerals, the deer may not", "choices": ["fail to gestate", "experience failing health"], "answer": 0, "metadata": {"id": "7-76", "split": "train", "negation_rule": "not/modal"}}
{"question": "If a person is searching for others in a forest at night, they can't signal quietly to each other by", "choices": ["flicking a lighter", "sleeping quietly"], "answer": 1, "metadata": {"id": "12-263", "split": "train", "negation_rule": "not/modal"}}
{"question": "Which will not take the longest to reach a boiling point", "choices": ["bath tub", "swimming pool"], "answer": 0, "metadata": {"id": "13-860", "split": "train", "negation_rule": "not/modal"}}
{"question": "An anemometer would not get a work out on a", "choices": ["blustery day", "cloudy day"], "answer": 1, "metadata": {"id": "9-455", "split": "dev", "negation_rule": "not/modal"}}
{"question": "A penguin, while a bird, would not avoid living in", "choices": ["a frozen habitat", "a native forest"], "answer": 0, "metadata": {"id": "10-252", "split": "train", "negation_rule": "not/modal"}}
{"question": "An electron microscope can't look at", "choices": ["my common cold", "an elephant"], "answer": 1, "metadata": {"id": "12-1000", "split": "train", "negation_rule": "not/modal"}}
{"question": "If a screwdriver is bought from a high end store known for high quality, it won't most likely end up", "choices": ["with rotting wood this week", "passed down from parent to child"], "answer": 0, "metadata": {"id": "12-863", "split": "train", "negation_rule": "not/modal"}}
{"question": "If I wanted to maintain energy I couldn't", "choices": ["leisure nap", "Jump for hours"], "answer": 1, "metadata": {"id": "13-7", "split": "train", "negation_rule": "not/modal"}}
{"question": "Taking a fingernail and pressing it to salt will not show", "choices": ["it is salty", "it is malleable"], "answer": 0, "metadata": {"id": "7-207", "split": "dev", "negation_rule": "not/modal"}}
{"question": "trees won't grow from", "choices": ["hack berries", "rocks"], "answer": 1, "metadata": {"id": "12-196", "split": "train", "negation_rule": "not/modal"}}
{"question": "Which of the following wouldn't be insulated", "choices": ["a statically charged shirt", "a beehive covered in wax"], "answer": 0, "metadata": {"id": "11-124", "split": "train", "negation_rule": "not/modal"}}
{"question": "A glass of water can't undergo a chemical change by adding", "choices": ["a cup of salt", "a cup of ice"], "answer": 1, "metadata": {"id": "9-429", "split": "test", "negation_rule": "not/modal"}}
{"question": "Dozens in your workplace are sick with the flu. To protect yourself, you might not", "choices": ["Inject yourself with a healthy person's blood", "inject yourself with deactivated elements of the illness"], "answer": 0, "metadata": {"id": "13-538", "split": "train", "negation_rule": "not/modal"}}
{"question": "A flashlight won't need this in order to radiate photons:", "choices": ["electron flow", "acoustic energy"], "answer": 1, "metadata": {"id": "9-893", "split": "test", "negation_rule": "not/modal"}}
{"question": "audible vibrations can't travel freely through", "choices": ["the ground", "nitrogen and oxygen"], "answer": 0, "metadata": {"id": "10-400", "split": "train", "negation_rule": "not/modal"}}
{"question": "If a snail is heated to the point of being burned, the snail won't", "choices": ["be discomforted", "be hungry"], "answer": 1, "metadata": {"id": "7-513", "split": "train", "negation_rule": "not/modal"}}
{"question": "A plastic bag is filled with milk and is placed in a chest. The chest has a device which takes all of the warm air away, so eventually, the milk will not", "choices": ["melt", "be solid"], "answer": 0, "metadata": {"id": "10-1130", "split": "train", "negation_rule": "not/modal"}}
{"question": "Two birds in completely different houses can't discuss something by", "choices": ["vocalizing", "sitting"], "answer": 1, "metadata": {"id": "12-515", "split": "train", "negation_rule": "not/modal"}}
{"question": "If a person blows on another person's arm, then nerves won't", "choices": ["make more nerves in that area", "alert the brain of this"], "answer": 0, "metadata": {"id": "13-332", "split": "train", "negation_rule": "not/modal"}}
{"question": "Putting a cardboard box in a bin instead of the trash can not", "choices": ["reduce the height of landfills", "keep it from the trash"], "answer": 1, "metadata": {"id": "7-950", "split": "train", "negation_rule": "not/modal"}}
{"question": "There are nutrients in dirt, like magnesium, and those nutrients may not be", "choices": ["poisoned", "collected into vegetation"], "answer": 0, "metadata": {"id": "9-423", "split": "train", "negation_rule": "not/modal"}}
{"question": "These wouldn't likely be broken down and recycled", "choices": ["pallets", "waste hydrogen"], "answer": 1, "metadata": {"id": "13-880", "split": "train", "negation_rule": "not/modal"}}
{"question": "Which of these might not use plants for an energy source", "choices": ["toy car", "station wagon"], "answer": 0, "metadata": {"id": "13-609", "split": "train", "negation_rule": "not/modal"}}
{"question": "Sweating will not make your body temperature go", "choices": ["down", "Sideways"], "answer": 1, "metadata": {"id": "12-746", "split": "train", "negation_rule": "not/modal"}}
{"question": "A puppy wakes up and needs to to for a walk. In order to have the ability to do this, he will not require", "choices": ["toys", "lunch"], "answer": 0, "metadata": {"id": "10-825", "split": "train", "negation_rule": "not/modal"}}
{"question": "If a plant is in an environment with a lot of oxygen, and then oxygen levels very slightly drop, the plant won't", "choices": ["calibrate", "understand"], "answer": 1, "metadata": {"id": "12-45", "split": "train", "negation_rule": "not/modal"}}
{"question": "Quartz can't very easily damage", "choices": ["diamonds", "smelted silica"], "answer": 0, "metadata": {"id": "10-803", "split": "train", "negation_rule": "not/modal"}}
{"question": "What can't you find in a forest", "choices": ["remedies", "Hogwarts"], "answer": 1, "metadata": {"id": "9-1159", "split": "dev", "negation_rule": "not/modal"}}
{"question": "A person seeking out natural resources would not start looking", "choices": ["in a spaceship", "in a pond"], "answer": 0, "metadata": {"id": "11-131", "split": "train", "negation_rule": "not/modal"}}
{"question": "If an organism is a living thing, it won't always", "choices": ["respirate", "cry"], "answer": 1, "metadata": {"id": "10-394", "split": "train", "negation_rule": "not/modal"}}
{"question": "Which would not likely be a chemical reaction", "choices": ["play dog", "an ember"], "answer": 0, "metadata": {"id": "12-633", "split": "train", "negation_rule": "not/modal"}}
{"question": "More butterflies will not come as buttercups become more", "choices": ["ripe", "social media friendly"], "answer": 1, "metadata": {"id": "14-619", "split": "train", "negation_rule": "not/modal"}}
{"question": "Omnivores wouldn't dine on", "choices": ["only that which grows from the ground", "leafy greens and steak"], "answer": 0, "metadata": {"id": "12-250", "split": "train", "negation_rule": "not/modal"}}
{"question": "An elephant on the plains and a diamondback in the desert won't receive", "choices": ["different amounts of precipitation", "zero amounts of precipitation"], "answer": 1, "metadata": {"id": "10-734", "split": "train", "negation_rule": "not/modal"}}
{"question": "With the addition of thrusters your forward momentum will not", "choices": ["decrease", "increase"], "answer": 0, "metadata": {"id": "14-709", "split": "train", "negation_rule": "not/modal"}}
{"question": "We might not use our carbon dioxide waste to", "choices": ["feed roses", "feed cats"], "answer": 1, "metadata": {"id": "12-748", "split": "train", "negation_rule": "not/modal"}}
{"question": "If a tree burns down, it can not be made right by", "choices": ["buying a plastic tree", "placing seed in dirt"], "answer": 0, "metadata": {"id": "7-640", "split": "dev", "negation_rule": "not/modal"}}
{"question": "Tectonic expression can't give massive amounts of data to a", "choices": ["seismograph", "lie detector"], "answer": 1, "metadata": {"id": "10-469", "split": "train", "negation_rule": "not/modal"}}
{"question": "A source of heat couldn't be", "choices": ["a snowflake", "holding hands"], "answer": 0, "metadata": {"id": "10-52", "split": "train", "negation_rule": "not/modal"}}
{"question": "An example of an electric insulator could not be", "choices": ["tupperware", "orange juice"], "answer": 1, "metadata": {"id": "14-918", "split": "train", "negation_rule": "not/modal"}}
{"question": "A large source of heat can't be seen in the", "choices": ["cave", "sky"], "answer": 0, "metadata": {"id": "11-44", "split": "train", "negation_rule": "not/modal"}}
{"question": "If a house is built using a raw material, it can not be built with", "choices": ["branches", "Styrofoam"], "answer": 1, "metadata": {"id": "13-61", "split": "train", "negation_rule": "not/modal"}}
{"question": "If a person is running a salad bar and needs to keep the bar cold, and therefore the ice frozen, they might not", "choices": ["melt the ice on a stove", "pour sodium over the ice"], "answer": 0, "metadata": {"id": "13-735", "split": "train", "negation_rule": "not/modal"}}
{"question": "It wouldn't be harder to grow a palm tree in", "choices": ["Idaho", "Arizona"], "answer": 1, "metadata": {"id": "1193", "split": "dev", "negation_rule": "not/modal"}}
{"question": "A herd of deer may not be forced to search for a new home if", "choices": ["more babies are born in the spring", "resources in an area become too few to maintain the herd"], "answer": 0, "metadata": {"id": "7-820", "split": "train", "negation_rule": "not/modal"}}
{"question": "To discover how durable a certain mineral may be, one couldn't", "choices": ["attempt to leave a mark on it", "melt it down and pour"], "answer": 1, "metadata": {"id": "10-877", "split": "train", "negation_rule": "not/modal"}}
{"question": "A landslide may not bring immense problems to", "choices": ["Jupiter", "living regions"], "answer": 0, "metadata": {"id": "12-983", "split": "train", "negation_rule": "not/modal"}}
{"question": "A boy wants to use his Walkman so that he can listen to some music. When he tries to turn it on, it us unable to, and the boy realizes that he won't need", "choices": ["lithium-ion", "heat"], "answer": 1, "metadata": {"id": "8-130", "split": "test", "negation_rule": "not/modal"}}
{"question": "A lake, pond, or stream can't all be used to", "choices": ["make extra food", "collect fluid from"], "answer": 0, "metadata": {"id": "9-615", "split": "dev", "negation_rule": "not/modal"}}
{"question": "You wouldn't use a lever to move a", "choices": ["safe", "feather"], "answer": 1, "metadata": {"id": "12-669", "split": "train", "negation_rule": "not/modal"}}
{"question": "A footprint in a rock may not have been from", "choices": ["new rock formation", "very long ago"], "answer": 0, "metadata": {"id": "7-824", "split": "train", "negation_rule": "not/modal"}}
{"question": "Another source of pollution may not be", "choices": ["throwing things in the ocean", "biking instead of driving the car"], "answer": 1, "metadata": {"id": "10-613", "split": "train", "negation_rule": "not/modal"}}
{"question": "As rabbits in a county die off, foxes won't", "choices": ["eat trees", "do the same"], "answer": 0, "metadata": {"id": "11-61", "split": "train", "negation_rule": "not/modal"}}
{"question": "A deer may be hungry and malnourished. In order to rectify this, the deer may not", "choices": ["consume dandelions", "eat other deer"], "answer": 1, "metadata": {"id": "10-6", "split": "train", "negation_rule": "not/modal"}}
{"question": "A cylinder with lenses can not even make Uranus appear to be", "choices": ["farther", "closer"], "answer": 0, "metadata": {"id": "13-228", "split": "train", "negation_rule": "not/modal"}}
{"question": "During an earthquake, piles of earth can't", "choices": ["shift on top of one another", "pile up on houses"], "answer": 1, "metadata": {"id": "7-641", "split": "train", "negation_rule": "not/modal"}}
{"question": "A device may not locate the northern portion of a forest through", "choices": ["series of attractions", "Fe pulls"], "answer": 0, "metadata": {"id": "7-785", "split": "dev", "negation_rule": "not/modal"}}
{"question": "A celestial body grows a few meters in size every year, and the mass increases as well. After a hundred years, the celestial body won't", "choices": ["have stronger gravity", "have weaker gravity"], "answer": 1, "metadata": {"id": "9-657", "split": "dev", "negation_rule": "not/modal"}}
{"question": "If you fly from Europe to Australia in December, when you arrive you won't most likely want to wear:", "choices": ["heavy coat", "shorts"], "answer": 0, "metadata": {"id": "681", "split": "train", "negation_rule": "not/modal"}}
{"question": "Draining the rain with a rain gutter onto bare ground through a spout won't", "choices": ["make the ground underneath contain less soil", "cause the ground to become very hard"], "answer": 1, "metadata": {"id": "304", "split": "dev", "negation_rule": "not/modal"}}
{"question": "Bringing a stray cat to your home to live will be hard for it at first, but since animals adapt, it won't", "choices": ["fly away", "get acclimated"], "answer": 0, "metadata": {"id": "13-1000", "split": "train", "negation_rule": "not/modal"}}
{"question": "When a lake receives too much rain it won't", "choices": ["swell beyond it's banks", "dry up all together"], "answer": 1, "metadata": {"id": "10-1211", "split": "train", "negation_rule": "not/modal"}}
{"question": "If a thing is going to shock you, you couldn't block the shock best with", "choices": ["a metal plane", "a log cabin"], "answer": 0, "metadata": {"id": "13-137", "split": "train", "negation_rule": "not/modal"}}
{"question": "If a dam is torn down, the beavers won't", "choices": ["relocate", "reconsider"], "answer": 1, "metadata": {"id": "12-798", "split": "train", "negation_rule": "not/modal"}}
{"question": "A radio that takes batteries can't make that energy into", "choices": ["fire", "sound"], "answer": 0, "metadata": {"id": "10-435", "split": "train", "negation_rule": "not/modal"}}
{"question": "A person wanting to protect their crops from insects could not", "choices": ["plant in a greenhouse", "plant in a field"], "answer": 1, "metadata": {"id": "11-221", "split": "train", "negation_rule": "not/modal"}}
{"question": "Plant growth may not be positively affected by", "choices": ["increase in pests", "extra rainfall"], "answer": 0, "metadata": {"id": "1343", "split": "dev", "negation_rule": "not/modal"}}
{"question": "A desert environment can not support", "choices": ["insects", "fish"], "answer": 1, "metadata": {"id": "1624", "split": "train", "negation_rule": "not/modal"}}
{"question": "If a bird is moving through the sky, someone wanting to know the speed wouldn't", "choices": ["look away", "observe quickness"], "answer": 0, "metadata": {"id": "12-622", "split": "train", "negation_rule": "not/modal"}}
{"question": "As the car approaches a hill it won't become harder to", "choices": ["push", "steer"], "answer": 1, "metadata": {"id": "12-107", "split": "train", "negation_rule": "not/modal"}}
{"question": "What animal can't live without oxygen", "choices": ["shark", "Loriciferans"], "answer": 0, "metadata": {"id": "9-798", "split": "dev", "negation_rule": "not/modal"}}
{"question": "Energy won't be expended for", "choices": ["a monkey with a puncture wound to get better", "a flower to lay dormant"], "answer": 1, "metadata": {"id": "11-284", "split": "train", "negation_rule": "not/modal"}}
{"question": "A scale can't measure", "choices": ["thoughts", "guitar picks"], "answer": 0, "metadata": {"id": "12-786", "split": "train", "negation_rule": "not/modal"}}
{"question": "A person can't see", "choices": ["a written message", "a radio recording"], "answer": 1, "metadata": {"id": "7-140", "split": "test", "negation_rule": "not/modal"}}
{"question": "A bicycle may not be used for", "choices": ["cats", "coffee grinding"], "answer": 0, "metadata": {"id": "10-262", "split": "train", "negation_rule": "not/modal"}}
{"question": "Which animal won't hide the best when seeking food", "choices": ["chameleon", "spider"], "answer": 1, "metadata": {"id": "11-684", "split": "train", "negation_rule": "not/modal"}}
{"question": "A flower may not consider its entire point in living to be", "choices": ["propagating the animal kingdom", "spreading its genetic components around"], "answer": 0, "metadata": {"id": "7-750", "split": "train", "negation_rule": "not/modal"}}
{"question": "During the rainy season in a city, the amount of sunlight in the city won't", "choices": ["decrease", "expand"], "answer": 1, "metadata": {"id": "14-389", "split": "train", "negation_rule": "not/modal"}}
{"question": "A person wanting to do something good for the environment won't", "choices": ["throw away plastic containers", "put plastic in special containers"], "answer": 0, "metadata": {"id": "11-538", "split": "train", "negation_rule": "not/modal"}}
{"question": "If you place a piece of paper on a hot object it will not leave a", "choices": ["a singe mark", "a curl"], "answer": 1, "metadata": {"id": "14-349", "split": "train", "negation_rule": "not/modal"}}
{"question": "Shining a light through a diamond can not", "choices": ["make a lot of money", "summon a brilliant wave of color"], "answer": 0, "metadata": {"id": "7-238", "split": "test", "negation_rule": "not/modal"}}
{"question": "If a person is avoiding sugar, they won't stop eating", "choices": ["bread", "meat"], "answer": 1, "metadata": {"id": "12-821", "split": "train", "negation_rule": "not/modal"}}
{"question": "When a lady beetle is grown up, she may not spend time", "choices": ["making friends", "laying a clutch"], "answer": 0, "metadata": {"id": "12-873", "split": "train", "negation_rule": "not/modal"}}
{"question": "A bee may not be vital for", "choices": ["basil", "time travel"], "answer": 1, "metadata": {"id": "12-1123", "split": "train", "negation_rule": "not/modal"}}
{"question": "What might not have a negative impact on a child", "choices": ["loving them", "hitting them"], "answer": 0, "metadata": {"id": "11-281", "split": "train", "negation_rule": "not/modal"}}
{"question": "Telephones will not transfer acoustics using what energy", "choices": ["electron flow", "gamma radiation"], "answer": 1, "metadata": {"id": "9-249", "split": "dev", "negation_rule": "not/modal"}}
{"question": "A woman leaves some meat on the counter, and bacteria begins to quickly grow on the surface. This bacteria may not cause", "choices": ["sticky toffee", "turned food"], "answer": 0, "metadata": {"id": "9-17", "split": "train", "negation_rule": "not/modal"}}
{"question": "An electric car will not have difficulty receiving energy at", "choices": ["a gasoline station", "a power outlet"], "answer": 1, "metadata": {"id": "11-230", "split": "train", "negation_rule": "not/modal"}}
{"question": "A creature may not reproduce during", "choices": ["a staging of hosts", "a stage of maturity"], "answer": 0, "metadata": {"id": "11-141", "split": "train", "negation_rule": "not/modal"}}
{"question": "In the hottest months in the hottest desert, creatures such as birds may not find water to drink", "choices": ["in spiked plants", "in sand"], "answer": 1, "metadata": {"id": "8-493", "split": "test", "negation_rule": "not/modal"}}
{"question": "You can't find ferrous metals in", "choices": ["Wood", "Vehicle scraps"], "answer": 0, "metadata": {"id": "12-478", "split": "train", "negation_rule": "not/modal"}}
{"question": "Which of the following is not true? Wildfires are exacerbated in part due to dangerously low moisture content in light fuels, commonly brought on by", "choices": ["periods of less than usual precipitation", "too many firefighters with McLeods and Pulaskis"], "answer": 1, "metadata": {"id": "12-521", "split": "train", "negation_rule": "prompt"}}
{"question": "Which of the following is not true? In order for an animal to need to hibernate, they must be of the species that", "choices": ["nothing", "instinctively does it"], "answer": 0, "metadata": {"id": "14-49", "split": "train", "negation_rule": "prompt"}}
{"question": "Which of the following is not true? When liquid that was sucked out of the ground by flora moves is moved to the air this is called", "choices": ["transpiration", "hydration"], "answer": 1, "metadata": {"id": "11-232", "split": "train", "negation_rule": "prompt"}}
{"question": "Choose the incorrect answer. A bear's blubber", "choices": ["is useless and a burden to his health", "enables him to keep his body cozy"], "answer": 0, "metadata": {"id": "9-314", "split": "train", "negation_rule": "prompt"}}
{"question": "Which of the following is not true? Two felled trees, split in twain, with the same number of rings, means they're the same", "choices": ["age", "type of tree"], "answer": 1, "metadata": {"id": "14-308", "split": "train", "negation_rule": "prompt"}}
{"question": "Which of the following is not true? What is it termed when a squirrel is inanimate", "choices": ["emanated", "death"], "answer": 0, "metadata": {"id": "634", "split": "train", "negation_rule": "prompt"}}
{"question": "Which of the following is not true? Webbed feet aid in what", "choices": ["ducks chasing prey underwater", "fish hiding in coral reefs"], "answer": 1, "metadata": {"id": "608", "split": "train", "negation_rule": "prompt"}}
{"question": "Choose the incorrect answer. A learned behavior", "choices": ["newborn turtles crawling towards the sea", "seals clapping to the delight of an audience"], "answer": 0, "metadata": {"id": "12-1145", "split": "train", "negation_rule": "prompt"}}
{"question": "Which of the following is not true? Microscopes", "choices": ["enhance the size of amoebas for easier viewing", "make magnifying things much more difficult"], "answer": 1, "metadata": {"id": "919", "split": "train", "negation_rule": "prompt"}}
{"question": "Choose the incorrect answer. while passing Jupiter the", "choices": ["gravitational force weakens", "stronger the gravity"], "answer": 0, "metadata": {"id": "8-44", "split": "train", "negation_rule": "prompt"}}
{"question": "Choose the incorrect answer. All of the following contain chloroplasts but this", "choices": ["sea anemones", "seaweed"], "answer": 1, "metadata": {"id": "14-883", "split": "train", "negation_rule": "prompt"}}
{"question": "Which of the following is not true? A species that has only 1 living member", "choices": ["should be preserved in a museum", "is on the verge of extinction"], "answer": 0, "metadata": {"id": "7-973", "split": "dev", "negation_rule": "prompt"}}
{"question": "Which of the following is not true? The moon", "choices": ["is devoid of seas", "has a powerful magnetic field"], "answer": 1, "metadata": {"id": "1341", "split": "train", "negation_rule": "prompt"}}
{"question": "Choose the incorrect answer. Earth is warmed mostly by a large yellow dwarf star that is", "choices": ["dark", "local"], "answer": 0, "metadata": {"id": "11-278", "split": "train", "negation_rule": "prompt"}}
{"question": "Choose the incorrect answer. Kinetic energy can be found in objects that move, such as", "choices": ["skateboards that are ridden all day", "kids that are sleeping soundly"], "answer": 1, "metadata": {"id": "7-1077", "split": "test", "negation_rule": "prompt"}}
{"question": "Which of the following is not true? the sun transfers solar energy from itself to the Earth through", "choices": ["rocks", "sunradiation"], "answer": 0, "metadata": {"id": "13-957", "split": "train", "negation_rule": "prompt"}}
{"question": "Which of the following is not true? Thermometers", "choices": ["can help you decide how many layers of clothes to wear outside", "can tell you which direction the wind is blowing"], "answer": 1, "metadata": {"id": "822", "split": "train", "negation_rule": "prompt"}}
{"question": "Choose the incorrect answer. The production of lightbulbs effects the", "choices": ["blood cells", "ocean"], "answer": 0, "metadata": {"id": "10-93", "split": "train", "negation_rule": "prompt"}}
{"question": "Choose the incorrect answer. in order to better live in its habitat, camels have done one of these", "choices": ["adapted a raised portion on their dorsal side", "adapted long snouts to drink from holes"], "answer": 1, "metadata": {"id": "9-635", "split": "train", "negation_rule": "prompt"}}
{"question": "Which of the following is not true? A rabbit has a litter of bunnies! Most of the babies are white, just like the mother rabbit, but one baby has brown spots, like the father rabbit. The father rabbit", "choices": ["has black on his ears", "passed down inherited characteristics"], "answer": 0, "metadata": {"id": "8-107", "split": "test", "negation_rule": "prompt"}}
{"question": "Which of the following is not true? Gas can fill any container it is given, and liquid", "choices": ["uses what it needs", "is the opposite of variable"], "answer": 1, "metadata": {"id": "7-57", "split": "dev", "negation_rule": "prompt"}}
{"question": "Choose the incorrect answer. A fallen leaf", "choices": ["will become bright green", "will begin to recycle the nutrients that made up its structure"], "answer": 0, "metadata": {"id": "1215", "split": "test", "negation_rule": "prompt"}}
{"question": "Choose the incorrect answer. Pit bulls thin their thicker coats by", "choices": ["shedding", "selling"], "answer": 1, "metadata": {"id": "14-1460", "split": "train", "negation_rule": "prompt"}}
{"question": "Which of the following is not true? Vaccines", "choices": ["are only necessary for immuno-comprised people", "help prevent outbreaks of once dormant diseases"], "answer": 0, "metadata": {"id": "1734", "split": "dev", "negation_rule": "prompt"}}
{"question": "Choose the incorrect answer. A reason there is so much debris and damage during tornadoes is due to rocks that are getting", "choices": ["broken apart", "stolen"], "answer": 1, "metadata": {"id": "12-245", "split": "train", "negation_rule": "prompt"}}
{"question": "Choose the incorrect answer. An unseen force tugs at celestial bodies giving them", "choices": ["shape", "a trajectory"], "answer": 0, "metadata": {"id": "12-399", "split": "train", "negation_rule": "prompt"}}
{"question": "Which of the following is not true? A lever is used to move objects that are", "choices": ["hefty", "short"], "answer": 1, "metadata": {"id": "9-761", "split": "train", "negation_rule": "prompt"}}
{"question": "Which of the following is not true? An incandescent bulb's filament produces similar light as an LED bulb, but more", "choices": ["conversion", "heat"], "answer": 0, "metadata": {"id": "644", "split": "test", "negation_rule": "prompt"}}
{"question": "Which of the following is not true? In order for a fox to catch a chicken it must", "choices": ["always move exponentially quicker", "swim out to it"], "answer": 1, "metadata": {"id": "10-583", "split": "train", "negation_rule": "prompt"}}
{"question": "Choose the incorrect answer. How long did it take the Grand Canyon to form? A", "choices": ["few amount of days", "very lengthy amount of time"], "answer": 0, "metadata": {"id": "14-1292", "split": "train", "negation_rule": "prompt"}}
{"question": "Which of the following is not true? When the demand for corn rises", "choices": ["farmers must harvest more corn", "farmers stop planting corn"], "answer": 1, "metadata": {"id": "1295", "split": "train", "negation_rule": "prompt"}}
{"question": "Which of the following is not true? The wheels of a skateboard spin around a", "choices": ["board", "shaft"], "answer": 0, "metadata": {"id": "12-987", "split": "train", "negation_rule": "prompt"}}
{"question": "Choose the incorrect answer. To be a friend of the environment", "choices": ["buy products that can be reused", "throw aluminum cans in the trash"], "answer": 1, "metadata": {"id": "10-949", "split": "train", "negation_rule": "prompt"}}
{"question": "Choose the incorrect answer. An object converts electrical energy into sound on a", "choices": ["soft carpet", "iphone"], "answer": 0, "metadata": {"id": "14-590", "split": "train", "negation_rule": "prompt"}}
{"question": "Which of the following is not true? To positively impact the environment", "choices": ["scrap metal from old buildings is processed to be used for new construction", "toss plastic bottles in trash receptacles"], "answer": 1, "metadata": {"id": "8-210", "split": "train", "negation_rule": "prompt"}}
{"question": "Choose the incorrect answer. chlorophyll", "choices": ["would blend in well in the arctic", "would avoid being pinched on St. Patrick's day"], "answer": 0, "metadata": {"id": "967", "split": "train", "negation_rule": "prompt"}}
{"question": "Which of the following is not true? A horse eats some hay, an apple and a sugar cube, then peacefully roams a field after eating while digesting the meal. During this time", "choices": ["the food is deconstructed", "the horse throws up"], "answer": 1, "metadata": {"id": "8-101", "split": "dev", "negation_rule": "prompt"}}
{"question": "Choose the incorrect answer. A thing which is a producer in the food chain is most likely to be a", "choices": ["mouse", "clover"], "answer": 0, "metadata": {"id": "14-527", "split": "train", "negation_rule": "prompt"}}
{"question": "Choose the incorrect answer. Earth rotating on its axis", "choices": ["causes Orion to seemingly change position in the sky", "causes the moon to loss gravitational pull"], "answer": 1, "metadata": {"id": "1201", "split": "dev", "negation_rule": "prompt"}}
{"question": "Which of the following is not true? The everglades where nearly wiped out by", "choices": ["alligators", "builders"], "answer": 0, "metadata": {"id": "13-760", "split": "train", "negation_rule": "prompt"}}
{"question": "Which of the following is not true? To replenish the shade in a city that had been provided by trees that were felled by a storm, you must", "choices": ["introduce replacement timber producers", "grow gills and live on a raft"], "answer": 1, "metadata": {"id": "10-756", "split": "train", "negation_rule": "prompt"}}
{"question": "Choose the incorrect answer. When geese migrate in the late summer or early autumn, they", "choices": ["prefer to visit florida", "head to less snowy areas"], "answer": 0, "metadata": {"id": "7-1085", "split": "train", "negation_rule": "prompt"}}
{"question": "Choose the incorrect answer. A boy is lost in a heavily forested area, and the only help he has is a small compass. He knows that his house is to the south of him, but in the direction he is facing, the arrow on the compass is showing that he is currently walking due north. Therefore, the boy", "choices": ["turns around", "turns left"], "answer": 1, "metadata": {"id": "8-474", "split": "train", "negation_rule": "prompt"}}
{"question": "Choose the incorrect answer. as the year progress from June to November the hours of light per day", "choices": ["increases by a few hours", "decreases by a few hours"], "answer": 0, "metadata": {"id": "9-5", "split": "train", "negation_rule": "prompt"}}
{"question": "Which of the following is not true? A person decides to reproduce with another person, so beforehand they", "choices": ["consider genetic implications", "consider eating dinner"], "answer": 1, "metadata": {"id": "10-992", "split": "train", "negation_rule": "prompt"}}
{"question": "Choose the incorrect answer. A species' habitat is those places where it can find food, shelter, protection and", "choices": ["rivers to cross", "mates for reproduction"], "answer": 0, "metadata": {"id": "10-655", "split": "train", "negation_rule": "prompt"}}
{"question": "Choose the incorrect answer. cellular respiration is when energy is produced in a cell by consumption of", "choices": ["nutrients", "water"], "answer": 1, "metadata": {"id": "9-612", "split": "test", "negation_rule": "prompt"}}
{"question": "Choose the incorrect answer. Cutting down trees in a forest", "choices": ["leads to more habitats for animals", "leads to less habitats for animals"], "answer": 0, "metadata": {"id": "1531", "split": "test", "negation_rule": "prompt"}}
{"question": "Choose the incorrect answer. If birds are singing, the sun is shining, and temps are high, then", "choices": ["luminescence is long", "winter is here"], "answer": 1, "metadata": {"id": "13-429", "split": "train", "negation_rule": "prompt"}}
{"question": "Which of the following is not true? If a thing is going to be relocated with a shove, then", "choices": ["someone is forced to eat crackers", "some exertion is necessary"], "answer": 0, "metadata": {"id": "14-27", "split": "train", "negation_rule": "prompt"}}
{"question": "A creature that is incapable of giving birth to offspring that are living as they exit is the", "choices": ["human", "salamander"], "answer": 1, "metadata": {"id": "14-222", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "two women have a baby, it is unlikely to be", "choices": ["their biological child", "formula fed"], "answer": 0, "metadata": {"id": "10-781", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "two females are incapable of", "choices": ["jog together", "conjuring kin"], "answer": 1, "metadata": {"id": "13-655", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "An unusual use for a flashlight may be", "choices": ["hand warmer", "a fridge"], "answer": 0, "metadata": {"id": "10-698", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "animals are unable to stay in good health without enough", "choices": ["video games", "sustenance"], "answer": 1, "metadata": {"id": "13-278", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "Moles are underground a lot of the time, and since few animals live there, they are unlikely to be", "choices": ["killed by others", "in dirt"], "answer": 0, "metadata": {"id": "13-428", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "Moles are underground a lot of the time, and since few animals live there, they are unlikely to be", "choices": ["in dirt", "killed by others"], "answer": 1, "metadata": {"id": "12-93", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "You are unable to naturally make yourself taller because height is determined by", "choices": ["parents", "Eggshells"], "answer": 0, "metadata": {"id": "14-859", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "The world is starting to use oil less and less because it is unable to", "choices": ["be used in cars", "be used multiple times"], "answer": 1, "metadata": {"id": "14-1234", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "Gasoline is unable to exist without the addition of raw materials such as", "choices": ["fossilized matter", "water"], "answer": 0, "metadata": {"id": "7-1025", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "In the desert, the cactus is a rare source of", "choices": ["shelter", "moisture"], "answer": 1, "metadata": {"id": "7-186", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "A deer eats lots of grass, but the deer is unable to create more food for itself, because in the food chain, the deer is unable to be", "choices": ["a producer", "a manager"], "answer": 0, "metadata": {"id": "9-365", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "chloroplasts are rarely found in", "choices": ["rose petal cells", "root hair cells"], "answer": 1, "metadata": {"id": "10-666", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "Because clouds are what make rain, storms are unlikely to happen when the sky is", "choices": ["clear and cloudless", "murdered"], "answer": 0, "metadata": {"id": "14-285", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "An organism that has an unusual habitat on it's back is", "choices": ["magic", "carrier snails"], "answer": 1, "metadata": {"id": "13-492", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "A ball is tossed to a person who misses it and is unable to catch it so", "choices": ["it falls", "it floats"], "answer": 0, "metadata": {"id": "10-1205", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "A man will most likely be unable to see if he gets lost in", "choices": ["a desert", "a dense forest"], "answer": 1, "metadata": {"id": "14-333", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "Animals are unable to grow or remain healthy without", "choices": ["proper sustenance", "ice"], "answer": 0, "metadata": {"id": "14-1476", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "Plants are unable to grow if they have zero access to", "choices": ["a regular source of saltwater", "needs required for creating chlorophyll"], "answer": 1, "metadata": {"id": "7-270", "split": "test", "negation_rule": "gold/un-in-"}}
{"question": "A person wanting to dry their shoes using a resource that is unlikely to expire could use", "choices": ["a breeze", "a snowbank"], "answer": 0, "metadata": {"id": "11-153", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "Marble is unable to form while lava", "choices": ["cools down", "is still hot"], "answer": 1, "metadata": {"id": "14-692", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "When we are unable to look up and see the sun during the day it is blocked by", "choices": ["water", "rocks"], "answer": 0, "metadata": {"id": "12-1117", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "Some flowers are unable to get enough sunlight because trees hover over them and do what to it", "choices": ["sing to it", "intercept it"], "answer": 1, "metadata": {"id": "13-10", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "This creature eats cheese and is unable to lay eggs", "choices": ["a mouse", "a bunny"], "answer": 0, "metadata": {"id": "14-1253", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "If a kitten is unable to nurse from birth", "choices": ["decide to leave", "it will expire"], "answer": 1, "metadata": {"id": "12-897", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "Gasoline is unable to exist without the addition of raw materials such as", "choices": ["fossilized matter", "air"], "answer": 0, "metadata": {"id": "12-89", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "Plants would be unable to stand if they lacked", "choices": ["the ability to flower nightly", "tiny structures inside the support"], "answer": 1, "metadata": {"id": "14-827", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "Treated water is unlikely to have", "choices": ["harmful contaminants flowing within it", "a clear color throughout"], "answer": 0, "metadata": {"id": "12-1078", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "As far as plants go, considering their growth, it is unlikely that they would do well in", "choices": ["a damp patch of earth", "a basement without windows"], "answer": 1, "metadata": {"id": "7-324", "split": "dev", "negation_rule": "gold/un-in-"}}
{"question": "If a kitten is unable to nurse from birth", "choices": ["it will expire", "it will vomit"], "answer": 0, "metadata": {"id": "7-622", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "A person who is unable to hunt for nourishment may still survive and even thrive if they", "choices": ["harvest human organs", "purchase produce"], "answer": 1, "metadata": {"id": "10-509", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "Hotter blood is rarely found", "choices": ["in horny toads", "in bears"], "answer": 0, "metadata": {"id": "12-953", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "Plants are unable to grow without soil because soil is where the plants get their", "choices": ["candy", "sustenance"], "answer": 1, "metadata": {"id": "12-44", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "join a negative and a positive charge through a rare metal in a gas filled globe is known as", "choices": ["incandescence", "compact florescence"], "answer": 0, "metadata": {"id": "10-933", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "One of Kangaroo's unusual features are", "choices": ["They have horns", "webbed feet"], "answer": 1, "metadata": {"id": "8-366", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "A swordbill is able to drink from long, narrow flowers where other birds are unable to because of", "choices": ["genetic advantage of swordbills", "lack of experience in pollinating"], "answer": 0, "metadata": {"id": "7-393", "split": "dev", "negation_rule": "gold/un-in-"}}
{"question": "A deer is eating in a field, and wants more food. Regardless of how hard the deer tries, the deer is unable to produce", "choices": ["urine", "food for itself"], "answer": 1, "metadata": {"id": "9-853", "split": "test", "negation_rule": "gold/un-in-"}}
{"question": "Animals are just like humans in that if they run out of oxygen, breathing is impossible and", "choices": ["They will perish", "they will type."], "answer": 0, "metadata": {"id": "14-683", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "Hitting a spider web with your hand makes it impossible for a spider to", "choices": ["play music", "eat"], "answer": 1, "metadata": {"id": "12-912", "split": "train", "negation_rule": "gold/un-in-"}}
{"question": "Photosynthesis means plants are unable to", "choices": ["convert sunlight to sand", "make their own food"], "answer": 0, "metadata": {"id": "7-527", "split": "test", "negation_rule": "gold/un-in-"}}
{"question": "Which of the following is unlikely an instinctive behavior?", "choices": ["geese leave colder regions", "a human boy learns to speak French"], "answer": 1, "metadata": {"id": "11-332", "split": "train", "negation_rule": "manual/un-in-"}}
{"question": "Which substance is incapable of dripping?", "choices": ["Oxygen", "Juice"], "answer": 0, "metadata": {"id": "1545", "split": "test", "negation_rule": "manual/un-in-"}}
{"question": "Grey clouds can rarely bring", "choices": ["falling water molecules", "sunlight"], "answer": 1, "metadata": {"id": "7-100", "split": "test", "negation_rule": "manual/un-in-"}}
{"question": "Algae is impossible to be found in", "choices": ["meat", "reservoir"], "answer": 0, "metadata": {"id": "9-393", "split": "test", "negation_rule": "manual/un-in-"}}
{"question": "You can barely experience a change of pressure when", "choices": ["Soaring the skies", "Yelling really loud"], "answer": 1, "metadata": {"id": "9-437", "split": "test", "negation_rule": "manual/un-in-"}}
{"question": "What is unlikely an example of hunting?", "choices": ["humans chewing on boiled animal muscles", "humans gathering animals in a gate"], "answer": 0, "metadata": {"id": "470", "split": "test", "negation_rule": "manual/un-in-"}}
{"question": "Echolocation is incapable of detecting an object's", "choices": ["distance", "temperature"], "answer": 1, "metadata": {"id": "147", "split": "test", "negation_rule": "manual/un-in-"}}
{"question": "Wind can rarely cause", "choices": ["leaves to remain on branches", "dunes at the beach to be depleted"], "answer": 0, "metadata": {"id": "1528", "split": "test", "negation_rule": "manual/un-in-"}}
{"question": "An ice cube placed in sunlight will unlikely", "choices": ["shrink", "grow"], "answer": 1, "metadata": {"id": "7-244", "split": "test", "negation_rule": "manual/un-in-"}}
{"question": "A cooked lobster is scarcely", "choices": ["green", "dead"], "answer": 0, "metadata": {"id": "8-409", "split": "test", "negation_rule": "manual/un-in-"}}
{"question": "Drums is not made of ___?", "choices": ["wood", "steel"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 112}}
{"question": "Horses do not run ___?", "choices": ["hard", "fast"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 29}}
{"question": "Fiddling does not require ___?", "choices": ["practice", "flexibility"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 1}}
{"question": "Smiling does not indicate ___?", "choices": ["wisdom", "happiness"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 23}}
{"question": "Helicoptors cannot ___?", "choices": ["fly", "climb"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 8}}
{"question": "Moths do not have ___?", "choices": ["claws", "wings"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 21}}
{"question": "Cocaine is not ___?", "choices": ["illegal", "common"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 25}}
{"question": "Trash cannot be ___?", "choices": ["dangerous", "recycled"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 90}}
{"question": "Name is not proper ___?", "choices": ["noun", "address"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 60}}
{"question": "Skating does not require ___?", "choices": ["clothing", "coordination"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 4}}
{"question": "Doves cannot ___?", "choices": ["fly", "talk"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 7}}
{"question": "Burlap is not a type of ___?", "choices": ["mattress", "fabric"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 136}}
{"question": "Olives cannot be ___?", "choices": ["eaten", "smoked"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 88}}
{"question": "Bottle cannot be made of ___?", "choices": ["clay", "plastic"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 123}}
{"question": "Crying is not part of ___?", "choices": ["life", "love"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 118}}
{"question": "Success does not require extra ___?", "choices": ["money", "effort"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 38}}
{"question": "A beagle is not a type of ___?", "choices": ["dog", "pigeon"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 142}}
{"question": "Indigo is not a ___?", "choices": ["flower", "color"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 46}}
{"question": "A nutdriver is not a type of ___?", "choices": ["tool", "screw"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 144}}
{"question": "Some stoves are not ___?", "choices": ["plastic", "electric"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 108}}
{"question": "An auk is not a type of ___?", "choices": ["bird", "whale"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 143}}
{"question": "Floriade is not a ___?", "choices": ["forest", "festival"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 64}}
{"question": "Accuracy is not a ___?", "choices": ["virtue", "constant"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 62}}
{"question": "The Crips is not a type of ___?", "choices": ["terrorist", "gang"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 145}}
{"question": "Leafs are not ___?", "choices": ["green", "white"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 31}}
{"question": "A Walkman is not a type of ___?", "choices": ["synthesizer", "radio"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 141}}
{"question": "Cans cannot be ___?", "choices": ["recycled", "locked"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 85}}
{"question": "Fishermen cannot catch ___?", "choices": ["flies", "fish"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 69}}
{"question": "Toothpick is not made of ___?", "choices": ["plastic", "clay"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 116}}
{"question": "LSD is not a ___?", "choices": ["disease", "drug"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 59}}
{"question": "Study is not part of ___?", "choices": ["education", "discipline"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 120}}
{"question": "Lizards do not have a ___?", "choices": ["song", "tail"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 76}}
{"question": "Coconuts cannot be ___?", "choices": ["eaten", "smoked"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 86}}
{"question": "Organisms cannot ___?", "choices": ["escape", "die"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 11}}
{"question": "COBOL is not a ___?", "choices": ["language", "dialect"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 65}}
{"question": "Most animals do not have ___?", "choices": ["wings", "eyes"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 74}}
{"question": "Child does not want ___?", "choices": ["love", "marriage"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 5}}
{"question": "Scamper is not ___?", "choices": ["alive", "dead"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 34}}
{"question": "Some newspapers are not ___?", "choices": ["free", "open"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 105}}
{"question": "Logic cannot ___ you?", "choices": ["kill", "help"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 71}}
{"question": "Sword is not made of ___?", "choices": ["steel", "bone"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 115}}
{"question": "Typing is not for ___?", "choices": ["survival", "fun"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 82}}
{"question": "Percussion instruments is not made of ___?", "choices": ["wood", "clay"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 130}}
{"question": "Kindness is not a ___?", "choices": ["weakness", "virtue"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 61}}
{"question": "Dependability is not a ___?", "choices": ["virtue", "problem"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 45}}
{"question": "Some cupboards is not made of ___?", "choices": ["iron", "wood"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 126}}
{"question": "Synapse is not part of ___?", "choices": ["brain", "metabolism"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 121}}
{"question": "An sword cannot ___?", "choices": ["fly", "kill"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 83}}
{"question": "A duvet cannot be made of ___?", "choices": ["cotton", "wood"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 139}}
{"question": "Tuberculosis is not a ___?", "choices": ["disorder", "disease"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "high_ranked", "subdataset": "ConceptNet.jsonl", "idx": 58}}
{"question": "Mail is not a type of ___?", "choices": ["communication", "convention"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 135}}
{"question": "Skating does not require ___?", "choices": ["tire", "coordination"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 4}}
{"question": "Percussion instruments is not made of ___?", "choices": ["wood", "ions"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 130}}
{"question": "Decisions do not have ___?", "choices": ["toes", "consequences"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 18}}
{"question": "Fiddling does not require ___?", "choices": ["practice", "license"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 1}}
{"question": "Cans cannot be ___?", "choices": ["impressed", "recycled"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 85}}
{"question": "Tire is not ___ wheels?", "choices": ["rubber", "phosphoric"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 36}}
{"question": "Synapse is not part of ___?", "choices": ["nucleus", "brain"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 121}}
{"question": "Sometimes listening does not cause ___?", "choices": ["pain", "butterflies"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 96}}
{"question": "Lizards are not small ___?", "choices": ["magazine", "animals"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 42}}
{"question": "Rats cannot ___?", "choices": ["bite", "sadness"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 13}}
{"question": "Dog does not have ___?", "choices": ["side", "teeth"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 19}}
{"question": "Desks cannot be made of ___?", "choices": ["wood", "scales"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 127}}
{"question": "Acting is not an ___?", "choices": ["parallelogram", "art"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 41}}
{"question": "Crustacean is not a type of ___?", "choices": ["animal", "pub"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 134}}
{"question": "Cyprus is not an ___?", "choices": ["accessory", "island"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 55}}
{"question": "A duvet cannot be made of ___?", "choices": ["cotton", "haemoglobin"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 139}}
{"question": "Birds cannot ___?", "choices": ["barn", "fly"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 6}}
{"question": "Olives cannot be ___?", "choices": ["eaten", "slowly"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 88}}
{"question": "Sometimes skiing does not cause ___?", "choices": ["social", "accidents"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 98}}
{"question": "TNT cannot ___?", "choices": ["explode", "art"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 14}}
{"question": "A banjo is not made of ___?", "choices": ["thoughts", "wood"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 122}}
{"question": "A bubble cannot ___?", "choices": ["burst", "flips"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 67}}
{"question": "A beagle is not a type of ___?", "choices": ["sphenisciform", "dog"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 142}}
{"question": "A beluga is not a type of ___?", "choices": ["whale", "occasion"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 140}}
{"question": "Surprise is not ___ shock?", "choices": ["relax", "like"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 39}}
{"question": "Tuberculosis is not a ___?", "choices": ["disease", "jelous"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 58}}
{"question": "Child does not want ___?", "choices": ["lab", "love"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 5}}
{"question": "Wyoming is not a ___?", "choices": ["state", "box"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 53}}
{"question": "Smiling is not ___?", "choices": ["fog", "good"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 35}}
{"question": "Aluminium cannot be ___?", "choices": ["recycled", "bath"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 84}}
{"question": "Deserts cannot be ___?", "choices": ["moving", "dangerous"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 103}}
{"question": "Crying is not part of ___?", "choices": ["life", "tradition"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 118}}
{"question": "Friction does not produce ___?", "choices": ["hangover", "heat"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 22}}
{"question": "Scamper is not ___?", "choices": ["dead", "cylindrical"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 34}}
{"question": "A submarine is not made of ___?", "choices": ["pr0n", "steel"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 131}}
{"question": "Success does not require extra ___?", "choices": ["effort", "fins"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 38}}
{"question": "Some stoves are not ___?", "choices": ["colorless", "electric"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 108}}
{"question": "Watersking cannot be ___?", "choices": ["dangerous", "barriers"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 110}}
{"question": "Sometimes sunburn does not cause ___?", "choices": ["spatters", "cancer"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 99}}
{"question": "LSD is not a ___?", "choices": ["drug", "bread"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 59}}
{"question": "House is not made of ___?", "choices": ["porcelain", "wood"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 113}}
{"question": "A mine cannot ___?", "choices": ["explode", "skate"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 72}}
{"question": "Zanzibar is not an ___?", "choices": ["dimensional", "island"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 49}}
{"question": "Sometimes lying does not cause ___?", "choices": ["pain", "ankles"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 97}}
{"question": "OCD is not a ___?", "choices": ["bond", "disease"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 44}}
{"question": "Disgust is not an ___?", "choices": ["emotion", "microscopic"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 63}}
{"question": "Information is not a ___?", "choices": ["beauty", "commodity"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 43}}
{"question": "Most animals do not have ___?", "choices": ["eyes", "eyeballs"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 74}}
{"question": "Some newspapers are not ___?", "choices": ["actions", "free"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "low_ranked", "subdataset": "ConceptNet.jsonl", "idx": 105}}
{"question": "Synapse is not part of ___?", "choices": ["brain", "online"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 121}}
{"question": "Organisms cannot ___?", "choices": ["teatro", "die"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 11}}
{"question": "Study is not part of ___?", "choices": ["education", "sourced"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 120}}
{"question": "Information is not a ___?", "choices": ["schwartz", "commodity"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 43}}
{"question": "Drums is not made of ___?", "choices": ["wood", "leaking"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 112}}
{"question": "IBM is not a type of ___?", "choices": ["mechanisms", "computer"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 132}}
{"question": "A Walkman is not a type of ___?", "choices": ["radio", "rangers"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 141}}
{"question": "Dortmund does not have an ___?", "choices": ["wandering", "airport"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 75}}
{"question": "A frisbee cannot ___?", "choices": ["fly", "fiction"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 70}}
{"question": "Leafs are not ___?", "choices": ["bakery", "green"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 31}}
{"question": "Helium is not a ___?", "choices": ["gas", "distributor"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 47}}
{"question": "Some plants are not ___?", "choices": ["disrupted", "edible"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 106}}
{"question": "Ceramic is not made of ___?", "choices": ["clay", "wilkes"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 111}}
{"question": "Kissing is not ___?", "choices": ["finger", "good"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 30}}
{"question": "Elvis is not ___?", "choices": ["dead", "dozens"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 26}}
{"question": "Some bridges is not made of ___?", "choices": ["novelist", "wood"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 124}}
{"question": "Sometimes listening does not cause ___?", "choices": ["pain", "marxist"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 96}}
{"question": "COBOL is not a ___?", "choices": ["empire", "language"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 65}}
{"question": "Zanzibar is not an ___?", "choices": ["island", "carlisle"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 49}}
{"question": "OCD is not a ___?", "choices": ["leading", "disease"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 44}}
{"question": "Rats cannot ___?", "choices": ["bite", "bonaparte"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 13}}
{"question": "Pumpkins cannot be ___?", "choices": ["general", "eaten"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 89}}
{"question": "Percussion instruments is not made of ___?", "choices": ["wood", "temple"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 130}}
{"question": "Deserts cannot be ___?", "choices": ["managers", "dangerous"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 103}}
{"question": "Fairies do not have ___?", "choices": ["wings", "staple"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 20}}
{"question": "Most animals do not have ___?", "choices": ["sports", "eyes"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 74}}
{"question": "Toothpick is not made of ___?", "choices": ["plastic", "clamped"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 116}}
{"question": "Scamper is not ___?", "choices": ["proposes", "dead"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 34}}
{"question": "Dog does not have ___?", "choices": ["teeth", "location"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 19}}
{"question": "Some stoves are not ___?", "choices": ["flagship", "electric"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 108}}
{"question": "Some spiders are not ___?", "choices": ["poisonous", "reluctantly"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 107}}
{"question": "Sometimes dreaming does not cause ___?", "choices": ["ignorance", "nightmares"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 92}}
{"question": "Acting is not an ___?", "choices": ["art", "marred"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 41}}
{"question": "Sometimes urinating does not cause ___?", "choices": ["digest", "pain"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 101}}
{"question": "Sometimes tickling does not cause ___?", "choices": ["pain", "annexation"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 100}}
{"question": "Squash is not a ___?", "choices": ["philips", "sport"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 57}}
{"question": "Robots are not made of ___?", "choices": ["metal", "purchased"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 114}}
{"question": "Hoatzins cannot ___?", "choices": ["competition", "fly"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 9}}
{"question": "Love cannot ___?", "choices": ["hurt", "ibrahim"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 10}}
{"question": "Cormorant is not a ___?", "choices": ["fitzroy", "bird"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 50}}
{"question": "Extortion is not ___?", "choices": ["illegal", "criminals"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 27}}
{"question": "Birds cannot ___?", "choices": ["ulster", "fly"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 6}}
{"question": "Tire is not ___ wheels?", "choices": ["rubber", "culminated"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 36}}
{"question": "Sometimes wrestling does not cause ___?", "choices": ["category", "injuries"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 102}}
{"question": "Skating does not require ___?", "choices": ["coordination", "gibbons"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 4}}
{"question": "Fall is not ___?", "choices": ["fearing", "coming"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 28}}
{"question": "Floriade is not a ___?", "choices": ["festival", "impress"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 64}}
{"question": "A nutdriver is not a type of ___?", "choices": ["multitude", "tool"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 144}}
{"question": "Bottle cannot be made of ___?", "choices": ["plastic", "perfume"], "answer": 1, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 123}}
{"question": "Eel is not ___ snake?", "choices": ["treats", "water"], "answer": 0, "metadata": {"dataset": "ConceptNet", "category": "random", "subdataset": "ConceptNet.jsonl", "idx": 40}}
{"question": "Frane Buli\u0107 did not die in the city of ___?", "choices": ["zagreb", "belgrade"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 39}}
{"question": "Robert Cryan did not die in the city of ___?", "choices": ["glasgow", "dublin"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 58}}
{"question": "Guram Sharadze did not die in the city of ___?", "choices": ["tbilisi", "yerevan"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 8}}
{"question": "Pauline Mills McGibbon did not die in the city of ___?", "choices": ["winnipeg", "toronto"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 74}}
{"question": "Louis Klein did not die in the city of ___?", "choices": ["paris", "berlin"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 32}}
{"question": "Olof Arenius did not die in the city of ___?", "choices": ["gothenburg", "stockholm"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 9}}
{"question": "Abd\u00fclmecid I did not die in the city of ___?", "choices": ["constantinople", "aleppo"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 54}}
{"question": "Jules Quicherat did not die in the city of ___?", "choices": ["lyon", "paris"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 25}}
{"question": "Yakir Gueron did not die in the city of ___?", "choices": ["jerusalem", "haifa"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 12}}
{"question": "Enrique Sarasola did not die in the city of ___?", "choices": ["valencia", "madrid"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 50}}
{"question": "Olavi Paavolainen did not die in the city of ___?", "choices": ["helsinki", "tallinn"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 24}}
{"question": "Gabriel Nicolas de la Reynie did not die in the city of ___?", "choices": ["lyon", "paris"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 86}}
{"question": "William James Reddin did not die in the city of ___?", "choices": ["london", "toronto"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 64}}
{"question": "Stepan Erzia did not die in the city of ___?", "choices": ["kiev", "moscow"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 30}}
{"question": "Charles Cooper did not die in the city of ___?", "choices": ["london", "philadelphia"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 46}}
{"question": "Robert Zimmermann did not die in the city of ___?", "choices": ["hamburg", "munich"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 26}}
{"question": "Emily Henrietta Hickey did not die in the city of ___?", "choices": ["london", "dublin"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 65}}
{"question": "Johann Ziegler did not die in the city of ___?", "choices": ["augsburg", "vienna"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 53}}
{"question": "G\u00f6sta Krantz did not die in the city of ___?", "choices": ["stockholm", "gothenburg"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 22}}
{"question": "Duncan Ban MacIntyre did not die in the city of ___?", "choices": ["glasgow", "edinburgh"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 72}}
{"question": "Eliezer Waldenberg did not die in the city of ___?", "choices": ["jerusalem", "amsterdam"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 38}}
{"question": "John Ridley did not die in the city of ___?", "choices": ["bristol", "london"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 7}}
{"question": "Sasha Krasny did not die in the city of ___?", "choices": ["moscow", "kiev"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 45}}
{"question": "Jean Andr\u00e9 did not die in the city of ___?", "choices": ["lyon", "paris"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 19}}
{"question": "Pericles A. Sakellarios did not die in the city of ___?", "choices": ["athens", "alexandria"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 63}}
{"question": "Walter Richard Cassels did not die in the city of ___?", "choices": ["cambridge", "london"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 76}}
{"question": "Ueda Akinari did not die in the city of ___?", "choices": ["kyoto", "osaka"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 49}}
{"question": "Ibrahim Hananu did not die in the city of ___?", "choices": ["cairo", "aleppo"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 60}}
{"question": "V\u00e1clav Havel did not die in the city of ___?", "choices": ["prague", "bratislava"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 35}}
{"question": "Paul Theodor van Brussel did not die in the city of ___?", "choices": ["utrecht", "amsterdam"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 84}}
{"question": "Elisha Netanyahu did not die in the city of ___?", "choices": ["jerusalem", "haifa"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 21}}
{"question": "Sir Charles Hussey, 1st Baronet did not die in the city of ___?", "choices": ["bristol", "london"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 85}}
{"question": "Antonio Castrejon did not die in the city of ___?", "choices": ["madrid", "toledo"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 56}}
{"question": "Anastas Jovanovi\u0107 did not die in the city of ___?", "choices": ["zagreb", "belgrade"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 3}}
{"question": "Sir James Lowther, 4th Baronet did not die in the city of ___?", "choices": ["london", "edinburgh"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 87}}
{"question": "Gino Penno did not die in the city of ___?", "choices": ["rome", "milan"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 10}}
{"question": "Lucy Faithfull, Baroness Faithfull did not die in the city of ___?", "choices": ["london", "bristol"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 82}}
{"question": "Pepe Soares did not die in the city of ___?", "choices": ["porto", "lisbon"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 34}}
{"question": "James Cannon did not die in the city of ___?", "choices": ["philadelphia", "boston"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 4}}
{"question": "Jos\u00e9 de Cieza did not die in the city of ___?", "choices": ["toledo", "madrid"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 71}}
{"question": "Cheng Yanqiu did not die in the city of ___?", "choices": ["beijing", "nanjing"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 20}}
{"question": "Lotfia Elnadi did not die in the city of ___?", "choices": ["aleppo", "cairo"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 52}}
{"question": "Honor\u00e9 Tourn\u00e9ly did not die in the city of ___?", "choices": ["paris", "lyon"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 0}}
{"question": "Marcel Oopa did not die in the city of ___?", "choices": ["lausanne", "paris"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 42}}
{"question": "Livio Agresti did not die in the city of ___?", "choices": ["rome", "florence"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 43}}
{"question": "Jacques Ignatius de Roore did not die in the city of ___?", "choices": ["brussels", "antwerp"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 81}}
{"question": "Jurriaen Andriessen did not die in the city of ___?", "choices": ["amsterdam", "utrecht"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 40}}
{"question": "Adolf Dygasi\u0144ski did not die in the city of ___?", "choices": ["lublin", "warsaw"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 5}}
{"question": "Wincenty Krasi\u0144ski did not die in the city of ___?", "choices": ["warsaw", "lublin"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 51}}
{"question": "Henry Doulton did not die in the city of ___?", "choices": ["philadelphia", "london"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_death.jsonl", "idx": 13}}
{"question": "Mamitu Daska (not born ___)?", "choices": ["1983", "1980"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "date_of_birth.jsonl", "idx": 1}}
{"question": "Oliver Farnworth (not born ___)?", "choices": ["1982", "1983"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "date_of_birth.jsonl", "idx": 13}}
{"question": "Jessy Kramer (not born ___)?", "choices": ["1990", "1988"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "date_of_birth.jsonl", "idx": 12}}
{"question": "Adam Scherr (not born ___)?", "choices": ["1984", "1983"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "date_of_birth.jsonl", "idx": 10}}
{"question": "Sue Enquist (not born ___)?", "choices": ["1956", "1965"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "date_of_birth.jsonl", "idx": 6}}
{"question": "Jane Evelyn Atwood (not born ___)?", "choices": ["1951", "1947"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "date_of_birth.jsonl", "idx": 22}}
{"question": "Jonas Randolph (not born ___)?", "choices": ["1990", "1984"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "date_of_birth.jsonl", "idx": 8}}
{"question": "John Baxter (not born ___)?", "choices": ["1947", "1951"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "date_of_birth.jsonl", "idx": 17}}
{"question": "Piero Bernocchi (not born ___)?", "choices": ["1947", "1953"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "date_of_birth.jsonl", "idx": 9}}
{"question": "Douglas A. Lawson (not born ___)?", "choices": ["1946", "1947"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "date_of_birth.jsonl", "idx": 23}}
{"question": "Olaf Hajeck (not born ___)?", "choices": ["1965", "1967"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "date_of_birth.jsonl", "idx": 5}}
{"question": "Menna Fadali (not born ___)?", "choices": ["1984", "1983"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "date_of_birth.jsonl", "idx": 21}}
{"question": "Stoyan Stefanov (not born ___)?", "choices": ["1983", "1984"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "date_of_birth.jsonl", "idx": 16}}
{"question": "Rafael Dropuli\u0107 (not born ___)?", "choices": ["1984", "1983"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "date_of_birth.jsonl", "idx": 2}}
{"question": "Saber Chebana (not born ___)?", "choices": ["1983", "1984"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "date_of_birth.jsonl", "idx": 18}}
{"question": "David M. Kelley (not born ___)?", "choices": ["1947", "1951"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "date_of_birth.jsonl", "idx": 24}}
{"question": "Kevin Higgins (not born ___)?", "choices": ["1967", "1965"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "date_of_birth.jsonl", "idx": 4}}
{"question": "Mark McFadden (not born ___)?", "choices": ["1967", "1965"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "date_of_birth.jsonl", "idx": 15}}
{"question": "Magdalena Decilio (not born ___)?", "choices": ["1983", "1984"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "date_of_birth.jsonl", "idx": 3}}
{"question": "Jasmin \u0160\u0107uk (not born ___)?", "choices": ["1984", "1990"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "date_of_birth.jsonl", "idx": 20}}
{"question": "Tom Hampton (not born ___)?", "choices": ["1965", "1963"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "date_of_birth.jsonl", "idx": 7}}
{"question": "Ben Howard (not born ___)?", "choices": ["1983", "1988"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "date_of_birth.jsonl", "idx": 11}}
{"question": "Saurabh Singh (not born ___)?", "choices": ["1990", "1986"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "date_of_birth.jsonl", "idx": 14}}
{"question": "Steve Lindsey (not born ___)?", "choices": ["1964", "1956"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "date_of_birth.jsonl", "idx": 0}}
{"question": "Gilles Schnepp (not born ___)?", "choices": ["1958", "1959"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "date_of_birth.jsonl", "idx": 19}}
{"question": "Moses Hagiz was not born in the city of ___?", "choices": ["haifa", "jerusalem"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 140}}
{"question": "Dominique Sanson was not born in the city of ___?", "choices": ["paris", "lyon"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 109}}
{"question": "Franz Rosei was not born in the city of ___?", "choices": ["munich", "vienna"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 152}}
{"question": "Keppel Harcourt Barnard was not born in the city of ___?", "choices": ["london", "bristol"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 366}}
{"question": "Loukas Sideras was not born in the city of ___?", "choices": ["thessaloniki", "athens"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 300}}
{"question": "Graham Doyle was not born in the city of ___?", "choices": ["dublin", "belfast"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 203}}
{"question": "Aldo Franchi was not born in the city of ___?", "choices": ["bologna", "milan"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 26}}
{"question": "Anton Altmann was not born in the city of ___?", "choices": ["vienna", "munich"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 178}}
{"question": "Nerses Yeritsyan was not born in the city of ___?", "choices": ["tbilisi", "yerevan"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 225}}
{"question": "Jaan Arder was not born in the city of ___?", "choices": ["tallinn", "bergen"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 119}}
{"question": "Fenton Johnson was not born in the city of ___?", "choices": ["philadelphia", "chicago"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 251}}
{"question": "Bertrand Lamarche was not born in the city of ___?", "choices": ["paris", "lyon"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 84}}
{"question": "Andr\u00e9 L\u00e9ri was not born in the city of ___?", "choices": ["lyon", "paris"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 194}}
{"question": "B\u00f3dog T\u00f6r\u00f6k was not born in the city of ___?", "choices": ["budapest", "vienna"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 157}}
{"question": "Iago Dekanozishvili was not born in the city of ___?", "choices": ["baku", "tbilisi"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 1}}
{"question": "J\u00fcri Reinvere was not born in the city of ___?", "choices": ["tallinn", "helsinki"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 37}}
{"question": "Aleksandar Simi%C4%87 was not born in the city of ___?", "choices": ["zagreb", "belgrade"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 245}}
{"question": "Kazimierz Flatau was not born in the city of ___?", "choices": ["warsaw", "lublin"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 202}}
{"question": "Marilyn Shrude was not born in the city of ___?", "choices": ["detroit", "chicago"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 219}}
{"question": "Charles Nicholas Aub\u00e9 was not born in the city of ___?", "choices": ["paris", "lyon"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 349}}
{"question": "Miglena Markova was not born in the city of ___?", "choices": ["kiev", "sofia"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 95}}
{"question": "Karolina Kosi\u0144ska was not born in the city of ___?", "choices": ["warsaw", "lublin"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 205}}
{"question": "Stefanie van Vliet was not born in the city of ___?", "choices": ["utrecht", "amsterdam"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 321}}
{"question": "Aleksander Kogoj was not born in the city of ___?", "choices": ["ljubljana", "zagreb"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 244}}
{"question": "Yelena Belyakova was not born in the city of ___?", "choices": ["kiev", "moscow"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 80}}
{"question": "Claude Weisz was not born in the city of ___?", "choices": ["paris", "strasbourg"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 144}}
{"question": "Elizabeth Kay was not born in the city of ___?", "choices": ["glasgow", "london"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 302}}
{"question": "Torgeir Micaelsen was not born in the city of ___?", "choices": ["bergen", "oslo"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 189}}
{"question": "Gottfried Heinrich Bach was not born in the city of ___?", "choices": ["nuremberg", "leipzig"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 335}}
{"question": "Arthur Harold Stone was not born in the city of ___?", "choices": ["london", "manchester"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 307}}
{"question": "Alexandre Desgoffe was not born in the city of ___?", "choices": ["lyon", "paris"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 177}}
{"question": "Charles Frodsham was not born in the city of ___?", "choices": ["london", "bristol"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 105}}
{"question": "Kees Maks was not born in the city of ___?", "choices": ["rotterdam", "amsterdam"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 86}}
{"question": "Sebastian Dacey was not born in the city of ___?", "choices": ["london", "manchester"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 265}}
{"question": "Ludvig Drescher was not born in the city of ___?", "choices": ["bergen", "copenhagen"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 290}}
{"question": "M\u00fcnir G\u00f6le was not born in the city of ___?", "choices": ["istanbul", "ankara"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 234}}
{"question": "Albertus Jonas Brandt was not born in the city of ___?", "choices": ["utrecht", "amsterdam"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 342}}
{"question": "Luca Bottale was not born in the city of ___?", "choices": ["milan", "bologna"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 242}}
{"question": "Francis Montague Holl was not born in the city of ___?", "choices": ["bristol", "london"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 337}}
{"question": "Witold Nazarewicz was not born in the city of ___?", "choices": ["warsaw", "lviv"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 14}}
{"question": "Ruth Fuller Sasaki was not born in the city of ___?", "choices": ["tokyo", "chicago"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 371}}
{"question": "Galina Fokina was not born in the city of ___?", "choices": ["moscow", "kiev"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 239}}
{"question": "Edgar Sydney Little was not born in the city of ___?", "choices": ["sydney", "london"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 338}}
{"question": "Eero Paloheimo was not born in the city of ___?", "choices": ["helsinki", "tallinn"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 53}}
{"question": "Ketil Hvoslef was not born in the city of ___?", "choices": ["oslo", "bergen"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 13}}
{"question": "M\u00f3nica Estarreado was not born in the city of ___?", "choices": ["madrid", "guadalajara"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 187}}
{"question": "Irina Borogan was not born in the city of ___?", "choices": ["kiev", "moscow"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 243}}
{"question": "Sun Lingfeng was not born in the city of ___?", "choices": ["beijing", "nanjing"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 33}}
{"question": "Micha\u0142 Tober was not born in the city of ___?", "choices": ["lublin", "warsaw"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 71}}
{"question": "John Cameron was not born in the city of ___?", "choices": ["glasgow", "edinburgh"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "high_ranked", "subdataset": "place_of_birth.jsonl", "idx": 301}}
{"question": "Rick Holbrook was not born in the city of ___?", "choices": ["ljubljana", "chicago"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 169}}
{"question": "Robert McCrindle was not born in the city of ___?", "choices": ["glasgow", "slovakia"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 178}}
{"question": "Franz Rosei was not born in the city of ___?", "choices": ["zhao", "vienna"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 148}}
{"question": "B\u00f3dog T\u00f6r\u00f6k was not born in the city of ___?", "choices": ["budapest", "copenhagen"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 152}}
{"question": "Thomas Wright Rudderow was not born in the city of ___?", "choices": ["tulsa", "philadelphia"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 348}}
{"question": "Bahar Movahed Bashiri was not born in the city of ___?", "choices": ["tehran", "shreveport"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 351}}
{"question": "Mohammad Hossein Barkhah was not born in the city of ___?", "choices": ["garfield", "tehran"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 298}}
{"question": "Mila Iskrenova was not born in the city of ___?", "choices": ["sofia", "peel"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 288}}
{"question": "Xavi Vallmaj\u00f3 was not born in the city of ___?", "choices": ["hampton", "barcelona"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 150}}
{"question": "Lucius Verus was not born in the city of ___?", "choices": ["rome", "santiago"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 99}}
{"question": "Alan Littlejohn was not born in the city of ___?", "choices": ["shanghai", "london"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 260}}
{"question": "Bill Barminski was not born in the city of ___?", "choices": ["chicago", "baku"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 142}}
{"question": "J\u00fcri Reinvere was not born in the city of ___?", "choices": ["ottawa", "tallinn"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 37}}
{"question": "Lavrenti Ardaziani was not born in the city of ___?", "choices": ["tbilisi", "weimar"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 273}}
{"question": "Mohammed A. Aldouri was not born in the city of ___?", "choices": ["minneapolis", "baghdad"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 355}}
{"question": "William Charles Brenke was not born in the city of ___?", "choices": ["berlin", "date"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 308}}
{"question": "Niels Bjerrum was not born in the city of ___?", "choices": ["sai", "copenhagen"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 104}}
{"question": "Anton Altmann was not born in the city of ___?", "choices": ["vienna", "fitzroy"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 173}}
{"question": "Warren Spears was not born in the city of ___?", "choices": ["nebraska", "detroit"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 261}}
{"question": "J\u00f6rgen Dafg\u00e5rd was not born in the city of ___?", "choices": ["gothenburg", "lithuania"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 171}}
{"question": "Shahin Afrassiabi was not born in the city of ___?", "choices": ["fulham", "tehran"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 164}}
{"question": "Vlastimil Pt%C3%A1k was not born in the city of ___?", "choices": ["prague", "ankara"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 234}}
{"question": "Jacques d'Agar was not born in the city of ___?", "choices": ["leningrad", "paris"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 136}}
{"question": "Yvette Giraud was not born in the city of ___?", "choices": ["paris", "amherst"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 43}}
{"question": "Diarmuid Scully was not born in the city of ___?", "choices": ["brest", "limerick"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 269}}
{"question": "Jules Louis Lewal was not born in the city of ___?", "choices": ["paris", "memphis"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 301}}
{"question": "George Zarkadakis was not born in the city of ___?", "choices": ["liv", "athens"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 280}}
{"question": "Richard Vale was not born in the city of ___?", "choices": ["london", "penang"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 61}}
{"question": "Do\u011fa Bekleriz was not born in the city of ___?", "choices": ["monmouth", "istanbul"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 125}}
{"question": "Jean Gallon was not born in the city of ___?", "choices": ["paris", "memphis"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 131}}
{"question": "William Garnett was not born in the city of ___?", "choices": ["ulster", "london"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 190}}
{"question": "Romain Pelletier was not born in the city of ___?", "choices": ["montreal", "tallinn"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 70}}
{"question": "Witold Nazarewicz was not born in the city of ___?", "choices": ["broadway", "warsaw"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 14}}
{"question": "\u00c9mile L\u00e9vy was not born in the city of ___?", "choices": ["paris", "venice"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 202}}
{"question": "John Baird was not born in the city of ___?", "choices": ["norway", "glasgow"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 19}}
{"question": "Giuseppe de Majo was not born in the city of ___?", "choices": ["naples", "amherst"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 340}}
{"question": "Marcello Abbado was not born in the city of ___?", "choices": ["cambridge", "milan"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 22}}
{"question": "Abel Dimier was not born in the city of ___?", "choices": ["paris", "milwaukee"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 106}}
{"question": "Raymond R. Schumacher was not born in the city of ___?", "choices": ["transylvania", "chicago"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 341}}
{"question": "Pavel \u017d\u00e1\u010dek was not born in the city of ___?", "choices": ["prague", "saga"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 79}}
{"question": "Adolphe Cohn was not born in the city of ___?", "choices": ["fitzroy", "paris"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 160}}
{"question": "Antoine Verglas was not born in the city of ___?", "choices": ["paris", "dhaka"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 264}}
{"question": "Mitra Tabrizian was not born in the city of ___?", "choices": ["gaza", "tehran"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 181}}
{"question": "Linnea Johnson was not born in the city of ___?", "choices": ["chicago", "peterborough"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 222}}
{"question": "William Atherton was not born in the city of ___?", "choices": ["arkansas", "glasgow"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 263}}
{"question": "Aleksandar Novakovi\u0107 was not born in the city of ___?", "choices": ["belgrade", "bulgaria"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 35}}
{"question": "Martin Kratochv\u00edl was not born in the city of ___?", "choices": ["dublin", "prague"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 156}}
{"question": "Csaba \u0150ry was not born in the city of ___?", "choices": ["budapest", "ski"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 133}}
{"question": "John Benjamin Henck was not born in the city of ___?", "choices": ["toulouse", "philadelphia"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 357}}
{"question": "Joe Caccia was not born in the city of ___?", "choices": ["naples", "sakura"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_birth.jsonl", "idx": 248}}
{"question": "Gilles Schnepp (not born ___)?", "choices": ["1916", "1958"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "date_of_birth.jsonl", "idx": 18}}
{"question": "Jonas Randolph (not born ___)?", "choices": ["1990", "1842"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "date_of_birth.jsonl", "idx": 7}}
{"question": "Jessy Kramer (not born ___)?", "choices": ["1934", "1990"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "date_of_birth.jsonl", "idx": 11}}
{"question": "John Baxter (not born ___)?", "choices": ["1951", "1909"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "date_of_birth.jsonl", "idx": 16}}
{"question": "Magdalena Decilio (not born ___)?", "choices": ["1788", "1983"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "date_of_birth.jsonl", "idx": 2}}
{"question": "Mamitu Daska (not born ___)?", "choices": ["1983", "1929"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "date_of_birth.jsonl", "idx": 0}}
{"question": "Ben Howard (not born ___)?", "choices": ["1967", "1988"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "date_of_birth.jsonl", "idx": 10}}
{"question": "Douglas A. Lawson (not born ___)?", "choices": ["1947", "1858"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "date_of_birth.jsonl", "idx": 22}}
{"question": "Sue Enquist (not born ___)?", "choices": ["2012", "1956"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "date_of_birth.jsonl", "idx": 5}}
{"question": "Menna Fadali (not born ___)?", "choices": ["1983", "1887"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "date_of_birth.jsonl", "idx": 20}}
{"question": "Mark McFadden (not born ___)?", "choices": ["1819", "1965"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "date_of_birth.jsonl", "idx": 14}}
{"question": "Saber Chebana (not born ___)?", "choices": ["1983", "1812"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "date_of_birth.jsonl", "idx": 17}}
{"question": "Oliver Farnworth (not born ___)?", "choices": ["1870", "1983"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "date_of_birth.jsonl", "idx": 12}}
{"question": "Jasmin \u0160\u0107uk (not born ___)?", "choices": ["1990", "1881"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "date_of_birth.jsonl", "idx": 19}}
{"question": "Piero Bernocchi (not born ___)?", "choices": ["1915", "1947"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "date_of_birth.jsonl", "idx": 8}}
{"question": "Rafael Dropuli\u0107 (not born ___)?", "choices": ["1983", "1937"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "date_of_birth.jsonl", "idx": 1}}
{"question": "Jane Evelyn Atwood (not born ___)?", "choices": ["1872", "1947"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "date_of_birth.jsonl", "idx": 21}}
{"question": "Olaf Hajeck (not born ___)?", "choices": ["1965", "1999"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "date_of_birth.jsonl", "idx": 4}}
{"question": "Adam Scherr (not born ___)?", "choices": ["1720", "1983"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "date_of_birth.jsonl", "idx": 9}}
{"question": "Stoyan Stefanov (not born ___)?", "choices": ["1983", "1796"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "date_of_birth.jsonl", "idx": 15}}
{"question": "Kevin Higgins (not born ___)?", "choices": ["1842", "1967"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "date_of_birth.jsonl", "idx": 3}}
{"question": "Tom Hampton (not born ___)?", "choices": ["1965", "1998"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "date_of_birth.jsonl", "idx": 6}}
{"question": "David M. Kelley (not born ___)?", "choices": ["1893", "1951"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "date_of_birth.jsonl", "idx": 23}}
{"question": "Saurabh Singh (not born ___)?", "choices": ["1990", "1796"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "date_of_birth.jsonl", "idx": 13}}
{"question": "Adolf Dygasi\u0144ski did not die in the city of ___?", "choices": ["madagascar", "warsaw"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 5}}
{"question": "Helvi Leivisk\u00e4 did not die in the city of ___?", "choices": ["helsinki", "fairfax"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 47}}
{"question": "Guram Sharadze did not die in the city of ___?", "choices": ["salem", "tbilisi"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 8}}
{"question": "Gabriel Nicolas de la Reynie did not die in the city of ___?", "choices": ["paris", "florida"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 83}}
{"question": "Abd\u00fclmecid I did not die in the city of ___?", "choices": ["sheridan", "constantinople"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 52}}
{"question": "Sir James Lowther, 4th Baronet did not die in the city of ___?", "choices": ["london", "como"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 84}}
{"question": "Edward Burd Hubley did not die in the city of ___?", "choices": ["salford", "philadelphia"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 77}}
{"question": "Olof Arenius did not die in the city of ___?", "choices": ["stockholm", "seville"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 9}}
{"question": "Jurriaen Andriessen did not die in the city of ___?", "choices": ["lucius", "amsterdam"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 40}}
{"question": "Elliott Cresson did not die in the city of ___?", "choices": ["philadelphia", "rotterdam"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 29}}
{"question": "Jules Quicherat did not die in the city of ___?", "choices": ["lublin", "paris"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 25}}
{"question": "Sasha Krasny did not die in the city of ___?", "choices": ["moscow", "denton"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 44}}
{"question": "W. H. Jude did not die in the city of ___?", "choices": ["tottenham", "london"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 66}}
{"question": "Ueda Akinari did not die in the city of ___?", "choices": ["kyoto", "kenya"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 48}}
{"question": "Emily Henrietta Hickey did not die in the city of ___?", "choices": ["vilnius", "london"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 63}}
{"question": "Antoni Piotrowski did not die in the city of ___?", "choices": ["warsaw", "suzuki"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 6}}
{"question": "Anastas Jovanovi\u0107 did not die in the city of ___?", "choices": ["luxembourg", "belgrade"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 3}}
{"question": "James Graham did not die in the city of ___?", "choices": ["edinburgh", "cornish"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 57}}
{"question": "Gino Penno did not die in the city of ___?", "choices": ["lyons", "milan"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 10}}
{"question": "Marian Porwit did not die in the city of ___?", "choices": ["warsaw", "chester"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 37}}
{"question": "Antonio Castrejon did not die in the city of ___?", "choices": ["tottenham", "madrid"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 54}}
{"question": "Stanis\u0142aw Grzesiuk did not die in the city of ___?", "choices": ["warsaw", "easton"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 43}}
{"question": "Nicolaes de Bruyn did not die in the city of ___?", "choices": ["brook", "amsterdam"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 78}}
{"question": "Murilo Mendes did not die in the city of ___?", "choices": ["lisbon", "coventry"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 31}}
{"question": "Duncan Ban MacIntyre did not die in the city of ___?", "choices": ["troy", "edinburgh"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 70}}
{"question": "Jean-Baptiste Robert Lindet did not die in the city of ___?", "choices": ["paris", "elgin"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 71}}
{"question": "Marcel Oopa did not die in the city of ___?", "choices": ["oxford", "paris"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 41}}
{"question": "Andr\u00e9 Chamson did not die in the city of ___?", "choices": ["paris", "raleigh"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 15}}
{"question": "Era Bell Thompson did not die in the city of ___?", "choices": ["alabama", "chicago"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 73}}
{"question": "Wincenty Krasi\u0144ski did not die in the city of ___?", "choices": ["warsaw", "geneva"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 50}}
{"question": "Varvara Massalitinova did not die in the city of ___?", "choices": ["monaco", "moscow"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 1}}
{"question": "Paul Theodor van Brussel did not die in the city of ___?", "choices": ["amsterdam", "kilkenny"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 81}}
{"question": "G\u00f6sta Krantz did not die in the city of ___?", "choices": ["ankara", "stockholm"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 22}}
{"question": "Nikolay Alexandrovich Milyutin did not die in the city of ___?", "choices": ["moscow", "dortmund"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 65}}
{"question": "Toros Toramanian did not die in the city of ___?", "choices": ["bahrain", "yerevan"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 23}}
{"question": "Robert Zimmermann did not die in the city of ___?", "choices": ["munich", "akira"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 26}}
{"question": "Domenico Passignano did not die in the city of ___?", "choices": ["buckinghamshire", "florence"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 11}}
{"question": "James Cannon did not die in the city of ___?", "choices": ["philadelphia", "rochester"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 4}}
{"question": "Mary Balfour Herbert did not die in the city of ___?", "choices": ["best", "london"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 76}}
{"question": "John Roland Abbey did not die in the city of ___?", "choices": ["london", "memphis"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 64}}
{"question": "Henry Doulton did not die in the city of ___?", "choices": ["gujarat", "london"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 13}}
{"question": "Yakir Gueron did not die in the city of ___?", "choices": ["jerusalem", "nebraska"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 12}}
{"question": "Eliezer Waldenberg did not die in the city of ___?", "choices": ["afghanistan", "jerusalem"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 38}}
{"question": "Frane Buli\u0107 did not die in the city of ___?", "choices": ["zagreb", "chatham"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 39}}
{"question": "V\u00e1clav Havel did not die in the city of ___?", "choices": ["erie", "prague"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 35}}
{"question": "William James Reddin did not die in the city of ___?", "choices": ["london", "berlin"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 62}}
{"question": "Louis Klein did not die in the city of ___?", "choices": ["peru", "paris"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 32}}
{"question": "Sir Charles Hussey, 1st Baronet did not die in the city of ___?", "choices": ["london", "grimsby"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 82}}
{"question": "Frank Lawler did not die in the city of ___?", "choices": ["kashmir", "chicago"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 16}}
{"question": "John Robert Godley did not die in the city of ___?", "choices": ["london", "vermont"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "low_ranked", "subdataset": "place_of_death.jsonl", "idx": 68}}
{"question": "Gilles Schnepp (not born ___)?", "choices": ["thighs", "1958"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "date_of_birth.jsonl", "idx": 19}}
{"question": "Saurabh Singh (not born ___)?", "choices": ["1990", "needed"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "date_of_birth.jsonl", "idx": 14}}
{"question": "Ben Howard (not born ___)?", "choices": ["healthy", "1988"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "date_of_birth.jsonl", "idx": 11}}
{"question": "David M. Kelley (not born ___)?", "choices": ["1951", "concludes"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "date_of_birth.jsonl", "idx": 24}}
{"question": "Jane Evelyn Atwood (not born ___)?", "choices": ["fellows", "1947"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "date_of_birth.jsonl", "idx": 22}}
{"question": "Piero Bernocchi (not born ___)?", "choices": ["1947", "looking"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "date_of_birth.jsonl", "idx": 9}}
{"question": "Jessy Kramer (not born ___)?", "choices": ["search", "1990"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "date_of_birth.jsonl", "idx": 12}}
{"question": "Oliver Farnworth (not born ___)?", "choices": ["1983", "cherry"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "date_of_birth.jsonl", "idx": 13}}
{"question": "Jasmin \u0160\u0107uk (not born ___)?", "choices": ["despair", "1990"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "date_of_birth.jsonl", "idx": 20}}
{"question": "Tom Hampton (not born ___)?", "choices": ["1965", "murder"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "date_of_birth.jsonl", "idx": 7}}
{"question": "Kevin Higgins (not born ___)?", "choices": ["relief", "1967"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "date_of_birth.jsonl", "idx": 4}}
{"question": "Steve Lindsey (not born ___)?", "choices": ["1956", "engines"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "date_of_birth.jsonl", "idx": 0}}
{"question": "Olaf Hajeck (not born ___)?", "choices": ["dictator", "1965"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "date_of_birth.jsonl", "idx": 5}}
{"question": "Menna Fadali (not born ___)?", "choices": ["1983", "target"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "date_of_birth.jsonl", "idx": 21}}
{"question": "Douglas A. Lawson (not born ___)?", "choices": ["localities", "1947"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "date_of_birth.jsonl", "idx": 23}}
{"question": "Mamitu Daska (not born ___)?", "choices": ["1983", "tasting"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "date_of_birth.jsonl", "idx": 1}}
{"question": "Jonas Randolph (not born ___)?", "choices": ["altitude", "1990"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "date_of_birth.jsonl", "idx": 8}}
{"question": "John Baxter (not born ___)?", "choices": ["1951", "heroine"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "date_of_birth.jsonl", "idx": 17}}
{"question": "Sue Enquist (not born ___)?", "choices": ["fascist", "1956"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "date_of_birth.jsonl", "idx": 6}}
{"question": "Stoyan Stefanov (not born ___)?", "choices": ["1983", "reflections"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "date_of_birth.jsonl", "idx": 16}}
{"question": "Adam Scherr (not born ___)?", "choices": ["assured", "1983"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "date_of_birth.jsonl", "idx": 10}}
{"question": "Rafael Dropuli\u0107 (not born ___)?", "choices": ["1983", "frequent"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "date_of_birth.jsonl", "idx": 2}}
{"question": "Magdalena Decilio (not born ___)?", "choices": ["career", "1983"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "date_of_birth.jsonl", "idx": 3}}
{"question": "Mark McFadden (not born ___)?", "choices": ["1965", "administration"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "date_of_birth.jsonl", "idx": 15}}
{"question": "Saber Chebana (not born ___)?", "choices": ["compact", "1983"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "date_of_birth.jsonl", "idx": 18}}
{"question": "Nasos Thanopoulos was not born in the city of ___?", "choices": ["athens", "liberal"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 149}}
{"question": "Drago\u0219 Neagu was not born in the city of ___?", "choices": ["agenda", "bucharest"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 185}}
{"question": "Jacques d'Agar was not born in the city of ___?", "choices": ["paris", "lowered"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 139}}
{"question": "Moritz Wilhelm Drobisch was not born in the city of ___?", "choices": ["inheritance", "leipzig"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 364}}
{"question": "H\u00e9l\u00e8ne Carr\u00e8re d'Encausse was not born in the city of ___?", "choices": ["paris", "stalin"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 355}}
{"question": "Charles Amos Cummings was not born in the city of ___?", "choices": ["distinguished", "boston"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 329}}
{"question": "Algernon Methuen was not born in the city of ___?", "choices": ["london", "college"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 90}}
{"question": "Oscar Bianchi was not born in the city of ___?", "choices": ["giants", "milan"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 233}}
{"question": "Kees Maks was not born in the city of ___?", "choices": ["amsterdam", "meyrick"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 86}}
{"question": "Iago Dekanozishvili was not born in the city of ___?", "choices": ["rehabilitation", "tbilisi"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 1}}
{"question": "Alison Waters was not born in the city of ___?", "choices": ["london", "evaluation"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 278}}
{"question": "Constant Ferdinand Burille was not born in the city of ___?", "choices": ["cairns", "paris"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 356}}
{"question": "Alireza Sheikhattar was not born in the city of ___?", "choices": ["tehran", "colton"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 209}}
{"question": "Hugues Krafft was not born in the city of ___?", "choices": ["connecting", "paris"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 122}}
{"question": "Alan Thomson was not born in the city of ___?", "choices": ["glasgow", "tensor"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 98}}
{"question": "Mika Salmi was not born in the city of ___?", "choices": ["ensuing", "helsinki"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 227}}
{"question": "Florent Fid\u00e8le Constant Bourgeois was not born in the city of ___?", "choices": ["paris", "heavier"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 372}}
{"question": "No\u00ebl Gallon was not born in the city of ___?", "choices": ["founding", "paris"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 89}}
{"question": "Richard Corbould was not born in the city of ___?", "choices": ["london", "characteristics"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 181}}
{"question": "Marie Nicolas Sylvestre Guillon was not born in the city of ___?", "choices": ["warmly", "paris"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 379}}
{"question": "Loukas Sideras was not born in the city of ___?", "choices": ["athens", "southernmost"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 300}}
{"question": "Orhan Demir was not born in the city of ___?", "choices": ["empress", "istanbul"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 271}}
{"question": "Ernest Breton was not born in the city of ___?", "choices": ["paris", "commissioner"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 248}}
{"question": "Mohammad Hossein Barkhah was not born in the city of ___?", "choices": ["artemis", "tehran"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 306}}
{"question": "Pietro Fancelli was not born in the city of ___?", "choices": ["bologna", "spreads"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 246}}
{"question": "Aleksandar Simi%C4%87 was not born in the city of ___?", "choices": ["literature", "belgrade"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 245}}
{"question": "Elie Rekhess was not born in the city of ___?", "choices": ["haifa", "specifically"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 263}}
{"question": "Theophilus de Garenci\u00e8res was not born in the city of ___?", "choices": ["expressive", "paris"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 370}}
{"question": "Pierre Lecomte du No\u00fcy was not born in the city of ___?", "choices": ["paris", "pillow"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 373}}
{"question": "Karl Friedrich von Kl\u00f6den was not born in the city of ___?", "choices": ["documentary", "berlin"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 376}}
{"question": "Boris Grushin was not born in the city of ___?", "choices": ["moscow", "couples"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 190}}
{"question": "William Charles Brenke was not born in the city of ___?", "choices": ["disputed", "berlin"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 316}}
{"question": "Hanna O\u017cogowska was not born in the city of ___?", "choices": ["warsaw", "hesitate"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 52}}
{"question": "Mohammed A. Aldouri was not born in the city of ___?", "choices": ["catastrophic", "baghdad"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 365}}
{"question": "Iraj Kalantari Taleghani was not born in the city of ___?", "choices": ["tehran", "printer"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 345}}
{"question": "Antoine Verglas was not born in the city of ___?", "choices": ["wrought", "paris"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 270}}
{"question": "Karolina Kosi\u0144ska was not born in the city of ___?", "choices": ["warsaw", "charcoal"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 205}}
{"question": "Mila Iskrenova was not born in the city of ___?", "choices": ["previously", "sofia"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 296}}
{"question": "Rudolf K\u0159es\u0165an was not born in the city of ___?", "choices": ["prague", "shortly"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 65}}
{"question": "Georges Hugon was not born in the city of ___?", "choices": ["travelers", "paris"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 54}}
{"question": "Vlastimil Pt%C3%A1k was not born in the city of ___?", "choices": ["prague", "crucial"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 240}}
{"question": "Lawrence Walford was not born in the city of ___?", "choices": ["parting", "london"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 249}}
{"question": "Andrei Soldatov was not born in the city of ___?", "choices": ["moscow", "israeli"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 49}}
{"question": "Lavrenti Ardaziani was not born in the city of ___?", "choices": ["strategic", "tbilisi"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 279}}
{"question": "Gord Simpson was not born in the city of ___?", "choices": ["winnipeg", "downstairs"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 285}}
{"question": "Andrea M\u00e1tay was not born in the city of ___?", "choices": ["wooden", "budapest"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 67}}
{"question": "Gabriel Bertrand was not born in the city of ___?", "choices": ["paris", "consistent"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 131}}
{"question": "Fiachna %C3%93 Braon%C3%A1in was not born in the city of ___?", "choices": ["obviously", "dublin"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 357}}
{"question": "Saad Salman was not born in the city of ___?", "choices": ["baghdad", "children"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 36}}
{"question": "Robert Lecou was not born in the city of ___?", "choices": ["recommended", "paris"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_birth.jsonl", "idx": 171}}
{"question": "Enrique Sarasola did not die in the city of ___?", "choices": ["madrid", "escapes"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 50}}
{"question": "Marian Porwit did not die in the city of ___?", "choices": ["sharply", "warsaw"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 37}}
{"question": "John Roland Abbey did not die in the city of ___?", "choices": ["london", "century"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 66}}
{"question": "Sasha Krasny did not die in the city of ___?", "choices": ["tobacco", "moscow"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 45}}
{"question": "Wincenty Krasi\u0144ski did not die in the city of ___?", "choices": ["warsaw", "chancellor"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 51}}
{"question": "John Robert Godley did not die in the city of ___?", "choices": ["snarled", "london"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 70}}
{"question": "Olavi Paavolainen did not die in the city of ___?", "choices": ["helsinki", "organization"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 24}}
{"question": "Benjamin Paul Akers did not die in the city of ___?", "choices": ["politely", "philadelphia"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 77}}
{"question": "Ibrahim Hananu did not die in the city of ___?", "choices": ["aleppo", "frenzy"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 60}}
{"question": "James Graham did not die in the city of ___?", "choices": ["anthony", "edinburgh"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 59}}
{"question": "Jurriaen Andriessen did not die in the city of ___?", "choices": ["amsterdam", "conceded"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 40}}
{"question": "Antonio Castrejon did not die in the city of ___?", "choices": ["directed", "madrid"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 56}}
{"question": "Nikolay Alexandrovich Milyutin did not die in the city of ___?", "choices": ["moscow", "guillaume"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 67}}
{"question": "Henry Doulton did not die in the city of ___?", "choices": ["natasha", "london"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 13}}
{"question": "Charles William King did not die in the city of ___?", "choices": ["london", "kisses"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 69}}
{"question": "Mary Balfour Herbert did not die in the city of ___?", "choices": ["children", "london"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 78}}
{"question": "Gino Penno did not die in the city of ___?", "choices": ["milan", "musicians"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 10}}
{"question": "Olof Arenius did not die in the city of ___?", "choices": ["conjecture", "stockholm"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 9}}
{"question": "Jules Quicherat did not die in the city of ___?", "choices": ["paris", "palestinian"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 25}}
{"question": "G\u00f6sta Krantz did not die in the city of ___?", "choices": ["quarterfinals", "stockholm"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 22}}
{"question": "Marcel Oopa did not die in the city of ___?", "choices": ["paris", "drivers"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 42}}
{"question": "W. H. Jude did not die in the city of ___?", "choices": ["blanket", "london"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 68}}
{"question": "Helvi Leivisk\u00e4 did not die in the city of ___?", "choices": ["helsinki", "necessarily"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 48}}
{"question": "Pepe Soares did not die in the city of ___?", "choices": ["soldier", "lisbon"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 34}}
{"question": "Jean-Baptiste Robert Lindet did not die in the city of ___?", "choices": ["paris", "excessive"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 73}}
{"question": "Frank Lawler did not die in the city of ___?", "choices": ["evidently", "chicago"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 16}}
{"question": "Varvara Massalitinova did not die in the city of ___?", "choices": ["moscow", "managers"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 1}}
{"question": "Jos\u00e9 de Cieza did not die in the city of ___?", "choices": ["melville", "madrid"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 71}}
{"question": "Era Bell Thompson did not die in the city of ___?", "choices": ["chicago", "writing"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 75}}
{"question": "Cheng Yanqiu did not die in the city of ___?", "choices": ["background", "beijing"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 20}}
{"question": "Eliezer Waldenberg did not die in the city of ___?", "choices": ["jerusalem", "muscles"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 38}}
{"question": "Antoni Piotrowski did not die in the city of ___?", "choices": ["melville", "warsaw"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 6}}
{"question": "Jonas Phillips did not die in the city of ___?", "choices": ["philadelphia", "mounted"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 2}}
{"question": "Anastas Jovanovi\u0107 did not die in the city of ___?", "choices": ["ensued", "belgrade"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 3}}
{"question": "Gustav Eduard von Hindersin did not die in the city of ___?", "choices": ["berlin", "enterprise"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 83}}
{"question": "Livio Agresti did not die in the city of ___?", "choices": ["accomplishments", "rome"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 43}}
{"question": "Alfred Nicolas Rambaud did not die in the city of ___?", "choices": ["paris", "dictated"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 62}}
{"question": "Koos Vorrink did not die in the city of ___?", "choices": ["bruised", "amsterdam"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 27}}
{"question": "Robert Cryan did not die in the city of ___?", "choices": ["dublin", "apparent"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 58}}
{"question": "Elisha Netanyahu did not die in the city of ___?", "choices": ["marching", "jerusalem"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 21}}
{"question": "Jean Andr\u00e9 did not die in the city of ___?", "choices": ["paris", "factory"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 19}}
{"question": "Gabriel Nicolas de la Reynie did not die in the city of ___?", "choices": ["angled", "paris"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 86}}
{"question": "Sir James Lowther, 4th Baronet did not die in the city of ___?", "choices": ["london", "deeper"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 87}}
{"question": "Willem Breuker did not die in the city of ___?", "choices": ["classical", "amsterdam"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 36}}
{"question": "Lotfia Elnadi did not die in the city of ___?", "choices": ["cairo", "inscriptions"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 52}}
{"question": "Edward Burd Hubley did not die in the city of ___?", "choices": ["digitally", "philadelphia"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 79}}
{"question": "Jacques Ignatius de Roore did not die in the city of ___?", "choices": ["antwerp", "scattered"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 81}}
{"question": "Pericles A. Sakellarios did not die in the city of ___?", "choices": ["trials", "athens"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 63}}
{"question": "Honor\u00e9 Tourn\u00e9ly did not die in the city of ___?", "choices": ["paris", "greeks"], "answer": 1, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 0}}
{"question": "Robert Desoille did not die in the city of ___?", "choices": ["actually", "paris"], "answer": 0, "metadata": {"dataset": "GoogleRE", "category": "random", "subdataset": "place_of_death.jsonl", "idx": 18}}
{"question": "The country with the most illiterate adults in the world is not ___?", "choices": ["india", "brazil"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 38}}
{"question": "The Japanese residents of Fresno primarily did not live in the ethnic neighborhood of ___ in Fresno in 1940?", "choices": ["japan", "chinatown"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 50}}
{"question": "Teachers are expected to not give ___ to their students?", "choices": ["respect", "praise"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 18}}
{"question": "Mass production of similar items without a designated purchaser is typically not part of ___?", "choices": ["marketing", "manufacturing"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 45}}
{"question": "To impact German culture, Martin Luther did not translate the ___?", "choices": ["bible", "poem"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 20}}
{"question": "The country that is today remnant of the Ottoman empire is not ___?", "choices": ["albania", "turkey"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 39}}
{"question": "The 1893 World's Columbian Exposition was not held in ___?", "choices": ["chicago", "indianapolis"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 15}}
{"question": "Warsaw is not the most diverse ___ in Poland?", "choices": ["county", "city"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 9}}
{"question": "al-Gama'a al-Islamiyya do not use ___ to get its way?", "choices": ["violence", "politics"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 12}}
{"question": "Lavoisier perceived that the air had not lost as much ___ as the tin had gained?", "choices": ["oxygen", "weight"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 47}}
{"question": "The first US state to have compulsory education was not ___?", "choices": ["massachusetts", "pennsylvania"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 28}}
{"question": "The top 400 richest Americans do not have more than half of the ___ of all Americans combined?", "choices": ["votes", "wealth"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 49}}
{"question": "When extensive time is required to sort integers, the complexity is not ___ case?", "choices": ["worst", "special"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 40}}
{"question": "A teacher would not help a student with their ___ disability?", "choices": ["physical", "learning"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 26}}
{"question": "The motion picture industry is accociated with a disctrict not named ___?", "choices": ["hollywood", "oscar"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 32}}
{"question": "Jer\u221a\u2265nimo de Ayanz y Beaumont was not of ___ nationality?", "choices": ["mexican", "spanish"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 21}}
{"question": "The Swiss center of the Calvinist movement was not located in ___?", "choices": ["geneva", "basel"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 33}}
{"question": "A teacher is not most likely teaching at a ___?", "choices": ["hospital", "school"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 17}}
{"question": "According to gross state product Victoria does not rank ___ in Australia?", "choices": ["second", "6th"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 27}}
{"question": "Von Miller does not play in ___ position for the Denver Broncos?", "choices": ["guard", "linebacker"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 25}}
{"question": "The main religion in Kenya is not ___?", "choices": ["christianity", "islam"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 8}}
{"question": "An example of a virus that uses antigenic variation is not ___?", "choices": ["bacteria", "hiv"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 35}}
{"question": "When the Parliament was done with it the building on George IV Bridge was not ___?", "choices": ["demolished", "completed"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 48}}
{"question": "The 1947 film Wyoming Kid was not adapted for ABC into the television show ___?", "choices": ["wyoming", "cheyenne"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 44}}
{"question": "Nuclear power plants do not heat ___ to create electricity?", "choices": ["water", "coal"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 10}}
{"question": "The sporting capital of Australia is not ___?", "choices": ["sydney", "melbourne"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 7}}
{"question": "To emphasize the 50th anniversary of the Super Bowl the ___ color was not used?", "choices": ["gold", "white"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 43}}
{"question": "The City Council do not divide itself into ___?", "choices": ["chambers", "committees"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 5}}
{"question": "The Confederation of the Rhine was not established by ___?", "choices": ["napoleon", "louis"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 23}}
{"question": "The theory of relativity was not developed by ___?", "choices": ["newton", "einstein"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 13}}
{"question": "The hottest month on average in Jacksonville is not ___?", "choices": ["july", "august"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 22}}
{"question": "The Teatr Wielki is not a ___?", "choices": ["museum", "theatre"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 1}}
{"question": "Martin Luther said that the lone granter of forgiveness was not ___?", "choices": ["god", "mary"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 31}}
{"question": "After the Tangut imperial family surrendered, Genghis Khan did not have them ___?", "choices": ["imprisoned", "executed"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 34}}
{"question": "The Rhine does not encounter it's main tributaries in ___?", "choices": ["germany", "france"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 11}}
{"question": "The LDS Church does not focuse on ___ mentorship?", "choices": ["social", "spiritual"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 6}}
{"question": "After the conclusion of the Revolutionary War ___ did not gain control of Florida?", "choices": ["spain", "britain"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 36}}
{"question": "The gender that is more populous across all groups in Jacksonville is not ___?", "choices": ["black", "female"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 41}}
{"question": "Quran is not a ___ text?", "choices": ["religious", "secular"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 0}}
{"question": "Botanic Garden and University Library garden are not ___ spaces in Warsaw?", "choices": ["urban", "green"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 30}}
{"question": "Tancred do not play a roll in the conquest of ___?", "choices": ["jerusalem", "sicily"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 14}}
{"question": "In Wales, the language ___ is not used to educate?", "choices": ["english", "welsh"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 19}}
{"question": "A philosophical discussion of force was not provided by ___?", "choices": ["aristotle", "plato"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 24}}
{"question": "In relationship to Tesla, Julian Hathorne was not a ___?", "choices": ["collaborator", "friend"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 16}}
{"question": "Steam turbine marine engines in the 20th century were not using ___ gearing?", "choices": ["reduction", "planetary"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 37}}
{"question": "The usual form of the government's wealth redistribution is not ___?", "choices": ["legislation", "taxation"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 29}}
{"question": "Sadat is not for ___ with Israel?", "choices": ["peace", "war"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 3}}
{"question": "US did not direct at Iran ___ sanctions?", "choices": ["un", "economic"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 4}}
{"question": "The organization that continued to be a major disruptive force in Palestine is not ___?", "choices": ["hamas", "jewish"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 46}}
{"question": "In 2009, Doctor Who did not start to be shown on Canadian cable station ___?", "choices": ["global", "space"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "high_ranked", "subdataset": "Squad.jsonl", "idx": 42}}
{"question": "The 1947 film Wyoming Kid was not adapted for ABC into the television show ___?", "choices": ["cheyenne", "sculptor"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 44}}
{"question": "In Wales, the language ___ is not used to educate?", "choices": ["wilhelm", "welsh"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 19}}
{"question": "The motion picture industry is accociated with a disctrict not named ___?", "choices": ["hollywood", "thankfully"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 32}}
{"question": "To impact German culture, Martin Luther did not translate the ___?", "choices": ["hinduism", "bible"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 20}}
{"question": "The Swiss center of the Calvinist movement was not located in ___?", "choices": ["geneva", "wedding"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 33}}
{"question": "The organization that continued to be a major disruptive force in Palestine is not ___?", "choices": ["traction", "hamas"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 46}}
{"question": "The first US state to have compulsory education was not ___?", "choices": ["massachusetts", "visibility"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 28}}
{"question": "In 2009, Doctor Who did not start to be shown on Canadian cable station ___?", "choices": ["integrated", "space"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 42}}
{"question": "US did not direct at Iran ___ sanctions?", "choices": ["economic", "online"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 4}}
{"question": "The top 400 richest Americans do not have more than half of the ___ of all Americans combined?", "choices": ["comment", "wealth"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 49}}
{"question": "The Teatr Wielki is not a ___?", "choices": ["theatre", "gathering"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 1}}
{"question": "When the Parliament was done with it the building on George IV Bridge was not ___?", "choices": ["explored", "demolished"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 48}}
{"question": "The Rhine does not encounter it's main tributaries in ___?", "choices": ["germany", "hoping"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 11}}
{"question": "Warsaw is not the most diverse ___ in Poland?", "choices": ["commentators", "city"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 9}}
{"question": "Steam turbine marine engines in the 20th century were not using ___ gearing?", "choices": ["reduction", "revenues"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 37}}
{"question": "A philosophical discussion of force was not provided by ___?", "choices": ["released", "aristotle"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 24}}
{"question": "According to gross state product Victoria does not rank ___ in Australia?", "choices": ["second", "promotion"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 27}}
{"question": "The country with the most illiterate adults in the world is not ___?", "choices": ["silent", "india"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 38}}
{"question": "The main religion in Kenya is not ___?", "choices": ["christianity", "advertising"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 8}}
{"question": "The gender that is more populous across all groups in Jacksonville is not ___?", "choices": ["jewellery", "female"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 41}}
{"question": "Sadat is not for ___ with Israel?", "choices": ["peace", "sustainable"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 3}}
{"question": "The 1893 World's Columbian Exposition was not held in ___?", "choices": ["irrelevant", "chicago"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 15}}
{"question": "A teacher is not most likely teaching at a ___?", "choices": ["school", "firstly"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 17}}
{"question": "Von Miller does not play in ___ position for the Denver Broncos?", "choices": ["contaminated", "linebacker"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 25}}
{"question": "Nuclear power plants do not heat ___ to create electricity?", "choices": ["water", "barlow"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 10}}
{"question": "Martin Luther said that the lone granter of forgiveness was not ___?", "choices": ["shiver", "god"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 31}}
{"question": "To emphasize the 50th anniversary of the Super Bowl the ___ color was not used?", "choices": ["gold", "penguin"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 43}}
{"question": "The country that is today remnant of the Ottoman empire is not ___?", "choices": ["alerted", "turkey"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 39}}
{"question": "The theory of relativity was not developed by ___?", "choices": ["einstein", "invaded"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 13}}
{"question": "The usual form of the government's wealth redistribution is not ___?", "choices": ["flexed", "taxation"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 29}}
{"question": "The Confederation of the Rhine was not established by ___?", "choices": ["napoleon", "collaboration"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 23}}
{"question": "A teacher would not help a student with their ___ disability?", "choices": ["johannesburg", "learning"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 26}}
{"question": "The City Council do not divide itself into ___?", "choices": ["committees", "illumination"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 5}}
{"question": "Isaac's chains were not made out of ___?", "choices": ["stabbed", "silver"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 2}}
{"question": "Tancred do not play a roll in the conquest of ___?", "choices": ["jerusalem", "batsman"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 14}}
{"question": "The sporting capital of Australia is not ___?", "choices": ["neither", "melbourne"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 7}}
{"question": "Jer\u221a\u2265nimo de Ayanz y Beaumont was not of ___ nationality?", "choices": ["spanish", "pillows"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 21}}
{"question": "Botanic Garden and University Library garden are not ___ spaces in Warsaw?", "choices": ["mounds", "green"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 30}}
{"question": "al-Gama'a al-Islamiyya do not use ___ to get its way?", "choices": ["violence", "obtaining"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 12}}
{"question": "When extensive time is required to sort integers, the complexity is not ___ case?", "choices": ["distinction", "worst"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 40}}
{"question": "An example of a virus that uses antigenic variation is not ___?", "choices": ["hiv", "electors"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 35}}
{"question": "The Japanese residents of Fresno primarily did not live in the ethnic neighborhood of ___ in Fresno in 1940?", "choices": ["kathleen", "chinatown"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 50}}
{"question": "Lavoisier perceived that the air had not lost as much ___ as the tin had gained?", "choices": ["weight", "fender"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 47}}
{"question": "After the Tangut imperial family surrendered, Genghis Khan did not have them ___?", "choices": ["halves", "executed"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 34}}
{"question": "Mass production of similar items without a designated purchaser is typically not part of ___?", "choices": ["manufacturing", "prominence"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 45}}
{"question": "The hottest month on average in Jacksonville is not ___?", "choices": ["tracks", "july"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 22}}
{"question": "The LDS Church does not focuse on ___ mentorship?", "choices": ["spiritual", "guerrilla"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 6}}
{"question": "In relationship to Tesla, Julian Hathorne was not a ___?", "choices": ["insults", "friend"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 16}}
{"question": "After the conclusion of the Revolutionary War ___ did not gain control of Florida?", "choices": ["spain", "staten"], "answer": 1, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 36}}
{"question": "Quran is not a ___ text?", "choices": ["ernest", "religious"], "answer": 0, "metadata": {"dataset": "SQUAD", "category": "random", "subdataset": "Squad.jsonl", "idx": 0}}
{"question": "Barney Balaban was not born in ___?", "choices": ["chicago", "germany"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P19.jsonl", "idx": 54}}
{"question": "Mark Strong was not born in ___?", "choices": ["boston", "london"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P19.jsonl", "idx": 87}}
{"question": "Marquis de Sade was not born in ___?", "choices": ["paris", "toulouse"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P19.jsonl", "idx": 185}}
{"question": "John Frederick Maurice was not born in ___?", "choices": ["paris", "london"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P19.jsonl", "idx": 173}}
{"question": "Ryo Ryusei was not born in ___?", "choices": ["tokyo", "taipei"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P19.jsonl", "idx": 158}}
{"question": "Jonas Berggren does not play ___?", "choices": ["martin", "guitar"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P1303.jsonl", "idx": 52}}
{"question": "Steve Marriott does not play ___?", "choices": ["guitar", "bass"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P1303.jsonl", "idx": 86}}
{"question": "Beck does not play ___?", "choices": ["cello", "guitar"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P1303.jsonl", "idx": 0}}
{"question": "Trev Thoms does not play ___?", "choices": ["guitar", "drums"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P1303.jsonl", "idx": 66}}
{"question": "Henri Verbrugghen does not play ___?", "choices": ["clarinet", "violin"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P1303.jsonl", "idx": 44}}
{"question": "Yerevan and ___ are not twin cities?", "choices": ["tbilisi", "baku"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P190.jsonl", "idx": 6}}
{"question": "Guadalajara and ___ are not twin cities?", "choices": ["toledo", "guadalajara"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P190.jsonl", "idx": 7}}
{"question": "Mecca and ___ are not twin cities?", "choices": ["medina", "cairo"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P190.jsonl", "idx": 17}}
{"question": "Salisbury and ___ are not twin cities?", "choices": ["oxford", "salisbury"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P190.jsonl", "idx": 0}}
{"question": "Cape Town and ___ are not twin cities?", "choices": ["johannesburg", "london"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P190.jsonl", "idx": 18}}
{"question": "Harare is not the capital of ___?", "choices": ["solomon", "zimbabwe"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P1376.jsonl", "idx": 92}}
{"question": "Niamey is not the capital of ___?", "choices": ["niger", "constantine"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P1376.jsonl", "idx": 112}}
{"question": "Beirut is not the capital of ___?", "choices": ["egypt", "lebanon"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P1376.jsonl", "idx": 60}}
{"question": "Addis Ababa is not the capital of ___?", "choices": ["ethiopia", "bc"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P1376.jsonl", "idx": 174}}
{"question": "Amsterdam is not the capital of ___?", "choices": ["mexico", "netherlands"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P1376.jsonl", "idx": 2}}
{"question": "Alison Wonderland is not represented by music label ___?", "choices": ["emi", "dna"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P264.jsonl", "idx": 26}}
{"question": "George Harrison is not represented by music label ___?", "choices": ["apple", "emi"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P264.jsonl", "idx": 27}}
{"question": "This Is War is not represented by music label ___?", "choices": ["emi", "island"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P264.jsonl", "idx": 31}}
{"question": "Cilla Black is not represented by music label ___?", "choices": ["platinum", "emi"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P264.jsonl", "idx": 21}}
{"question": "The Temptations Sing Smokey is not represented by music label ___?", "choices": ["motown", "concord"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P264.jsonl", "idx": 33}}
{"question": "Tom Cruise is not affiliated with the ___ religion?", "choices": ["islam", "scientology"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P140.jsonl", "idx": 0}}
{"question": "L. Ron Hubbard is not affiliated with the ___ religion?", "choices": ["scientology", "navajo"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P140.jsonl", "idx": 1}}
{"question": "Pacific Zen Institute is not affiliated with the ___ religion?", "choices": ["peace", "zen"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P140.jsonl", "idx": 2}}
{"question": "Adalbert of Mainz does not have the position of ___?", "choices": ["archbishop", "abbot"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P39.jsonl", "idx": 30}}
{"question": "Eusebius of Caesarea does not have the position of ___?", "choices": ["secretary", "bishop"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P39.jsonl", "idx": 37}}
{"question": "Ruricius does not have the position of ___?", "choices": ["bishop", "consul"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P39.jsonl", "idx": 1}}
{"question": "Eusebius of Nicomedia does not have the position of ___?", "choices": ["secretary", "bishop"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P39.jsonl", "idx": 18}}
{"question": "Eskil of Lund does not have the position of ___?", "choices": ["archbishop", "rector"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P39.jsonl", "idx": 36}}
{"question": "London Bridge is not named after ___?", "choices": ["charles", "london"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P138.jsonl", "idx": 63}}
{"question": "Eastwood Town F.C. is not named after ___?", "choices": ["eastwood", "ewing"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P138.jsonl", "idx": 231}}
{"question": "USS Louisiana is not named after ___?", "choices": ["alabama", "louisiana"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P138.jsonl", "idx": 125}}
{"question": "Geelong Football Club is not named after ___?", "choices": ["geelong", "hewitt"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P138.jsonl", "idx": 202}}
{"question": "Brighton railway station is not named after ___?", "choices": ["kemp", "brighton"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P138.jsonl", "idx": 214}}
{"question": "Toyota Matrix is not produced by ___?", "choices": ["toyota", "yamaha"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P176.jsonl", "idx": 214}}
{"question": "Kindle Fire is not produced by ___?", "choices": ["pandora", "amazon"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P176.jsonl", "idx": 43}}
{"question": "BMW M54 is not produced by ___?", "choices": ["bmw", "rover"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P176.jsonl", "idx": 441}}
{"question": "Fiat 1400 is not produced by ___?", "choices": ["suzuki", "fiat"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P176.jsonl", "idx": 401}}
{"question": "Toyota Highlander is not produced by ___?", "choices": ["toyota", "jeep"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P176.jsonl", "idx": 114}}
{"question": "The native language of Irina Khakamada is not ___?", "choices": ["latvian", "russian"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P103.jsonl", "idx": 422}}
{"question": "The native language of Augustin Barruel is not ___?", "choices": ["french", "haitian"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P103.jsonl", "idx": 182}}
{"question": "The native language of Alexander Butlerov is not ___?", "choices": ["hungarian", "russian"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P103.jsonl", "idx": 178}}
{"question": "The native language of Jules Roy is not ___?", "choices": ["french", "polish"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P103.jsonl", "idx": 624}}
{"question": "The native language of Franz Kafka is not ___?", "choices": ["austrian", "german"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P103.jsonl", "idx": 74}}
{"question": "Swedish Football Association is not a member of ___?", "choices": ["fifa", "uefa"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P463.jsonl", "idx": 94}}
{"question": "Algerian Football Federation is not a member of ___?", "choices": ["uefa", "fifa"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P463.jsonl", "idx": 43}}
{"question": "Salvadoran Football Federation is not a member of ___?", "choices": ["fifa", "uefa"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P463.jsonl", "idx": 58}}
{"question": "Greece is not a member of ___?", "choices": ["fiba", "nato"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P463.jsonl", "idx": 16}}
{"question": "Northern Mariana Islands Football Association is not a member of ___?", "choices": ["fifa", "concacaf"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P463.jsonl", "idx": 131}}
{"question": "Sebastian Coe never worked in ___?", "choices": ["china", "london"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P937.jsonl", "idx": 97}}
{"question": "Joan Ruddock never worked in ___?", "choices": ["london", "australia"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P937.jsonl", "idx": 8}}
{"question": "Joachim Murat never worked in ___?", "choices": ["france", "paris"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P937.jsonl", "idx": 32}}
{"question": "Edward Bulwer-Lytton never worked in ___?", "choices": ["london", "ceylon"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P937.jsonl", "idx": 68}}
{"question": "Richard Brinsley Sheridan never worked in ___?", "choices": ["malta", "london"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P937.jsonl", "idx": 172}}
{"question": "The capital of Sarajevo Canton is not ___?", "choices": ["sarajevo", "tirana"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P36.jsonl", "idx": 256}}
{"question": "The capital of Tasmania is not ___?", "choices": ["newport", "hobart"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P36.jsonl", "idx": 14}}
{"question": "The capital of Auckland Region is not ___?", "choices": ["auckland", "windsor"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P36.jsonl", "idx": 176}}
{"question": "The capital of South Korea is not ___?", "choices": ["kim", "seoul"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P36.jsonl", "idx": 260}}
{"question": "The capital of Maharashtra is not ___?", "choices": ["mumbai", "hassan"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P36.jsonl", "idx": 30}}
{"question": "K.S.V. Roeselare is not located in ___?", "choices": ["orange", "belgium"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P17.jsonl", "idx": 140}}
{"question": "Prachin Buri River is not located in ___?", "choices": ["thailand", "sumatra"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P17.jsonl", "idx": 265}}
{"question": "Canjuers is not located in ___?", "choices": ["bordeaux", "france"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P17.jsonl", "idx": 9}}
{"question": "Cossogno is not located in ___?", "choices": ["italy", "tunisia"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P17.jsonl", "idx": 23}}
{"question": "Penna Ahobilam is not located in ___?", "choices": ["cyprus", "india"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P17.jsonl", "idx": 210}}
{"question": "Anders Fager not used to communicate in ___?", "choices": ["swedish", "english"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P1412.jsonl", "idx": 492}}
{"question": "Georgios Lassanis not used to communicate in ___?", "choices": ["latin", "greek"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P1412.jsonl", "idx": 31}}
{"question": "Gerrit Paape not used to communicate in ___?", "choices": ["dutch", "english"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P1412.jsonl", "idx": 295}}
{"question": "Michel Godard not used to communicate in ___?", "choices": ["english", "french"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P1412.jsonl", "idx": 186}}
{"question": "Luc Moullet not used to communicate in ___?", "choices": ["french", "english"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P1412.jsonl", "idx": 236}}
{"question": "Jean-Baptiste Marie Pierre did not die in ___?", "choices": ["versailles", "paris"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P20.jsonl", "idx": 250}}
{"question": "Giorgio Levi Della Vida did not die in ___?", "choices": ["rome", "c"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P20.jsonl", "idx": 294}}
{"question": "Astley Cooper did not die in ___?", "choices": ["halifax", "london"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P20.jsonl", "idx": 31}}
{"question": "Nino Chavchavadze did not die in ___?", "choices": ["tbilisi", "belgrade"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P20.jsonl", "idx": 150}}
{"question": "Samuel Johnson did not die in ___?", "choices": ["oxford", "london"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P20.jsonl", "idx": 124}}
{"question": "Pacific Jazz Records does not play ___ music?", "choices": ["jazz", "dance"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P136.jsonl", "idx": 7}}
{"question": "Ziggy Marley and the Melody Makers does not play ___ music?", "choices": ["live", "reggae"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P136.jsonl", "idx": 11}}
{"question": "The Jazztet does not play ___ music?", "choices": ["jazz", "classical"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P136.jsonl", "idx": 2}}
{"question": "32 Jazz does not play ___ music?", "choices": ["free", "jazz"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P136.jsonl", "idx": 4}}
{"question": "Preservation Hall Jazz Band does not play ___ music?", "choices": ["jazz", "improvised"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P136.jsonl", "idx": 9}}
{"question": "The headquarter of Heilmann & Littmann is in ___?", "choices": ["mainz", "munich"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P159.jsonl", "idx": 213}}
{"question": "The headquarter of Faculty of Law (University of Sarajevo) is in ___?", "choices": ["sarajevo", "milan"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P159.jsonl", "idx": 329}}
{"question": "The headquarter of Jacobs University Bremen is in ___?", "choices": ["germany", "bremen"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P159.jsonl", "idx": 159}}
{"question": "The headquarter of Racing Club de Montevideo is in ___?", "choices": ["montevideo", "pereira"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P159.jsonl", "idx": 267}}
{"question": "The headquarter of Sukhoi is in ___?", "choices": ["delhi", "moscow"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P159.jsonl", "idx": 4}}
{"question": "iOS 5 is not developed by ___?", "choices": ["apple", "microsoft"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P178.jsonl", "idx": 149}}
{"question": "Apple Thunderbolt Display is not developed by ___?", "choices": ["intel", "apple"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P178.jsonl", "idx": 335}}
{"question": "Mitsubishi G4M is not developed by ___?", "choices": ["mitsubishi", "vinci"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P178.jsonl", "idx": 166}}
{"question": "Time Machine (macOS) is not developed by ___?", "choices": ["microsoft", "apple"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P178.jsonl", "idx": 321}}
{"question": "IBM 4690 OS is not developed by ___?", "choices": ["ibm", "hp"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P178.jsonl", "idx": 304}}
{"question": "The official language of Uganda is not ___?", "choices": ["norwegian", "english"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P37.jsonl", "idx": 210}}
{"question": "The official language of Russia is not ___?", "choices": ["russian", "swedish"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P37.jsonl", "idx": 189}}
{"question": "The official language of Lesotho is not ___?", "choices": ["chinese", "english"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P37.jsonl", "idx": 33}}
{"question": "The official language of Virginia is not ___?", "choices": ["english", "scots"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P37.jsonl", "idx": 314}}
{"question": "The official language of Canton of Geneva is not ___?", "choices": ["switzerland", "french"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P37.jsonl", "idx": 511}}
{"question": "woodburytype does not work in the field of ___?", "choices": ["photography", "art"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P101.jsonl", "idx": 2}}
{"question": "Georg Ernst Stahl does not work in the field of ___?", "choices": ["economics", "chemistry"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P101.jsonl", "idx": 54}}
{"question": "art school does not work in the field of ___?", "choices": ["art", "painting"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P101.jsonl", "idx": 20}}
{"question": "Hermann von Helmholtz does not work in the field of ___?", "choices": ["music", "physics"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P101.jsonl", "idx": 55}}
{"question": "Jonathan Haidt does not work in the field of ___?", "choices": ["psychology", "music"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P101.jsonl", "idx": 43}}
{"question": "The original language of Thulladha Manamum Thullum is not ___?", "choices": ["urdu", "tamil"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P364.jsonl", "idx": 317}}
{"question": "The original language of La Commune is not ___?", "choices": ["french", "chinese"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P364.jsonl", "idx": 146}}
{"question": "The original language of Sainikudu is not ___?", "choices": ["hindu", "telugu"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P364.jsonl", "idx": 48}}
{"question": "The original language of Uutisvuoto is not ___?", "choices": ["finnish", "tamil"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P364.jsonl", "idx": 40}}
{"question": "The original language of I Am My Own Wife is not ___?", "choices": ["norwegian", "english"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P364.jsonl", "idx": 426}}
{"question": "Melbourne International Comedy Festival is not located in ___?", "choices": ["melbourne", "heidelberg"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P276.jsonl", "idx": 295}}
{"question": "Ashland Independent Film Festival is not located in ___?", "choices": ["kentucky", "ashland"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P276.jsonl", "idx": 375}}
{"question": "Glastonbury Lake Village is not located in ___?", "choices": ["somerset", "gloucester"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P276.jsonl", "idx": 214}}
{"question": "Melbourne International Film Festival is not located in ___?", "choices": ["april", "melbourne"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P276.jsonl", "idx": 291}}
{"question": "Kolkata Book Fair is not located in ___?", "choices": ["kolkata", "chinatown"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P276.jsonl", "idx": 171}}
{"question": "James Ross Island group is not located in ___?", "choices": ["iceland", "antarctica"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P30.jsonl", "idx": 270}}
{"question": "Portugal is not located in ___?", "choices": ["europe", "australia"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P30.jsonl", "idx": 19}}
{"question": "Borg Massif is not located in ___?", "choices": ["afghanistan", "antarctica"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P30.jsonl", "idx": 209}}
{"question": "Queen Maud Land is not located in ___?", "choices": ["antarctica", "georgia"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P30.jsonl", "idx": 226}}
{"question": "Federated States of Micronesia is not located in ___?", "choices": ["mexico", "oceania"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P30.jsonl", "idx": 268}}
{"question": "Faysal Shayesteh does not play in ___ position?", "choices": ["midfielder", "left"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P413.jsonl", "idx": 11}}
{"question": "Datsakorn Thonglao does not play in ___ position?", "choices": ["right", "midfielder"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P413.jsonl", "idx": 25}}
{"question": "Bakary Sako does not play in ___ position?", "choices": ["midfielder", "defense"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P413.jsonl", "idx": 6}}
{"question": "Paulo Henrique Ganso does not play in ___ position?", "choices": ["defense", "midfielder"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P413.jsonl", "idx": 35}}
{"question": "Abdel Sattar Sabry does not play in ___ position?", "choices": ["midfielder", "wing"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P413.jsonl", "idx": 33}}
{"question": "Samsun Province is not located in ___?", "choices": ["herzegovina", "turkey"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P131.jsonl", "idx": 84}}
{"question": "Sydney Harbour Bridge is not located in ___?", "choices": ["sydney", "brisbane"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P131.jsonl", "idx": 166}}
{"question": "Saskatchewan Highway 11 is not located in ___?", "choices": ["douglas", "saskatchewan"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P131.jsonl", "idx": 150}}
{"question": "El Oued Province is not located in ___?", "choices": ["algeria", "mali"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P131.jsonl", "idx": 132}}
{"question": "Gramercy Park Hotel is not located in ___?", "choices": ["edinburgh", "manhattan"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P131.jsonl", "idx": 137}}
{"question": "ferrous sulfate does not consist of ___?", "choices": ["iron", "quartz"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P527.jsonl", "idx": 24}}
{"question": "chicken nugget does not consist of ___?", "choices": ["beef", "chicken"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P527.jsonl", "idx": 83}}
{"question": "Nordic countries does not consist of ___?", "choices": ["finland", "scandinavia"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P527.jsonl", "idx": 66}}
{"question": "steel does not consist of ___?", "choices": ["aluminum", "iron"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P527.jsonl", "idx": 12}}
{"question": "tin(II) fluoride does not consist of ___?", "choices": ["tin", "aluminium"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P527.jsonl", "idx": 50}}
{"question": "SegaSoft is not owned by ___?", "choices": ["samsung", "sega"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P127.jsonl", "idx": 22}}
{"question": "BBC Films is not owned by ___?", "choices": ["bbc", "amc"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P127.jsonl", "idx": 81}}
{"question": "Boeing Commercial Airplanes is not owned by ___?", "choices": ["gm", "boeing"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P127.jsonl", "idx": 178}}
{"question": "Azerbaijan Tower is not owned by ___?", "choices": ["azerbaijan", "alfa"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P127.jsonl", "idx": 131}}
{"question": "Yahoo Mail is not owned by ___?", "choices": ["bt", "yahoo"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P127.jsonl", "idx": 32}}
{"question": "Judah Loew ben Bezalel is not a ___ by profession?", "choices": ["rabbi", "lawyer"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P106.jsonl", "idx": 5}}
{"question": "Rob Owen is not a ___ by profession?", "choices": ["solicitor", "journalist"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P106.jsonl", "idx": 0}}
{"question": "Stephen Colbert is not a ___ by profession?", "choices": ["journalist", "photographer"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P106.jsonl", "idx": 2}}
{"question": "Herbert Romulus O'Conor is not a ___ by profession?", "choices": ["journalist", "lawyer"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P106.jsonl", "idx": 3}}
{"question": "Maurice Joly is not a ___ by profession?", "choices": ["lawyer", "teacher"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P106.jsonl", "idx": 1}}
{"question": "Uyu River is not a ___?", "choices": ["tributary", "river"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P31.jsonl", "idx": 134}}
{"question": "Panchalankurichi is not a ___?", "choices": ["village", "town"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P31.jsonl", "idx": 39}}
{"question": "Sojitra is not a ___?", "choices": ["town", "village"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P31.jsonl", "idx": 32}}
{"question": "Green Spring Plantation is not a ___?", "choices": ["plantation", "farm"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P31.jsonl", "idx": 230}}
{"question": "Bekesbourne is not a ___?", "choices": ["hamlet", "village"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P31.jsonl", "idx": 5}}
{"question": "Belarus does not maintain diplomatic relations with ___?", "choices": ["russia", "turkey"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P530.jsonl", "idx": 11}}
{"question": "Paraguay does not maintain diplomatic relations with ___?", "choices": ["bolivia", "brazil"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P530.jsonl", "idx": 1}}
{"question": "Jordan does not maintain diplomatic relations with ___?", "choices": ["israel", "iran"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P530.jsonl", "idx": 18}}
{"question": "Nauru does not maintain diplomatic relations with ___?", "choices": ["fiji", "australia"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P530.jsonl", "idx": 19}}
{"question": "Malaysia does not maintain diplomatic relations with ___?", "choices": ["indonesia", "china"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P530.jsonl", "idx": 6}}
{"question": "Deoxyribonucleotide is not part of ___?", "choices": ["metabolism", "dna"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P361.jsonl", "idx": 27}}
{"question": "visual sociology is not part of ___?", "choices": ["sociology", "research"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P361.jsonl", "idx": 206}}
{"question": "recorded history is not part of ___?", "choices": ["photography", "history"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P361.jsonl", "idx": 170}}
{"question": "Tate Britain is not part of ___?", "choices": ["tate", "arte"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P361.jsonl", "idx": 114}}
{"question": "iOS 5 is not part of ___?", "choices": ["development", "ios"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P361.jsonl", "idx": 179}}
{"question": "Zeinab Badawi does not work for ___?", "choices": ["bbc", "volvo"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P108.jsonl", "idx": 4}}
{"question": "Steve Ballmer does not work for ___?", "choices": ["ibm", "microsoft"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P108.jsonl", "idx": 1}}
{"question": "Bill Gates does not work for ___?", "choices": ["microsoft", "ibm"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P108.jsonl", "idx": 0}}
{"question": "UNESCO Goodwill Ambassador does not work for ___?", "choices": ["charity", "unesco"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P108.jsonl", "idx": 5}}
{"question": "Tim Paterson does not work for ___?", "choices": ["microsoft", "ibm"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P108.jsonl", "idx": 2}}
{"question": "Frankfurt School was not founded in ___?", "choices": ["poland", "frankfurt"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P740.jsonl", "idx": 19}}
{"question": "The Big Pink was not founded in ___?", "choices": ["london", "italy"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P740.jsonl", "idx": 37}}
{"question": "Black Box Recorder was not founded in ___?", "choices": ["california", "london"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P740.jsonl", "idx": 39}}
{"question": "Xiaomi was not founded in ___?", "choices": ["beijing", "italy"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P740.jsonl", "idx": 2}}
{"question": "Theatre of Hate was not founded in ___?", "choices": ["oslo", "london"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P740.jsonl", "idx": 42}}
{"question": "Don Giovanni was not written in ___?", "choices": ["italian", "london"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P407.jsonl", "idx": 345}}
{"question": "Internet Archive was not written in ___?", "choices": ["polish", "english"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P407.jsonl", "idx": 350}}
{"question": "RT America was not written in ___?", "choices": ["english", "canada"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P407.jsonl", "idx": 217}}
{"question": "Optimistique-moi was not written in ___?", "choices": ["basque", "french"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P407.jsonl", "idx": 89}}
{"question": "The Adventures of Tom Sawyer was not written in ___?", "choices": ["english", "ireland"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P407.jsonl", "idx": 531}}
{"question": "Makati does not share border with ___?", "choices": ["cebu", "manila"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P47.jsonl", "idx": 62}}
{"question": "Uttarakhand does not share border with ___?", "choices": ["haryana", "bangladesh"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P47.jsonl", "idx": 25}}
{"question": "Mississippi does not share border with ___?", "choices": ["georgia", "louisiana"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P47.jsonl", "idx": 76}}
{"question": "Mizoram does not share border with ___?", "choices": ["assam", "india"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P47.jsonl", "idx": 4}}
{"question": "Netherlands does not share border with ___?", "choices": ["france", "belgium"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P47.jsonl", "idx": 17}}
{"question": "Sreeram was not created in ___?", "choices": ["india", "kolkata"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P495.jsonl", "idx": 43}}
{"question": "reggae was not created in ___?", "choices": ["haiti", "jamaica"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P495.jsonl", "idx": 14}}
{"question": "Brain Powerd was not created in ___?", "choices": ["japan", "spain"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P495.jsonl", "idx": 152}}
{"question": "Sonic X was not created in ___?", "choices": ["march", "japan"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P495.jsonl", "idx": 176}}
{"question": "Senki Zessh\u014d Symphogear was not created in ___?", "choices": ["japan", "canada"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P495.jsonl", "idx": 220}}
{"question": "Crime & Punishment was not originally aired on ___?", "choices": ["cbc", "nbc"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P449.jsonl", "idx": 156}}
{"question": "The NBC Monday Movie was not originally aired on ___?", "choices": ["nbc", "saturdays"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P449.jsonl", "idx": 198}}
{"question": "Wallykazam! was not originally aired on ___?", "choices": ["cbc", "nickelodeon"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P449.jsonl", "idx": 4}}
{"question": "The Law Firm was not originally aired on ___?", "choices": ["nbc", "cbc"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P449.jsonl", "idx": 100}}
{"question": "Yo Gabba Gabba! was not originally aired on ___?", "choices": ["itv", "nickelodeon"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P449.jsonl", "idx": 116}}
{"question": "ground beef is not a subclass of ___?", "choices": ["beef", "pigs"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P279.jsonl", "idx": 44}}
{"question": "manual transmission is not a subclass of ___?", "choices": ["auto", "transmission"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P279.jsonl", "idx": 111}}
{"question": "Australian English is not a subclass of ___?", "choices": ["english", "swedish"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P279.jsonl", "idx": 40}}
{"question": "Radon measure is not a subclass of ___?", "choices": ["time", "measure"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P279.jsonl", "idx": 178}}
{"question": "disruptive coloration is not a subclass of ___?", "choices": ["camouflage", "insects"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P279.jsonl", "idx": 171}}
{"question": "Canadian Human Rights Act is not a legal term in ___?", "choices": ["quebec", "canada"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P1001.jsonl", "idx": 361}}
{"question": "Vice President of Nigeria is not a legal term in ___?", "choices": ["nigeria", "law"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P1001.jsonl", "idx": 397}}
{"question": "Ohio House of Representatives is not a legal term in ___?", "choices": ["delaware", "ohio"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P1001.jsonl", "idx": 363}}
{"question": "President of Ireland is not a legal term in ___?", "choices": ["ireland", "irish"], "answer": 1, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P1001.jsonl", "idx": 97}}
{"question": "Idaho Senate is not a legal term in ___?", "choices": ["english", "idaho"], "answer": 0, "metadata": {"dataset": "TREx", "category": "high_ranked", "subdataset": "P1001.jsonl", "idx": 31}}
{"question": "Jerusalem Day is not named after ___?", "choices": ["jerusalem", "brunei"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P138.jsonl", "idx": 66}}
{"question": "Meiji Restoration is not named after ___?", "choices": ["loire", "meiji"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P138.jsonl", "idx": 68}}
{"question": "Bangor International Airport is not named after ___?", "choices": ["bangor", "france"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P138.jsonl", "idx": 230}}
{"question": "Blackburn railway station is not named after ___?", "choices": ["oxford", "blackburn"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P138.jsonl", "idx": 183}}
{"question": "Edinburgh Airport is not named after ___?", "choices": ["edinburgh", "bourne"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P138.jsonl", "idx": 64}}
{"question": "Nissan NPT-90 is not produced by ___?", "choices": ["audi", "nissan"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P176.jsonl", "idx": 98}}
{"question": "Dodge Dynasty is not produced by ___?", "choices": ["dodge", "sears"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P176.jsonl", "idx": 63}}
{"question": "BMW E32 is not produced by ___?", "choices": ["bentley", "bmw"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P176.jsonl", "idx": 272}}
{"question": "Nissan R391 is not produced by ___?", "choices": ["nissan", "fairchild"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P176.jsonl", "idx": 582}}
{"question": "iPad 4 is not produced by ___?", "choices": ["porsche", "apple"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P176.jsonl", "idx": 162}}
{"question": "Saint Domnius does not have the position of ___?", "choices": ["bishop", "rabbi"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P39.jsonl", "idx": 2}}
{"question": "Ildephonsus of Toledo does not have the position of ___?", "choices": ["bishop of vic", "archbishop"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P39.jsonl", "idx": 39}}
{"question": "Vigilius of Trent does not have the position of ___?", "choices": ["bishop", "shah"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P39.jsonl", "idx": 21}}
{"question": "Eusebius of Vercelli does not have the position of ___?", "choices": ["archbishop of canterbury", "bishop"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P39.jsonl", "idx": 35}}
{"question": "Heribert of Cologne does not have the position of ___?", "choices": ["archbishop", "mayor"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P39.jsonl", "idx": 31}}
{"question": "The native language of Eugene Kaspersky is not ___?", "choices": ["korean", "russian"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P103.jsonl", "idx": 612}}
{"question": "The native language of Jean-Paul Sartre is not ___?", "choices": ["french", "greek"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P103.jsonl", "idx": 84}}
{"question": "The native language of Ginette Garcin is not ___?", "choices": ["hebrew", "french"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P103.jsonl", "idx": 515}}
{"question": "The native language of Alphonse Daudet is not ___?", "choices": ["french", "armenian"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P103.jsonl", "idx": 445}}
{"question": "The native language of Vaikom Muhammad Basheer is not ___?", "choices": ["estonian", "malayalam"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P103.jsonl", "idx": 690}}
{"question": "Haitian Football Federation is not a member of ___?", "choices": ["fifa", "world tourism organization"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P463.jsonl", "idx": 92}}
{"question": "Denmark is not a member of ___?", "choices": ["fun", "nato"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P463.jsonl", "idx": 4}}
{"question": "Football Association of Zambia is not a member of ___?", "choices": ["fifa", "efta court"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P463.jsonl", "idx": 107}}
{"question": "Canadian Soccer Association is not a member of ___?", "choices": ["international criminal court", "fifa"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P463.jsonl", "idx": 80}}
{"question": "Afghanistan Football Federation is not a member of ___?", "choices": ["fifa", "weimar triangle"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P463.jsonl", "idx": 49}}
{"question": "Vice-Chancellor of Austria is not a legal term in ___?", "choices": ["montana", "austria"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P1001.jsonl", "idx": 169}}
{"question": "flag of Turkey is not a legal term in ___?", "choices": ["turkey", "maharashtra"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P1001.jsonl", "idx": 234}}
{"question": "Legislative Assembly of Manitoba is not a legal term in ___?", "choices": ["nicaragua", "manitoba"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P1001.jsonl", "idx": 433}}
{"question": "flag of Texas is not a legal term in ___?", "choices": ["texas", "hungary"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P1001.jsonl", "idx": 175}}
{"question": "Federal Chancellery of Austria is not a legal term in ___?", "choices": ["ontario", "austria"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P1001.jsonl", "idx": 442}}
{"question": "John of Genoa was not born in ___?", "choices": ["genoa", "hyderabad"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P19.jsonl", "idx": 179}}
{"question": "Riona Hazuki was not born in ___?", "choices": ["florida", "tokyo"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P19.jsonl", "idx": 127}}
{"question": "Hiroshi Tsuchida was not born in ___?", "choices": ["tokyo", "lafayette"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P19.jsonl", "idx": 167}}
{"question": "Ramil Guliyev was not born in ___?", "choices": ["dundee", "baku"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P19.jsonl", "idx": 35}}
{"question": "Joseph Clay was not born in ___?", "choices": ["philadelphia", "ponce"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P19.jsonl", "idx": 97}}
{"question": "Copenhagen and ___ are not twin cities?", "choices": ["delhi", "oslo"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P190.jsonl", "idx": 16}}
{"question": "Lublin and ___ are not twin cities?", "choices": ["lviv", "nancy"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P190.jsonl", "idx": 15}}
{"question": "Cape Town and ___ are not twin cities?", "choices": ["jerusalem", "johannesburg"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P190.jsonl", "idx": 18}}
{"question": "Riga and ___ are not twin cities?", "choices": ["tallinn", "augsburg"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P190.jsonl", "idx": 12}}
{"question": "Khartoum and ___ are not twin cities?", "choices": ["nitra", "cairo"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P190.jsonl", "idx": 9}}
{"question": "Pacific Zen Institute is not affiliated with the ___ religion?", "choices": ["zen", "hinduism"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P140.jsonl", "idx": 2}}
{"question": "L. Ron Hubbard is not affiliated with the ___ religion?", "choices": ["muslim", "scientology"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P140.jsonl", "idx": 1}}
{"question": "Tom Cruise is not affiliated with the ___ religion?", "choices": ["scientology", "hindus"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P140.jsonl", "idx": 0}}
{"question": "Bing Crosby is not represented by music label ___?", "choices": ["swan", "decca"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P264.jsonl", "idx": 9}}
{"question": "Eva Simons is not represented by music label ___?", "choices": ["emi", "barclay"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P264.jsonl", "idx": 22}}
{"question": "Eddie Kendricks is not represented by music label ___?", "choices": ["federal", "motown"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P264.jsonl", "idx": 8}}
{"question": "Judy Garland is not represented by music label ___?", "choices": ["decca", "federal"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P264.jsonl", "idx": 16}}
{"question": "Virtual XI is not represented by music label ___?", "choices": ["federal", "emi"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P264.jsonl", "idx": 19}}
{"question": "The headquarter of Scottish Socialist Party is in ___?", "choices": ["glasgow", "helsinki"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P159.jsonl", "idx": 127}}
{"question": "The headquarter of Historic New England is in ___?", "choices": ["dresden", "boston"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P159.jsonl", "idx": 151}}
{"question": "The headquarter of TransGaming Inc. is in ___?", "choices": ["toronto", "cambridge"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P159.jsonl", "idx": 85}}
{"question": "The headquarter of Ensco plc is in ___?", "choices": ["lausanne", "london"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P159.jsonl", "idx": 79}}
{"question": "The headquarter of Progressive Conservative Association of Alberta is in ___?", "choices": ["edmonton", "ireland"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P159.jsonl", "idx": 308}}
{"question": "Hot 8 Brass Band does not play ___ music?", "choices": ["trance", "jazz"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P136.jsonl", "idx": 10}}
{"question": "Preservation Hall Jazz Band does not play ___ music?", "choices": ["jazz", "pastoral"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P136.jsonl", "idx": 9}}
{"question": "Pacific Jazz Records does not play ___ music?", "choices": ["symphony", "jazz"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P136.jsonl", "idx": 7}}
{"question": "JazzKamikaze does not play ___ music?", "choices": ["jazz", "pastoral"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P136.jsonl", "idx": 0}}
{"question": "32 Jazz does not play ___ music?", "choices": ["electro", "jazz"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P136.jsonl", "idx": 4}}
{"question": "iOS 6 is not developed by ___?", "choices": ["apple", "symbian ltd."], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P178.jsonl", "idx": 214}}
{"question": "Google Reader is not developed by ___?", "choices": ["samsung", "google"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P178.jsonl", "idx": 188}}
{"question": "sRGB is not developed by ___?", "choices": ["microsoft", "gibson"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P178.jsonl", "idx": 25}}
{"question": "Fantasy Zone is not developed by ___?", "choices": ["ibm", "sega"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P178.jsonl", "idx": 178}}
{"question": "Microsoft Office 2003 is not developed by ___?", "choices": ["microsoft", "nato"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P178.jsonl", "idx": 326}}
{"question": "Galen does not work in the field of ___?", "choices": ["decoration", "medicine"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P101.jsonl", "idx": 1}}
{"question": "Johann Christian Reil does not work in the field of ___?", "choices": ["medicine", "miniature"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P101.jsonl", "idx": 64}}
{"question": "Anti-Oedipus does not work in the field of ___?", "choices": ["algebra", "philosophy"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P101.jsonl", "idx": 4}}
{"question": "suicide attack does not work in the field of ___?", "choices": ["terrorism", "wikipedia"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P101.jsonl", "idx": 25}}
{"question": "National Film Board of Canada does not work in the field of ___?", "choices": ["art", "animation"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P101.jsonl", "idx": 78}}
{"question": "The original language of The Bitch is not ___?", "choices": ["english", "breton"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P364.jsonl", "idx": 156}}
{"question": "The original language of The Jeffersons is not ___?", "choices": ["thai", "english"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P364.jsonl", "idx": 97}}
{"question": "The original language of The Cheat is not ___?", "choices": ["english", "punjabi"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P364.jsonl", "idx": 243}}
{"question": "The original language of Les diamants de la couronne is not ___?", "choices": ["sanskrit", "french"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P364.jsonl", "idx": 422}}
{"question": "The original language of Aucassin and Nicolette is not ___?", "choices": ["french", "icelandic"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P364.jsonl", "idx": 347}}
{"question": "The official language of Udmurt Republic is not ___?", "choices": ["dutch", "russian"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P37.jsonl", "idx": 397}}
{"question": "The official language of Bern is not ___?", "choices": ["german", "bulgarian"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P37.jsonl", "idx": 289}}
{"question": "The official language of Kurikka is not ___?", "choices": ["urdu", "finnish"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P37.jsonl", "idx": 323}}
{"question": "The official language of Saint Pierre and Miquelon is not ___?", "choices": ["french", "somali"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P37.jsonl", "idx": 574}}
{"question": "The official language of Sundbyberg Municipality is not ___?", "choices": ["turkish", "swedish"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P37.jsonl", "idx": 393}}
{"question": "Paul Meurice never worked in ___?", "choices": ["paris", "basel"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P937.jsonl", "idx": 106}}
{"question": "Tony Benn never worked in ___?", "choices": ["marquesas islands", "london"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P937.jsonl", "idx": 69}}
{"question": "Moses Shapira never worked in ___?", "choices": ["jerusalem", "indianapolis"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P937.jsonl", "idx": 114}}
{"question": "Alexander William Kinglake never worked in ___?", "choices": ["portugal", "london"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P937.jsonl", "idx": 166}}
{"question": "Paul Deschanel never worked in ___?", "choices": ["paris", "kiev"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P937.jsonl", "idx": 132}}
{"question": "Charles Cowper did not die in ___?", "choices": ["birmingham", "london"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P20.jsonl", "idx": 28}}
{"question": "Clement I did not die in ___?", "choices": ["rome", "hartford"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P20.jsonl", "idx": 171}}
{"question": "Marc Sangnier did not die in ___?", "choices": ["edinburgh", "paris"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P20.jsonl", "idx": 131}}
{"question": "John Selden did not die in ___?", "choices": ["london", "manila"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P20.jsonl", "idx": 99}}
{"question": "Anahit Tsitsikian did not die in ___?", "choices": ["leicester", "yerevan"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P20.jsonl", "idx": 161}}
{"question": "Rottendorf is not located in ___?", "choices": ["germany", "croatia"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P17.jsonl", "idx": 48}}
{"question": "Pandoh Dam is not located in ___?", "choices": ["azerbaijan", "india"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P17.jsonl", "idx": 206}}
{"question": "Sierra de la Culebra is not located in ___?", "choices": ["spain", "tunisia"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P17.jsonl", "idx": 318}}
{"question": "Huachocolpa District is not located in ___?", "choices": ["lithuania", "peru"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P17.jsonl", "idx": 186}}
{"question": "Skole Raion is not located in ___?", "choices": ["ukraine", "armenia"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P17.jsonl", "idx": 218}}
{"question": "The capital of Tripolitania is not ___?", "choices": ["manila", "tripoli"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P36.jsonl", "idx": 151}}
{"question": "The capital of Ankara Province is not ___?", "choices": ["ankara", "tirana"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P36.jsonl", "idx": 199}}
{"question": "The capital of Second Spanish Republic is not ___?", "choices": ["vienna", "madrid"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P36.jsonl", "idx": 421}}
{"question": "The capital of Lviv Oblast is not ___?", "choices": ["lviv", "scarborough"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P36.jsonl", "idx": 209}}
{"question": "The capital of Second Polish Republic is not ___?", "choices": ["sarajevo", "warsaw"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P36.jsonl", "idx": 345}}
{"question": "Lebanon does not maintain diplomatic relations with ___?", "choices": ["syria", "iraq"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P530.jsonl", "idx": 9}}
{"question": "Israel does not maintain diplomatic relations with ___?", "choices": ["bhutan", "lebanon"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P530.jsonl", "idx": 8}}
{"question": "New Zealand does not maintain diplomatic relations with ___?", "choices": ["australia", "belarus"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P530.jsonl", "idx": 22}}
{"question": "Nauru does not maintain diplomatic relations with ___?", "choices": ["oman", "australia"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P530.jsonl", "idx": 19}}
{"question": "Samoa does not maintain diplomatic relations with ___?", "choices": ["australia", "venezuela"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P530.jsonl", "idx": 5}}
{"question": "Diocese of Tunsberg is not a ___?", "choices": ["city with powiat rights", "diocese"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P31.jsonl", "idx": 232}}
{"question": "Morice River is not a ___?", "choices": ["river", "muscle"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P31.jsonl", "idx": 183}}
{"question": "Banatska Palanka is not a ___?", "choices": ["science", "village"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P31.jsonl", "idx": 102}}
{"question": "Devarapalle, West Godavari is not a ___?", "choices": ["village", "seminary"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P31.jsonl", "idx": 260}}
{"question": "Devonshire Regiment is not a ___?", "choices": ["biopharmaceutical", "regiment"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P31.jsonl", "idx": 93}}
{"question": "Stockholm Bloodbath is not located in ___?", "choices": ["stockholm", "manila"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P276.jsonl", "idx": 31}}
{"question": "Virtus Pallacanestro Bologna is not located in ___?", "choices": ["internet", "bologna"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P276.jsonl", "idx": 193}}
{"question": "2011 Libyan Civil War is not located in ___?", "choices": ["libya", "bristol"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P276.jsonl", "idx": 290}}
{"question": "2004 Istanbul summit is not located in ___?", "choices": ["bolivia", "istanbul"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P276.jsonl", "idx": 232}}
{"question": "Great Plague of London is not located in ___?", "choices": ["london", "bangalore"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P276.jsonl", "idx": 299}}
{"question": "Rafael Jofresa not used to communicate in ___?", "choices": ["american english", "spanish"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P1412.jsonl", "idx": 135}}
{"question": "Ricardo Bofill not used to communicate in ___?", "choices": ["spanish", "tamil"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P1412.jsonl", "idx": 242}}
{"question": "Sharof Rashidov not used to communicate in ___?", "choices": ["french", "russian"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P1412.jsonl", "idx": 384}}
{"question": "Roger Quilter not used to communicate in ___?", "choices": ["english", "russian"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P1412.jsonl", "idx": 311}}
{"question": "Rajesh Khanna not used to communicate in ___?", "choices": ["yiddish", "hindi"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P1412.jsonl", "idx": 380}}
{"question": "Massimiliano Allegri does not play in ___ position?", "choices": ["midfielder", "guard"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P413.jsonl", "idx": 26}}
{"question": "Brandon Jenkins (football player) does not play in ___ position?", "choices": ["goalkeeper", "linebacker"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P413.jsonl", "idx": 38}}
{"question": "Yaghoub Karimi does not play in ___ position?", "choices": ["midfielder", "quarterback"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P413.jsonl", "idx": 16}}
{"question": "Vadis Odjidja-Ofoe does not play in ___ position?", "choices": ["catcher", "midfielder"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P413.jsonl", "idx": 14}}
{"question": "Massimiliano Cappioli does not play in ___ position?", "choices": ["midfielder", "goaltender"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P413.jsonl", "idx": 20}}
{"question": "Wellington Phoenix FC is not located in ___?", "choices": ["greenland", "wellington"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P131.jsonl", "idx": 142}}
{"question": "Bern Theatre is not located in ___?", "choices": ["bern", "helsinki"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P131.jsonl", "idx": 113}}
{"question": "University of Paris III: Sorbonne Nouvelle is not located in ___?", "choices": ["hungary", "paris"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P131.jsonl", "idx": 227}}
{"question": "Lake Conroe is not located in ___?", "choices": ["texas", "monmouth"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P131.jsonl", "idx": 80}}
{"question": "Film and Television Institute of India is not located in ___?", "choices": ["haryana", "pune"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P131.jsonl", "idx": 228}}
{"question": "Evans Peninsula is not located in ___?", "choices": ["antarctica", "americas"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P30.jsonl", "idx": 63}}
{"question": "Astrolabe Glacier is not located in ___?", "choices": ["americas", "antarctica"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P30.jsonl", "idx": 84}}
{"question": "Teres Ridge is not located in ___?", "choices": ["antarctica", "europe"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P30.jsonl", "idx": 128}}
{"question": "Ruppert Coast is not located in ___?", "choices": ["oceania", "antarctica"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P30.jsonl", "idx": 90}}
{"question": "Odbert Island is not located in ___?", "choices": ["antarctica", "oceania"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P30.jsonl", "idx": 207}}
{"question": "zinc hydroxide does not consist of ___?", "choices": ["cereal", "zinc"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P527.jsonl", "idx": 57}}
{"question": "tin(IV) oxide does not consist of ___?", "choices": ["tin", "spain"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P527.jsonl", "idx": 33}}
{"question": "fermented milk product does not consist of ___?", "choices": ["syntax", "milk"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P527.jsonl", "idx": 97}}
{"question": "zinc bromide does not consist of ___?", "choices": ["zinc", "genoa"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P527.jsonl", "idx": 35}}
{"question": "adenine does not consist of ___?", "choices": ["chocolate", "nitrogen"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P527.jsonl", "idx": 11}}
{"question": "BBC Worldwide is not owned by ___?", "choices": ["bbc", "hamas"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P127.jsonl", "idx": 42}}
{"question": "Google Keep is not owned by ___?", "choices": ["mitchell", "google"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P127.jsonl", "idx": 133}}
{"question": "Pennsylvania Station is not owned by ___?", "choices": ["amtrak", "qatar"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P127.jsonl", "idx": 116}}
{"question": "Durham Bulls Athletic Park is not owned by ___?", "choices": ["australia", "durham"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P127.jsonl", "idx": 219}}
{"question": "Yahoo Games is not owned by ___?", "choices": ["yahoo", "johannesburg"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P127.jsonl", "idx": 125}}
{"question": "Judah Loew ben Bezalel is not a ___ by profession?", "choices": ["songwriter", "rabbi"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P106.jsonl", "idx": 5}}
{"question": "Rob Owen is not a ___ by profession?", "choices": ["journalist", "detective"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P106.jsonl", "idx": 0}}
{"question": "Jean Gabriel Marchand is not a ___ by profession?", "choices": ["astronaut", "lawyer"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P106.jsonl", "idx": 4}}
{"question": "Stephen Colbert is not a ___ by profession?", "choices": ["journalist", "playwright"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P106.jsonl", "idx": 2}}
{"question": "Maurice Joly is not a ___ by profession?", "choices": ["barrister", "lawyer"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P106.jsonl", "idx": 1}}
{"question": "Transboundary river is not a subclass of ___?", "choices": ["river", "monastery"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P279.jsonl", "idx": 108}}
{"question": "sphenoid bone is not a subclass of ___?", "choices": ["alloy", "bone"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P279.jsonl", "idx": 194}}
{"question": "Middle Irish is not a subclass of ___?", "choices": ["irish", "anime"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P279.jsonl", "idx": 67}}
{"question": "Park golf is not a subclass of ___?", "choices": ["rna", "golf"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P279.jsonl", "idx": 210}}
{"question": "G and H-class destroyer is not a subclass of ___?", "choices": ["destroyer", "triangle"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P279.jsonl", "idx": 316}}
{"question": "North Macedonia does not share border with ___?", "choices": ["virginia", "greece"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P47.jsonl", "idx": 148}}
{"question": "Mauritania does not share border with ___?", "choices": ["mali", "new york"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P47.jsonl", "idx": 18}}
{"question": "Guyana does not share border with ___?", "choices": ["yukon", "venezuela"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P47.jsonl", "idx": 48}}
{"question": "Liechtenstein does not share border with ___?", "choices": ["switzerland", "sant boi de llobregat"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P47.jsonl", "idx": 39}}
{"question": "Gambia does not share border with ___?", "choices": ["city of bristol", "senegal"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P47.jsonl", "idx": 74}}
{"question": "Bern is not the capital of ___?", "choices": ["switzerland", "ukraine"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P1376.jsonl", "idx": 95}}
{"question": "Podgorica is not the capital of ___?", "choices": ["madagascar", "montenegro"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P1376.jsonl", "idx": 74}}
{"question": "Athens is not the capital of ___?", "choices": ["greece", "yemen"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P1376.jsonl", "idx": 46}}
{"question": "Nuuk is not the capital of ___?", "choices": ["lakes", "greenland"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P1376.jsonl", "idx": 148}}
{"question": "Annapolis is not the capital of ___?", "choices": ["maryland", "yunnan"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P1376.jsonl", "idx": 137}}
{"question": "political philosophy is not part of ___?", "choices": ["sl", "philosophy"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P361.jsonl", "idx": 111}}
{"question": "financial economics is not part of ___?", "choices": ["economics", "organism"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P361.jsonl", "idx": 198}}
{"question": "Tate Liverpool is not part of ___?", "choices": ["sex", "tate"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P361.jsonl", "idx": 120}}
{"question": "Dianetics is not part of ___?", "choices": ["scientology", "norwegian"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P361.jsonl", "idx": 13}}
{"question": "Highlands of Iceland is not part of ___?", "choices": ["boeing", "iceland"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P361.jsonl", "idx": 241}}
{"question": "Louisiana Voodoo was not founded in ___?", "choices": ["louisiana", "nagoya"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P740.jsonl", "idx": 15}}
{"question": "The Pretty Things was not founded in ___?", "choices": ["glasgow", "london"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P740.jsonl", "idx": 36}}
{"question": "The Big Pink was not founded in ___?", "choices": ["london", "brighton"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P740.jsonl", "idx": 37}}
{"question": "Transport for London was not founded in ___?", "choices": ["tehran", "london"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P740.jsonl", "idx": 49}}
{"question": "Sound Transit was not founded in ___?", "choices": ["seattle", "dresden"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P740.jsonl", "idx": 30}}
{"question": "Dan Sealey does not play ___?", "choices": ["pipe organ", "guitar"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P1303.jsonl", "idx": 50}}
{"question": "Lev Naumov does not play ___?", "choices": ["piano", "harp"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P1303.jsonl", "idx": 12}}
{"question": "Edin Karamazov does not play ___?", "choices": ["saxophone", "guitar"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P1303.jsonl", "idx": 103}}
{"question": "Pete Lesperance does not play ___?", "choices": ["guitar", "trombone"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P1303.jsonl", "idx": 20}}
{"question": "Jimi Hendrix does not play ___?", "choices": ["flute", "guitar"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P1303.jsonl", "idx": 77}}
{"question": "Bill Gates does not work for ___?", "choices": ["microsoft", "unesco"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P108.jsonl", "idx": 0}}
{"question": "UNESCO Goodwill Ambassador does not work for ___?", "choices": ["nintendo", "unesco"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P108.jsonl", "idx": 5}}
{"question": "Zeinab Badawi does not work for ___?", "choices": ["bbc", "nintendo"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P108.jsonl", "idx": 4}}
{"question": "Esko Aho does not work for ___?", "choices": ["nintendo", "nokia"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P108.jsonl", "idx": 3}}
{"question": "Tim Paterson does not work for ___?", "choices": ["microsoft", "fiat"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P108.jsonl", "idx": 2}}
{"question": "Waterzooi was not created in ___?", "choices": ["russia", "belgium"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P495.jsonl", "idx": 63}}
{"question": "Wz. 35 anti-tank rifle was not created in ___?", "choices": ["poland", "philippines"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P495.jsonl", "idx": 241}}
{"question": "Ayyam El Sadat was not created in ___?", "choices": ["malaysia", "egypt"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P495.jsonl", "idx": 189}}
{"question": "Olvi was not created in ___?", "choices": ["finland", "cuba"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P495.jsonl", "idx": 53}}
{"question": "Animator.ru was not created in ___?", "choices": ["argentina", "russia"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P495.jsonl", "idx": 10}}
{"question": "Mwng was not written in ___?", "choices": ["welsh", "czech"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P407.jsonl", "idx": 83}}
{"question": "Rock Sound was not written in ___?", "choices": ["polish", "english"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P407.jsonl", "idx": 210}}
{"question": "La Cucaracha was not written in ___?", "choices": ["spanish", "turkish"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P407.jsonl", "idx": 138}}
{"question": "Silent Alarm was not written in ___?", "choices": ["finnish", "english"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P407.jsonl", "idx": 321}}
{"question": "New Musical Express was not written in ___?", "choices": ["english", "tamil"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P407.jsonl", "idx": 387}}
{"question": "Hull High was not originally aired on ___?", "choices": ["argentina", "nbc"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P449.jsonl", "idx": 65}}
{"question": "Crime & Punishment was not originally aired on ___?", "choices": ["nbc", "history"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P449.jsonl", "idx": 156}}
{"question": "The Long Bright Dark was not originally aired on ___?", "choices": ["bbc", "hbo"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P449.jsonl", "idx": 186}}
{"question": "Sam & Cat was not originally aired on ___?", "choices": ["nickelodeon", "bbc"], "answer": 1, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P449.jsonl", "idx": 108}}
{"question": "The Betty Hutton Show was not originally aired on ___?", "choices": ["youtube", "cbs"], "answer": 0, "metadata": {"dataset": "TREx", "category": "low_ranked", "subdataset": "P449.jsonl", "idx": 175}}
{"question": "Eusebius of Nicomedia does not have the position of ___?", "choices": ["bishop", "politics"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P39_random.jsonl", "idx": 18}}
{"question": "Ibrahim Pasha of Egypt does not have the position of ___?", "choices": ["relativity", "governor"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P39_random.jsonl", "idx": 40}}
{"question": "Herculanus of Perugia does not have the position of ___?", "choices": ["bishop", "shaved"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P39_random.jsonl", "idx": 23}}
{"question": "William of Hirsau does not have the position of ___?", "choices": ["republic", "abbot"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P39_random.jsonl", "idx": 28}}
{"question": "Lupus of Troyes does not have the position of ___?", "choices": ["bishop", "remotely"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P39_random.jsonl", "idx": 14}}
{"question": "KC-767 is not developed by ___?", "choices": ["disciplines", "boeing"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P178_random.jsonl", "idx": 32}}
{"question": "Intel MCS-51 is not developed by ___?", "choices": ["intel", "whisper"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P178_random.jsonl", "idx": 160}}
{"question": "WinDbg is not developed by ___?", "choices": ["poorly", "microsoft"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P178_random.jsonl", "idx": 24}}
{"question": "B-29 Superfortress is not developed by ___?", "choices": ["boeing", "concussion"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P178_random.jsonl", "idx": 104}}
{"question": "Microsoft Office Live is not developed by ___?", "choices": ["villains", "microsoft"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P178_random.jsonl", "idx": 355}}
{"question": "anatomical location does not work in the field of ___?", "choices": ["anatomy", "statutes"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P101_random.jsonl", "idx": 38}}
{"question": "history journal does not work in the field of ___?", "choices": ["incorporated", "history"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P101_random.jsonl", "idx": 51}}
{"question": "Abraham bar Hiyya does not work in the field of ___?", "choices": ["astronomy", "diploma"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P101_random.jsonl", "idx": 67}}
{"question": "Paul Cameron does not work in the field of ___?", "choices": ["landlord", "psychology"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P101_random.jsonl", "idx": 47}}
{"question": "Edward B. Titchener does not work in the field of ___?", "choices": ["psychology", "testimony"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P101_random.jsonl", "idx": 63}}
{"question": "Virtual XI is not represented by music label ___?", "choices": ["elders", "emi"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P264_random.jsonl", "idx": 19}}
{"question": "Judy Garland is not represented by music label ___?", "choices": ["decca", "surfaces"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P264_random.jsonl", "idx": 16}}
{"question": "Ella Fitzgerald is not represented by music label ___?", "choices": ["sincerity", "decca"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P264_random.jsonl", "idx": 10}}
{"question": "Maria Callas is not represented by music label ___?", "choices": ["emi", "perpendicular"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P264_random.jsonl", "idx": 11}}
{"question": "Midge Ure is not represented by music label ___?", "choices": ["lyricist", "emi"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P264_random.jsonl", "idx": 20}}
{"question": "Towers of London was not founded in ___?", "choices": ["london", "rescued"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P740_random.jsonl", "idx": 38}}
{"question": "Coldplay was not founded in ___?", "choices": ["archdiocese", "london"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P740_random.jsonl", "idx": 1}}
{"question": "Xiaomi was not founded in ___?", "choices": ["beijing", "temeraire"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P740_random.jsonl", "idx": 2}}
{"question": "London Stock Exchange was not founded in ___?", "choices": ["achievement", "london"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P740_random.jsonl", "idx": 51}}
{"question": "ST Aerospace was not founded in ___?", "choices": ["singapore", "certainly"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P740_random.jsonl", "idx": 21}}
{"question": "The native language of Patrice Leconte is not ___?", "choices": ["faction", "french"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P103_random.jsonl", "idx": 525}}
{"question": "The native language of Louis Barthou is not ___?", "choices": ["french", "mortar"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P103_random.jsonl", "idx": 336}}
{"question": "The native language of Jean-Louis Barrault is not ___?", "choices": ["discussed", "french"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P103_random.jsonl", "idx": 625}}
{"question": "The native language of William Howitt is not ___?", "choices": ["english", "mixing"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P103_random.jsonl", "idx": 369}}
{"question": "The native language of Zachary Taylor is not ___?", "choices": ["sincerity", "english"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P103_random.jsonl", "idx": 465}}
{"question": "Djibouti does not share border with ___?", "choices": ["ethiopia", "recordings"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P47_random.jsonl", "idx": 31}}
{"question": "Romania does not share border with ___?", "choices": ["unincorporated", "ukraine"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P47_random.jsonl", "idx": 111}}
{"question": "Gibraltar does not share border with ___?", "choices": ["spain", "starting"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P47_random.jsonl", "idx": 20}}
{"question": "Nunavut does not share border with ___?", "choices": ["beginnings", "quebec"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P47_random.jsonl", "idx": 75}}
{"question": "Campagnano di Roma does not share border with ___?", "choices": ["rome", "collection"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P47_random.jsonl", "idx": 162}}
{"question": "Australia does not maintain diplomatic relations with ___?", "choices": ["dripping", "laos"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P530_random.jsonl", "idx": 13}}
{"question": "Italy does not maintain diplomatic relations with ___?", "choices": ["lebanon", "insights"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P530_random.jsonl", "idx": 16}}
{"question": "Central African Republic does not maintain diplomatic relations with ___?", "choices": ["walled", "cameroon"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P530_random.jsonl", "idx": 26}}
{"question": "Philippines does not maintain diplomatic relations with ___?", "choices": ["indonesia", "comment"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P530_random.jsonl", "idx": 3}}
{"question": "New Zealand does not maintain diplomatic relations with ___?", "choices": ["sidewalk", "australia"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P530_random.jsonl", "idx": 22}}
{"question": "Tanya Savicheva not used to communicate in ___?", "choices": ["russian", "thomson"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P1412_random.jsonl", "idx": 331}}
{"question": "Michel Duchaussoy not used to communicate in ___?", "choices": ["wolverhampton", "french"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P1412_random.jsonl", "idx": 139}}
{"question": "Louis Riel not used to communicate in ___?", "choices": ["french", "wetland"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P1412_random.jsonl", "idx": 402}}
{"question": "Abraham Fraenkel not used to communicate in ___?", "choices": ["september", "hebrew"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P1412_random.jsonl", "idx": 274}}
{"question": "Agostino Rocca not used to communicate in ___?", "choices": ["italian", "unable"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P1412_random.jsonl", "idx": 493}}
{"question": "Rob Owen is not a ___ by profession?", "choices": ["yankees", "journalist"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P106_random.jsonl", "idx": 0}}
{"question": "Herbert Romulus O'Conor is not a ___ by profession?", "choices": ["lawyer", "connectivity"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P106_random.jsonl", "idx": 3}}
{"question": "Judah Loew ben Bezalel is not a ___ by profession?", "choices": ["medication", "rabbi"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P106_random.jsonl", "idx": 5}}
{"question": "Maurice Joly is not a ___ by profession?", "choices": ["lawyer", "flipping"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P106_random.jsonl", "idx": 1}}
{"question": "Jean Gabriel Marchand is not a ___ by profession?", "choices": ["blowing", "lawyer"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P106_random.jsonl", "idx": 4}}
{"question": "Vijayawada Junction railway station is not located in ___?", "choices": ["india", "auxiliary"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P17_random.jsonl", "idx": 320}}
{"question": "Parippally is not located in ___?", "choices": ["propagation", "india"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P17_random.jsonl", "idx": 113}}
{"question": "Santo Spirito in Sassia is not located in ___?", "choices": ["italy", "macedonia"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P17_random.jsonl", "idx": 331}}
{"question": "Tudeshk Rural District is not located in ___?", "choices": ["visitor", "iran"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P17_random.jsonl", "idx": 271}}
{"question": "Botswana Football Association is not located in ___?", "choices": ["botswana", "months"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P17_random.jsonl", "idx": 288}}
{"question": "The official language of International Organization for Standardization is not ___?", "choices": ["twentieth", "english"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P37_random.jsonl", "idx": 568}}
{"question": "The official language of Ruovesi is not ___?", "choices": ["finnish", "wrestled"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P37_random.jsonl", "idx": 65}}
{"question": "The official language of Tervola is not ___?", "choices": ["croydon", "finnish"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P37_random.jsonl", "idx": 64}}
{"question": "The official language of Trinidad and Tobago is not ___?", "choices": ["english", "bicycle"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P37_random.jsonl", "idx": 531}}
{"question": "The official language of Pontianak Sultanate is not ___?", "choices": ["personalities", "malay"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P37_random.jsonl", "idx": 381}}
{"question": "Lexus RX is not produced by ___?", "choices": ["toyota", "borough"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P176_random.jsonl", "idx": 372}}
{"question": "BMW 1 Series is not produced by ___?", "choices": ["continue", "bmw"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P176_random.jsonl", "idx": 734}}
{"question": "Chevrolet Trax is not produced by ___?", "choices": ["chevrolet", "specialist"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P176_random.jsonl", "idx": 501}}
{"question": "Dodge Dakota is not produced by ___?", "choices": ["copenhagen", "dodge"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P176_random.jsonl", "idx": 41}}
{"question": "Nokia Lumia 630 is not produced by ___?", "choices": ["nokia", "stairwell"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P176_random.jsonl", "idx": 664}}
{"question": "The capital of Maharashtra is not ___?", "choices": ["northeastern", "mumbai"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P36_random.jsonl", "idx": 30}}
{"question": "The capital of Azerbaijan is not ___?", "choices": ["baku", "kidnapped"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P36_random.jsonl", "idx": 0}}
{"question": "The capital of City of Brisbane is not ___?", "choices": ["pseudo", "brisbane"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P36_random.jsonl", "idx": 349}}
{"question": "The capital of Second Spanish Republic is not ___?", "choices": ["madrid", "unlock"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P36_random.jsonl", "idx": 421}}
{"question": "The capital of Apulia is not ___?", "choices": ["pillow", "bari"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P36_random.jsonl", "idx": 9}}
{"question": "Colchester Community Stadium is not owned by ___?", "choices": ["colchester", "broadway"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P127_random.jsonl", "idx": 158}}
{"question": "Google Scholar is not owned by ___?", "choices": ["wilhelm", "google"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P127_random.jsonl", "idx": 137}}
{"question": "Digital Audio Tape is not owned by ___?", "choices": ["sony", "parsons"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P127_random.jsonl", "idx": 172}}
{"question": "MSN Games is not owned by ___?", "choices": ["bosses", "microsoft"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P127_random.jsonl", "idx": 56}}
{"question": "Bavarian State Painting Collections is not owned by ___?", "choices": ["bavaria", "emperor"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P127_random.jsonl", "idx": 221}}
{"question": "New Horizons was not written in ___?", "choices": ["motionless", "english"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P407_random.jsonl", "idx": 123}}
{"question": "Biblioteka Dlya Chteniya was not written in ___?", "choices": ["russian", "helpful"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P407_random.jsonl", "idx": 394}}
{"question": "Le Gaulois was not written in ___?", "choices": ["locals", "french"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P407_random.jsonl", "idx": 284}}
{"question": "Kyrgyz Revolution of 2010 was not written in ___?", "choices": ["russian", "authorities"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P407_random.jsonl", "idx": 518}}
{"question": "L'Officiel Hommes was not written in ___?", "choices": ["economy", "french"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P407_random.jsonl", "idx": 237}}
{"question": "Kilby Island is not located in ___?", "choices": ["antarctica", "practically"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P30_random.jsonl", "idx": 130}}
{"question": "Cape Monaco is not located in ___?", "choices": ["naming", "antarctica"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P30_random.jsonl", "idx": 152}}
{"question": "Morocco is not located in ___?", "choices": ["africa", "inscribed"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P30_random.jsonl", "idx": 32}}
{"question": "Somalia is not located in ___?", "choices": ["assault", "africa"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P30_random.jsonl", "idx": 38}}
{"question": "Congo basin is not located in ___?", "choices": ["africa", "passages"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P30_random.jsonl", "idx": 149}}
{"question": "National Assembly of Quebec is not a legal term in ___?", "choices": ["vicious", "quebec"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P1001_random.jsonl", "idx": 340}}
{"question": "Federal Court of Canada is not a legal term in ___?", "choices": ["canada", "stirring"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P1001_random.jsonl", "idx": 350}}
{"question": "National Council of Austria is not a legal term in ___?", "choices": ["alliance", "austria"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P1001_random.jsonl", "idx": 434}}
{"question": "National Council of the Slovak Republic is not a legal term in ___?", "choices": ["slovakia", "streak"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P1001_random.jsonl", "idx": 486}}
{"question": "Hawaii Senate is not a legal term in ___?", "choices": ["edition", "hawaii"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P1001_random.jsonl", "idx": 38}}
{"question": "Green Mount Cemetery is not a ___?", "choices": ["cemetery", "report"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P31_random.jsonl", "idx": 233}}
{"question": "Inferior gemellus muscle is not a ___?", "choices": ["madhya", "muscle"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P31_random.jsonl", "idx": 213}}
{"question": "Eden Roc Renaissance Hotel Miami Beach is not a ___?", "choices": ["hotel", "download"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P31_random.jsonl", "idx": 276}}
{"question": "Kyle Rayner is not a ___?", "choices": ["bahadur", "superhero"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P31_random.jsonl", "idx": 166}}
{"question": "Lake Livingston is not a ___?", "choices": ["reservoir", "slipped"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P31_random.jsonl", "idx": 108}}
{"question": "Steve Ballmer does not work for ___?", "choices": ["evacuated", "microsoft"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P108_random.jsonl", "idx": 1}}
{"question": "UNESCO Goodwill Ambassador does not work for ___?", "choices": ["unesco", "vector"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P108_random.jsonl", "idx": 5}}
{"question": "Tim Paterson does not work for ___?", "choices": ["scotch", "microsoft"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P108_random.jsonl", "idx": 2}}
{"question": "Bill Gates does not work for ___?", "choices": ["microsoft", "holder"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P108_random.jsonl", "idx": 0}}
{"question": "Zeinab Badawi does not work for ___?", "choices": ["minute", "bbc"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P108_random.jsonl", "idx": 4}}
{"question": "The headquarter of University of South Florida is in ___?", "choices": ["tampa", "measurement"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P159_random.jsonl", "idx": 271}}
{"question": "The headquarter of Green Party of England and Wales is in ___?", "choices": ["vargas", "london"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P159_random.jsonl", "idx": 328}}
{"question": "The headquarter of BayernLB is in ___?", "choices": ["munich", "border"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P159_random.jsonl", "idx": 15}}
{"question": "The headquarter of Iranian reform movement is in ___?", "choices": ["silence", "tehran"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P159_random.jsonl", "idx": 239}}
{"question": "The headquarter of Hooters is in ___?", "choices": ["atlanta", "athletics"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P159_random.jsonl", "idx": 3}}
{"question": "Rachel Whiteread was not born in ___?", "choices": ["baptized", "london"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P19_random.jsonl", "idx": 69}}
{"question": "Zhou Long was not born in ___?", "choices": ["beijing", "wondering"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P19_random.jsonl", "idx": 110}}
{"question": "Lord Edward Gleichen was not born in ___?", "choices": ["confronted", "london"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P19_random.jsonl", "idx": 187}}
{"question": "Daniele Franceschini was not born in ___?", "choices": ["rome", "telegraph"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P19_random.jsonl", "idx": 3}}
{"question": "Adam Kendon was not born in ___?", "choices": ["protect", "london"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P19_random.jsonl", "idx": 149}}
{"question": "David Sainsbury, Baron Sainsbury of Turville never worked in ___?", "choices": ["london", "director"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P937_random.jsonl", "idx": 222}}
{"question": "Giulio Andreotti never worked in ___?", "choices": ["golfer", "rome"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P937_random.jsonl", "idx": 13}}
{"question": "Otto von Bismarck never worked in ___?", "choices": ["berlin", "shortage"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P937_random.jsonl", "idx": 152}}
{"question": "Andrew Lloyd Webber never worked in ___?", "choices": ["traditionally", "london"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P937_random.jsonl", "idx": 154}}
{"question": "Cyril Smith never worked in ___?", "choices": ["london", "speeds"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P937_random.jsonl", "idx": 104}}
{"question": "Bruce County is not located in ___?", "choices": ["nominate", "ontario"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P131_random.jsonl", "idx": 108}}
{"question": "Florence Charterhouse is not located in ___?", "choices": ["florence", "surgery"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P131_random.jsonl", "idx": 42}}
{"question": "Seoul station is not located in ___?", "choices": ["lethal", "seoul"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P131_random.jsonl", "idx": 22}}
{"question": "Zlatibor District is not located in ___?", "choices": ["serbia", "algerian"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P131_random.jsonl", "idx": 114}}
{"question": "Gulf Coast of the United States is not located in ___?", "choices": ["recovered", "texas"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P131_random.jsonl", "idx": 226}}
{"question": "Alexander VIII did not die in ___?", "choices": ["rome", "gandhi"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P20_random.jsonl", "idx": 120}}
{"question": "Jean Nicolas Pierre Hachette did not die in ___?", "choices": ["navarro", "paris"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P20_random.jsonl", "idx": 297}}
{"question": "Peter Strudel did not die in ___?", "choices": ["vienna", "excavation"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P20_random.jsonl", "idx": 19}}
{"question": "Evgeny Lifshitz did not die in ___?", "choices": ["styled", "moscow"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P20_random.jsonl", "idx": 116}}
{"question": "Ticky Holgado did not die in ___?", "choices": ["paris", "abbreviation"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P20_random.jsonl", "idx": 48}}
{"question": "Boston is not the capital of ___?", "choices": ["lately", "massachusetts"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P1376_random.jsonl", "idx": 67}}
{"question": "Amsterdam is not the capital of ___?", "choices": ["netherlands", "nicholas"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P1376_random.jsonl", "idx": 2}}
{"question": "Jakarta is not the capital of ___?", "choices": ["cannon", "indonesia"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P1376_random.jsonl", "idx": 53}}
{"question": "Tallahassee is not the capital of ___?", "choices": ["florida", "educational"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P1376_random.jsonl", "idx": 163}}
{"question": "Kigali is not the capital of ___?", "choices": ["emphasize", "rwanda"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P1376_random.jsonl", "idx": 155}}
{"question": "Datsakorn Thonglao does not play in ___ position?", "choices": ["midfielder", "celebrities"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P413_random.jsonl", "idx": 25}}
{"question": "Francesco Bolzoni does not play in ___ position?", "choices": ["tighten", "midfielder"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P413_random.jsonl", "idx": 24}}
{"question": "Paulo Henrique Ganso does not play in ___ position?", "choices": ["midfielder", "monsters"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P413_random.jsonl", "idx": 35}}
{"question": "Pirri does not play in ___ position?", "choices": ["flooded", "midfielder"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P413_random.jsonl", "idx": 1}}
{"question": "Joao Plata does not play in ___ position?", "choices": ["forward", "scientists"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P413_random.jsonl", "idx": 12}}
{"question": "Mexico City and ___ are not twin cities?", "choices": ["although", "guadalajara"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P190_random.jsonl", "idx": 20}}
{"question": "Pristina and ___ are not twin cities?", "choices": ["tirana", "thorough"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P190_random.jsonl", "idx": 4}}
{"question": "Ljubljana and ___ are not twin cities?", "choices": ["apparatus", "zagreb"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P190_random.jsonl", "idx": 3}}
{"question": "Budapest and ___ are not twin cities?", "choices": ["vienna", "fairies"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P190_random.jsonl", "idx": 10}}
{"question": "Cape Town and ___ are not twin cities?", "choices": ["werewolves", "johannesburg"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P190_random.jsonl", "idx": 18}}
{"question": "Yerba Buena Jazz Band does not play ___ music?", "choices": ["jazz", "deadline"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P136_random.jsonl", "idx": 8}}
{"question": "Funkadelic does not play ___ music?", "choices": ["strips", "funk"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P136_random.jsonl", "idx": 1}}
{"question": "Hot 8 Brass Band does not play ___ music?", "choices": ["jazz", "friedrich"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P136_random.jsonl", "idx": 10}}
{"question": "Preservation Hall Jazz Band does not play ___ music?", "choices": ["hillside", "jazz"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P136_random.jsonl", "idx": 9}}
{"question": "Pacific Jazz Records does not play ___ music?", "choices": ["jazz", "artificial"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P136_random.jsonl", "idx": 7}}
{"question": "minicomputer is not a subclass of ___?", "choices": ["informs", "computer"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P279_random.jsonl", "idx": 16}}
{"question": "quick bread is not a subclass of ___?", "choices": ["bread", "consolidated"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P279_random.jsonl", "idx": 103}}
{"question": "splenic artery is not a subclass of ___?", "choices": ["change", "artery"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P279_random.jsonl", "idx": 206}}
{"question": "landscape ecology is not a subclass of ___?", "choices": ["ecology", "notice"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P279_random.jsonl", "idx": 203}}
{"question": "mainstream jazz is not a subclass of ___?", "choices": ["fortunately", "jazz"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P279_random.jsonl", "idx": 102}}
{"question": "The David Letterman Show was not originally aired on ___?", "choices": ["nbc", "trafficking"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P449_random.jsonl", "idx": 187}}
{"question": "The Wire was not originally aired on ___?", "choices": ["majority", "hbo"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P449_random.jsonl", "idx": 84}}
{"question": "The Andy Williams Show was not originally aired on ___?", "choices": ["nbc", "torque"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P449_random.jsonl", "idx": 169}}
{"question": "College Football Live was not originally aired on ___?", "choices": ["philanthropist", "espn"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P449_random.jsonl", "idx": 150}}
{"question": "The Tonight Show Starring Johnny Carson was not originally aired on ___?", "choices": ["nbc", "psychic"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P449_random.jsonl", "idx": 210}}
{"question": "Dwaram Venkataswamy Naidu does not play ___?", "choices": ["eastman", "violin"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P1303_random.jsonl", "idx": 118}}
{"question": "Brad Delson does not play ___?", "choices": ["guitar", "promotion"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P1303_random.jsonl", "idx": 43}}
{"question": "Rob Barrett does not play ___?", "choices": ["admiral", "guitar"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P1303_random.jsonl", "idx": 7}}
{"question": "Aaron Lee Tasjan does not play ___?", "choices": ["guitar", "budget"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P1303_random.jsonl", "idx": 114}}
{"question": "Claude Delvincourt does not play ___?", "choices": ["protector", "piano"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P1303_random.jsonl", "idx": 53}}
{"question": "Football Association of Thailand is not a member of ___?", "choices": ["fifa", "observers"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P463_random.jsonl", "idx": 104}}
{"question": "South African Football Association is not a member of ___?", "choices": ["priorities", "fifa"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P463_random.jsonl", "idx": 113}}
{"question": "Austrian Football Association is not a member of ___?", "choices": ["fifa", "lecturer"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P463_random.jsonl", "idx": 57}}
{"question": "Football Association of Finland is not a member of ___?", "choices": ["calvin", "fifa"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P463_random.jsonl", "idx": 115}}
{"question": "Football Association of Brunei Darussalam is not a member of ___?", "choices": ["fifa", "application"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P463_random.jsonl", "idx": 130}}
{"question": "Idol 2010 is not part of ___?", "choices": ["arguments", "idol"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P361_random.jsonl", "idx": 184}}
{"question": "Greater Antilles is not part of ___?", "choices": ["caribbean", "hovered"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P361_random.jsonl", "idx": 92}}
{"question": "Old Egyptian is not part of ___?", "choices": ["mechanism", "egyptian"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P361_random.jsonl", "idx": 219}}
{"question": "IBM Research is not part of ___?", "choices": ["ibm", "facial"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P361_random.jsonl", "idx": 129}}
{"question": "Tate Modern is not part of ___?", "choices": ["satisfy", "tate"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P361_random.jsonl", "idx": 162}}
{"question": "Slayers Great was not created in ___?", "choices": ["japan", "superior"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P495_random.jsonl", "idx": 167}}
{"question": "Hell Girl was not created in ___?", "choices": ["plains", "japan"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P495_random.jsonl", "idx": 146}}
{"question": "Dual! Parallel Trouble Adventure was not created in ___?", "choices": ["japan", "hopeless"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P495_random.jsonl", "idx": 249}}
{"question": "J-pop was not created in ___?", "choices": ["bruised", "japan"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P495_random.jsonl", "idx": 56}}
{"question": "Jo Jeeta Wohi Super Star was not created in ___?", "choices": ["india", "schooling"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P495_random.jsonl", "idx": 262}}
{"question": "L. Ron Hubbard is not affiliated with the ___ religion?", "choices": ["republic", "scientology"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P140_random.jsonl", "idx": 1}}
{"question": "Pacific Zen Institute is not affiliated with the ___ religion?", "choices": ["zen", "living"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P140_random.jsonl", "idx": 2}}
{"question": "Tom Cruise is not affiliated with the ___ religion?", "choices": ["navajo", "scientology"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P140_random.jsonl", "idx": 0}}
{"question": "Bradford Regional Airport is not named after ___?", "choices": ["bradford", "patriarch"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P138_random.jsonl", "idx": 239}}
{"question": "Darlington railway station is not named after ___?", "choices": ["stockholm", "darlington"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P138_random.jsonl", "idx": 166}}
{"question": "Stamford A.F.C. is not named after ___?", "choices": ["stamford", "devoid"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P138_random.jsonl", "idx": 53}}
{"question": "Athens County is not named after ___?", "choices": ["garrison", "athens"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P138_random.jsonl", "idx": 74}}
{"question": "Manchester Airport is not named after ___?", "choices": ["manchester", "judgment"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P138_random.jsonl", "idx": 94}}
{"question": "The original language of De Wereld Draait Door is not ___?", "choices": ["mistakenly", "dutch"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P364_random.jsonl", "idx": 404}}
{"question": "The original language of Varudu is not ___?", "choices": ["telugu", "millimetres"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P364_random.jsonl", "idx": 54}}
{"question": "The original language of Mouna Ragam is not ___?", "choices": ["ambushed", "tamil"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P364_random.jsonl", "idx": 140}}
{"question": "The original language of Abhiyum Naanum is not ___?", "choices": ["tamil", "assessed"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P364_random.jsonl", "idx": 210}}
{"question": "The original language of Bella Notte is not ___?", "choices": ["analyst", "italian"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P364_random.jsonl", "idx": 149}}
{"question": "nickel(II) hydroxide does not consist of ___?", "choices": ["nickel", "woodrow"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P527_random.jsonl", "idx": 58}}
{"question": "jollof rice does not consist of ___?", "choices": ["perennial", "rice"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P527_random.jsonl", "idx": 64}}
{"question": "iron(II,III) oxide does not consist of ___?", "choices": ["iron", "unfair"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P527_random.jsonl", "idx": 74}}
{"question": "nickel silver does not consist of ___?", "choices": ["shrine", "copper"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P527_random.jsonl", "idx": 75}}
{"question": "fossil fuel does not consist of ___?", "choices": ["petroleum", "symmetry"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P527_random.jsonl", "idx": 34}}
{"question": "University of Edinburgh is not located in ___?", "choices": ["character", "edinburgh"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P276_random.jsonl", "idx": 139}}
{"question": "OKK Beograd is not located in ___?", "choices": ["belgrade", "homosexual"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P276_random.jsonl", "idx": 45}}
{"question": "Ano Liosia Olympic Hall is not located in ___?", "choices": ["strikeouts", "athens"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P276_random.jsonl", "idx": 285}}
{"question": "Harlem International Film Festival is not located in ___?", "choices": ["harlem", "southampton"], "answer": 1, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P276_random.jsonl", "idx": 296}}
{"question": "Channel 4's Comedy Gala is not located in ___?", "choices": ["laurence", "london"], "answer": 0, "metadata": {"dataset": "TREx", "category": "random", "subdataset": "P276_random.jsonl", "idx": 282}}
